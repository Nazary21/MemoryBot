2025-02-13 15:34:53,469 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:34:53,469 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 15:34:53,472 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 15:34:53,512 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x104e4a3c0>
2025-02-13 15:34:53,512 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1047ece60> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 15:34:53,573 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x104e41590>
2025-02-13 15:34:53,573 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:34:53,573 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:34:53,574 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:34:53,574 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:34:53,574 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:34:53,643 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 14:34:53 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 15:34:53,643 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 15:34:53,643 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:34:53,643 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:34:53,643 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:34:53,643 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:34:53,644 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 15:34:53,644 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:34:53,645 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:37:17,038 - __main__ - DEBUG - Webhook called
2025-02-13 15:37:17,038 - __main__ - DEBUG - Webhook body: {'update_id': 647682790, 'message': {'message_id': 14, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739457436, 'text': 'Yoyoyoy'}}
2025-02-13 15:37:17,039 - __main__ - DEBUG - Parsed update: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 14, 37, 16, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=14, supergroup_chat_created=False, text='Yoyoyoy'), update_id=647682790)
2025-02-13 15:37:33,397 - asyncio - ERROR - Task was destroyed but it is pending!
task: <Task pending name='Task-4' coro=<update_history_context() running at /Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/utils/context_updater.py:32>>
2025-02-13 15:37:33,398 - asyncio - ERROR - Task was destroyed but it is pending!
task: <Task pending name='Task-5' coro=<periodic_history_analysis() running at /Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/utils/whole_history_analyzer.py:64>>
2025-02-13 15:37:35,317 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:37:35,317 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 15:37:35,320 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 15:37:35,362 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10e54a3c0>
2025-02-13 15:37:35,362 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108fece60> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 15:37:35,415 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10e541590>
2025-02-13 15:37:35,416 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:37:35,416 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:37:35,416 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:37:35,416 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:37:35,416 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:37:35,503 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 14:37:35 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 15:37:35,504 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 15:37:35,504 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:37:35,504 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:37:35,504 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:37:35,504 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:37:35,505 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 15:37:35,505 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:37:35,507 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:37:40,878 - __main__ - DEBUG - Webhook called
2025-02-13 15:37:40,878 - __main__ - DEBUG - Webhook body: {'update_id': 647682791, 'message': {'message_id': 15, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739457460, 'text': 'yoyoyo'}}
2025-02-13 15:37:40,879 - __main__ - DEBUG - Parsed update: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 14, 37, 40, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=15, supergroup_chat_created=False, text='yoyoyo'), update_id=647682791)
2025-02-13 15:39:20,608 - asyncio - ERROR - Task was destroyed but it is pending!
task: <Task pending name='Task-4' coro=<update_history_context() running at /Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/utils/context_updater.py:32>>
2025-02-13 15:39:20,608 - asyncio - ERROR - Task was destroyed but it is pending!
task: <Task pending name='Task-5' coro=<periodic_history_analysis() running at /Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/utils/whole_history_analyzer.py:64>>
2025-02-13 15:39:24,084 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:39:24,084 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 15:39:24,087 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 15:39:24,155 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x106b563c0>
2025-02-13 15:39:24,156 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105aecef0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 15:39:24,197 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x106b45590>
2025-02-13 15:39:24,198 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:39:24,198 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:39:24,198 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:39:24,198 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:39:24,198 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:39:24,245 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 14:39:24 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 15:39:24,246 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 15:39:24,246 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:39:24,246 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:39:24,246 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:39:24,246 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:39:24,246 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 15:39:24,247 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:39:24,248 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:39:27,014 - __main__ - DEBUG - Webhook called
2025-02-13 15:39:27,014 - __main__ - DEBUG - Webhook body: {'update_id': 647682792, 'message': {'message_id': 16, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739457566, 'text': 'hola'}}
2025-02-13 15:39:27,015 - __main__ - DEBUG - Parsed update: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 14, 39, 26, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=16, supergroup_chat_created=False, text='hola'), update_id=647682792)
2025-02-13 15:39:40,118 - __main__ - DEBUG - Webhook called
2025-02-13 15:39:40,119 - __main__ - DEBUG - Webhook body: {'update_id': 647682793, 'message': {'message_id': 17, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739457580, 'text': '@dildong are you there?', 'entities': [{'offset': 0, 'length': 8, 'type': 'mention'}]}}
2025-02-13 15:39:40,119 - __main__ - DEBUG - Parsed update: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 14, 39, 40, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.MENTION>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=17, supergroup_chat_created=False, text='@dildong are you there?'), update_id=647682793)
2025-02-13 15:41:36,491 - asyncio - ERROR - Task was destroyed but it is pending!
task: <Task pending name='Task-4' coro=<update_history_context() running at /Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/utils/context_updater.py:32>>
2025-02-13 15:41:36,492 - asyncio - ERROR - Task was destroyed but it is pending!
task: <Task pending name='Task-5' coro=<periodic_history_analysis() running at /Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/utils/whole_history_analyzer.py:64>>
2025-02-13 15:41:38,284 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:41:38,287 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 15:41:38,289 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 15:41:38,333 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x115c53a10>
2025-02-13 15:41:38,333 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1106d8f80> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 15:41:38,378 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x115c59f90>
2025-02-13 15:41:38,378 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:41:38,378 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:41:38,378 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:41:38,378 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:41:38,378 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:41:38,739 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 14:41:38 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 15:41:38,739 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 15:41:38,740 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:41:38,740 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:41:38,740 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:41:38,740 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:41:38,740 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 15:41:54,887 - __main__ - DEBUG - Webhook called
2025-02-13 15:41:54,887 - __main__ - DEBUG - Webhook body: {'update_id': 647682794, 'message': {'message_id': 18, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739457714, 'text': 'Yoo!'}}
2025-02-13 15:41:54,887 - __main__ - DEBUG - Message text: Yoo!
2025-02-13 15:41:54,887 - __main__ - DEBUG - From user: nm_2719
2025-02-13 15:41:54,888 - __main__ - DEBUG - Parsed update: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 14, 41, 54, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=18, supergroup_chat_created=False, text='Yoo!'), update_id=647682794)
2025-02-13 15:41:54,888 - __main__ - DEBUG - Update added to queue successfully
2025-02-13 15:48:03,407 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:48:03,409 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 15:48:03,411 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 15:48:03,541 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e37a10>
2025-02-13 15:48:03,541 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103cbcef0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 15:48:03,587 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e3df90>
2025-02-13 15:48:03,587 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:48:03,588 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:48:03,588 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:48:03,588 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:48:03,588 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:48:03,653 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 14:48:03 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 15:48:03,654 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 15:48:03,654 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:48:03,654 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:48:03,654 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:48:03,654 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:48:03,654 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 15:53:14,482 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:53:14,485 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 15:53:14,488 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 15:53:14,537 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103b2f8c0>
2025-02-13 15:53:14,538 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1039aeb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 15:53:14,584 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103b1e210>
2025-02-13 15:53:14,584 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:53:14,585 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:53:14,585 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:53:14,585 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:53:14,585 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:53:14,625 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 14:53:14 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 15:53:14,626 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 15:53:14,626 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:53:14,626 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:53:14,626 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:53:14,626 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:53:14,626 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 15:53:14,626 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 15:53:14,626 - telegram.ext.Application - INFO - Application started
2025-02-13 15:53:14,627 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 15:53:14,627 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:53:14,627 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:53:14,627 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:53:14,627 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:53:14,627 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:53:14,744 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 14:53:14 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 15:53:14,744 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 15:53:14,744 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:53:14,744 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:53:14,744 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:53:14,745 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:53:14,745 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 15:53:31,815 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Hello, are you working?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 15:53:31,839 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 15:53:31,840 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 15:53:31,889 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103b85fd0>
2025-02-13 15:53:31,889 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1039acdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 15:53:31,918 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103bc4550>
2025-02-13 15:53:31,918 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:53:31,918 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:53:31,918 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:53:31,918 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:53:31,918 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:53:32,985 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Thu, 13 Feb 2025 14:53:32 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_508b7411c1e0b0378c64a8b217f6c1fd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BUUFMujxN2Nr_4tZP4O1TQUqBGFWvgPvqOVgSkcMJa0-1739458412-1.0.1.1-FbB_BkSNBEOmGFYTtUiFWGUB3I5b9kFUIeZeJvU_4i7BJ4Qfzhr3tOSNW2ZZ9JMx.viot9XkJScYlmOBj5VvDA; path=/; expires=Thu, 13-Feb-25 15:23:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=5V7h4lGckAJYNDJUq7JqvLlXt19q.A4ZCAnV1l2FcLc-1739458412931-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115a6029887eca9-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 15:53:32,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-02-13 15:53:32,986 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:53:32,986 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:53:32,986 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:53:32,986 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:53:32,986 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Thu, 13 Feb 2025 14:53:32 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_508b7411c1e0b0378c64a8b217f6c1fd'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=BUUFMujxN2Nr_4tZP4O1TQUqBGFWvgPvqOVgSkcMJa0-1739458412-1.0.1.1-FbB_BkSNBEOmGFYTtUiFWGUB3I5b9kFUIeZeJvU_4i7BJ4Qfzhr3tOSNW2ZZ9JMx.viot9XkJScYlmOBj5VvDA; path=/; expires=Thu, 13-Feb-25 15:23:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=5V7h4lGckAJYNDJUq7JqvLlXt19q.A4ZCAnV1l2FcLc-1739458412931-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115a6029887eca9-MAD'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 15:53:32,986 - openai._base_client - DEBUG - request_id: req_508b7411c1e0b0378c64a8b217f6c1fd
2025-02-13 15:53:32,986 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-02-13 15:53:32,990 - openai._base_client - DEBUG - Retrying due to status code 429
2025-02-13 15:53:32,990 - openai._base_client - DEBUG - 2 retries left
2025-02-13 15:53:32,990 - openai._base_client - INFO - Retrying request to /chat/completions in 0.463617 seconds
2025-02-13 15:53:33,456 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Hello, are you working?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 15:53:33,457 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 15:53:33,457 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:53:33,458 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:53:33,458 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:53:33,458 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:53:33,458 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:53:33,743 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Thu, 13 Feb 2025 14:53:33 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_ba15a0ffe29e26e0873dc509ef70d8fa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115a60c3832eca9-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 15:53:33,743 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-02-13 15:53:33,744 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:53:33,744 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:53:33,744 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:53:33,744 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:53:33,744 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Thu, 13 Feb 2025 14:53:33 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_ba15a0ffe29e26e0873dc509ef70d8fa', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115a60c3832eca9-MAD', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 15:53:33,744 - openai._base_client - DEBUG - request_id: req_ba15a0ffe29e26e0873dc509ef70d8fa
2025-02-13 15:53:33,744 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-02-13 15:53:33,746 - openai._base_client - DEBUG - Retrying due to status code 429
2025-02-13 15:53:33,746 - openai._base_client - DEBUG - 1 retry left
2025-02-13 15:53:33,746 - openai._base_client - INFO - Retrying request to /chat/completions in 0.832752 seconds
2025-02-13 15:53:34,584 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Hello, are you working?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 15:53:34,587 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 15:53:34,587 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:53:34,588 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:53:34,588 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:53:34,589 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:53:34,589 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:53:34,871 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Thu, 13 Feb 2025 14:53:34 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_7b458a42e205224564461610370f027c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115a6134a3ceca9-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 15:53:34,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-02-13 15:53:34,871 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:53:34,871 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:53:34,871 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:53:34,871 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:53:34,871 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Thu, 13 Feb 2025 14:53:34 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_7b458a42e205224564461610370f027c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115a6134a3ceca9-MAD', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 15:53:34,872 - openai._base_client - DEBUG - request_id: req_7b458a42e205224564461610370f027c
2025-02-13 15:53:34,872 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-02-13 15:53:34,873 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 15:53:34,875 - __main__ - ERROR - OpenAI test error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 60, in test_openai
    response = await get_chat_response("Hello, are you working?")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 48, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ~~~~~~~~~~~~~~~~~~~^
        input_options,
        ^^^^^^^^^^^^^^
    ...<4 lines>...
        stream_cls=stream_cls,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ~~~~~~~~~~~~~^
        options=options,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        stream_cls=stream_cls,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ~~~~~~~~~~~~~~~~~~~^
        input_options,
        ^^^^^^^^^^^^^^
    ...<4 lines>...
        stream_cls=stream_cls,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ~~~~~~~~~~~~~^
        options=options,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        stream_cls=stream_cls,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-02-13 15:57:49,896 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 15:57:49,896 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 15:57:49,897 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 15:57:49,897 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 15:57:49,897 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 15:57:49,963 - httpcore.connection - DEBUG - close.started
2025-02-13 15:57:49,964 - httpcore.connection - DEBUG - close.complete
2025-02-13 15:57:51,567 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 15:57:51,570 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 15:57:51,573 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 15:57:51,637 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1062f78c0>
2025-02-13 15:57:51,637 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106176b10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 15:57:51,679 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1062e6210>
2025-02-13 15:57:51,680 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:57:51,680 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:57:51,680 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:57:51,680 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:57:51,680 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:57:51,724 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 14:57:51 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 15:57:51,724 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 15:57:51,724 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:57:51,724 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:57:51,724 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:57:51,725 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:57:51,725 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 15:57:51,725 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 15:57:51,725 - telegram.ext.Application - INFO - Application started
2025-02-13 15:57:51,725 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 15:57:51,725 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 15:57:51,726 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 15:57:51,726 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 15:57:51,726 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 15:57:51,726 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 15:57:51,883 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 14:57:51 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 15:57:51,883 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 15:57:51,883 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 15:57:51,884 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 15:57:51,884 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 15:57:51,884 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 15:57:51,884 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:03:22,755 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:03:22,759 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:03:22,760 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:03:22,760 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:03:22,760 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:04:19,486 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:04:19,514 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:04:19,517 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:04:19,520 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:04:19,596 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x115c5b8c0>
2025-02-13 16:04:19,596 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1107deb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:04:19,645 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x115c4a210>
2025-02-13 16:04:19,645 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:04:19,645 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:04:19,646 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:04:19,646 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:04:19,646 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:04:19,683 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:04:19 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:04:19,684 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:04:19,684 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:04:19,684 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:04:19,684 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:04:19,684 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:04:19,684 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:04:19,684 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:04:19,684 - telegram.ext.Application - INFO - Application started
2025-02-13 16:04:19,684 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 16:04:19,685 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:04:19,685 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:04:19,685 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:04:19,685 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:04:19,685 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:04:19,918 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:04:19 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:04:19,919 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:04:19,919 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:04:19,919 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:04:19,919 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:04:19,920 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:04:19,920 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:04:28,123 - __main__ - INFO - Received webhook: {'update_id': 647682798, 'message': {'message_id': 22, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459068, 'text': 'test'}}
2025-02-13 16:04:28,124 - telegram.ext.Application - DEBUG - Processing update Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 4, 28, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=22, supergroup_chat_created=False, text='test'), update_id=647682798)
2025-02-13 16:04:28,124 - __main__ - INFO - Processing message: test
2025-02-13 16:04:28,128 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'test'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:04:28,152 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:04:28,153 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:04:28,212 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x115cb16a0>
2025-02-13 16:04:28,212 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1107dcdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:04:28,234 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x115ce82d0>
2025-02-13 16:04:28,235 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:04:28,236 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:04:28,236 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:04:28,236 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:04:28,236 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:04:29,408 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:04:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'458'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199973'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_47a00010d67ece47805399051bfeeb8f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qsamZJKcn.U4CtoevXwGq3BBXwroGtC35dMR2aNqiuM-1739459069-1.0.1.1-fRTg.mwk_k4kjSw7.l0B6sh5QptPKztbeps6CG0LRV_IIlAD8Vg3Jpm2H.msfOLZEhmcrc8ffEOhmooCvYdTtQ; path=/; expires=Thu, 13-Feb-25 15:34:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=A5SbwlJBl61NYY4UY_JITJUm296D1rjVbRGyIZwB6ow-1739459069452-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115b608dbd22fc7-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:04:29,409 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:04:29,409 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:04:29,411 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:04:29,411 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:04:29,411 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:04:29,412 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:04:29 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '458'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199973'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_47a00010d67ece47805399051bfeeb8f'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=qsamZJKcn.U4CtoevXwGq3BBXwroGtC35dMR2aNqiuM-1739459069-1.0.1.1-fRTg.mwk_k4kjSw7.l0B6sh5QptPKztbeps6CG0LRV_IIlAD8Vg3Jpm2H.msfOLZEhmcrc8ffEOhmooCvYdTtQ; path=/; expires=Thu, 13-Feb-25 15:34:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=A5SbwlJBl61NYY4UY_JITJUm296D1rjVbRGyIZwB6ow-1739459069452-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115b608dbd22fc7-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:04:29,412 - openai._base_client - DEBUG - request_id: req_47a00010d67ece47805399051bfeeb8f
2025-02-13 16:04:29,417 - __main__ - INFO - Got response: Hello! How can I assist you today?
2025-02-13 16:04:29,418 - __main__ - ERROR - Error in message handler: This object has no bot associated with it. Shortcuts cannot be used.
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 85, in message_handler
    await update.message.reply_text(response)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.
2025-02-13 16:04:29,422 - telegram.ext.Application - ERROR - No error handlers are registered, logging exception.
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 85, in message_handler
    await update.message.reply_text(response)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_application.py", line 1325, in process_update
    await coroutine
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_handlers/basehandler.py", line 158, in handle_update
    return await self.callback(update, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 88, in message_handler
    await update.message.reply_text("An error occurred while processing your message.")
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.
2025-02-13 16:04:46,453 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Hello, are you working?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:04:46,454 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:04:46,454 - httpcore.connection - DEBUG - close.started
2025-02-13 16:04:46,454 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:04:46,454 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:04:46,475 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x115ce8a50>
2025-02-13 16:04:46,475 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1107dcdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:04:46,500 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1161c0640>
2025-02-13 16:04:46,500 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:04:46,500 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:04:46,500 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:04:46,500 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:04:46,500 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:04:47,348 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:04:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'448'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199968'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_a4655dc37c088a79dd2e86e8c4b6f44a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LnSHygHnDXrheImCPPpjo4wGNbhZrhGR9GnLzUGiqdg-1739459087-1.0.1.1-xeGtUV3eD8tANss3Se8k_Dvz975W9k28h88K.2D8tgvQlwXeCrtV1V8ZLOiXLqfSvSgWTID73xPAypCZsfM1Pw; path=/; expires=Thu, 13-Feb-25 15:34:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=omowZ8DeeJd6MSqxATjfbqe9Fj9MDzH6xeT5zCz12e4-1739459087251-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115b67b0af169eb-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:04:47,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:04:47,350 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:04:47,351 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:04:47,351 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:04:47,351 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:04:47,351 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:04:47 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '448'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199968'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '9ms'), ('x-request-id', 'req_a4655dc37c088a79dd2e86e8c4b6f44a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=LnSHygHnDXrheImCPPpjo4wGNbhZrhGR9GnLzUGiqdg-1739459087-1.0.1.1-xeGtUV3eD8tANss3Se8k_Dvz975W9k28h88K.2D8tgvQlwXeCrtV1V8ZLOiXLqfSvSgWTID73xPAypCZsfM1Pw; path=/; expires=Thu, 13-Feb-25 15:34:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=omowZ8DeeJd6MSqxATjfbqe9Fj9MDzH6xeT5zCz12e4-1739459087251-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115b67b0af169eb-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:04:47,352 - openai._base_client - DEBUG - request_id: req_a4655dc37c088a79dd2e86e8c4b6f44a
2025-02-13 16:04:56,491 - __main__ - INFO - Received webhook: {'update_id': 647682799, 'message': {'message_id': 23, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459096, 'text': 'Yo'}}
2025-02-13 16:04:56,493 - telegram.ext.Application - DEBUG - Processing update Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 4, 56, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=23, supergroup_chat_created=False, text='Yo'), update_id=647682799)
2025-02-13 16:04:56,493 - __main__ - INFO - Processing message: Yo
2025-02-13 16:04:56,496 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Yo'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:04:56,496 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:04:56,496 - httpcore.connection - DEBUG - close.started
2025-02-13 16:04:56,496 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:04:56,496 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:04:56,524 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1161c0e90>
2025-02-13 16:04:56,524 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1107dcdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:04:56,548 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x115c43bf0>
2025-02-13 16:04:56,549 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:04:56,549 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:04:56,549 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:04:56,549 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:04:56,549 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:04:57,255 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:04:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'486'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199973'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_1947f63edb6b38f42faa6c097ef9ee7d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=838s27_m_cwl_YMiVwqKP3HTc..syKPHMXk1VCvEmUw-1739459097-1.0.1.1-Mm_XgJnsniXh6RJ.8lWyEPfLvqzIaybDLCgUboXx9Ry_C4D.sjc60dyYZBlx9TGK6hu2EF9AEYxz8HJkEUDzuw; path=/; expires=Thu, 13-Feb-25 15:34:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=1W0a5WhRGbpSIZ2iP0G03eljiCTIyKGJjsIv7x4GGZc-1739459097297-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115b6b9d8b60345-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:04:57,256 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:04:57,256 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:04:57,300 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:04:57,300 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:04:57,300 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:04:57,300 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:04:57 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '486'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199973'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_1947f63edb6b38f42faa6c097ef9ee7d'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=838s27_m_cwl_YMiVwqKP3HTc..syKPHMXk1VCvEmUw-1739459097-1.0.1.1-Mm_XgJnsniXh6RJ.8lWyEPfLvqzIaybDLCgUboXx9Ry_C4D.sjc60dyYZBlx9TGK6hu2EF9AEYxz8HJkEUDzuw; path=/; expires=Thu, 13-Feb-25 15:34:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=1W0a5WhRGbpSIZ2iP0G03eljiCTIyKGJjsIv7x4GGZc-1739459097297-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115b6b9d8b60345-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:04:57,300 - openai._base_client - DEBUG - request_id: req_1947f63edb6b38f42faa6c097ef9ee7d
2025-02-13 16:04:57,301 - __main__ - INFO - Got response: Hello! How can I assist you today?
2025-02-13 16:04:57,301 - __main__ - ERROR - Error in message handler: This object has no bot associated with it. Shortcuts cannot be used.
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 85, in message_handler
    await update.message.reply_text(response)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.
2025-02-13 16:04:57,302 - telegram.ext.Application - ERROR - No error handlers are registered, logging exception.
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 85, in message_handler
    await update.message.reply_text(response)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_application.py", line 1325, in process_update
    await coroutine
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_handlers/basehandler.py", line 158, in handle_update
    return await self.callback(update, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 88, in message_handler
    await update.message.reply_text("An error occurred while processing your message.")
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.
2025-02-13 16:05:20,103 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:05:20,104 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:05:20,104 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:05:20,104 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:05:20,104 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:05:20,141 - httpcore.connection - DEBUG - close.started
2025-02-13 16:05:20,141 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:05:21,579 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:05:21,606 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:05:21,609 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:05:21,612 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:05:21,651 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10a15b8c0>
2025-02-13 16:05:21,651 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104cdeb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:05:21,691 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10a14a210>
2025-02-13 16:05:21,693 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:05:21,693 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:05:21,693 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:05:21,693 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:05:21,693 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:05:21,732 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:05:21 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:05:21,732 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:05:21,732 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:05:21,733 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:05:21,733 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:05:21,733 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:05:21,733 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:05:21,733 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:05:21,733 - telegram.ext.Application - INFO - Application started
2025-02-13 16:05:21,733 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 16:05:21,734 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:05:21,734 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:05:21,734 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:05:21,734 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:05:21,734 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:05:21,779 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:05:21 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:05:21,779 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:05:21,779 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:05:21,779 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:05:21,779 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:05:21,779 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:05:21,779 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:05:32,454 - __main__ - INFO - Received webhook: {'update_id': 647682800, 'message': {'message_id': 24, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459132, 'text': 'test'}}
2025-02-13 16:05:32,455 - telegram.ext.Application - DEBUG - Processing update Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 5, 32, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=24, supergroup_chat_created=False, text='test'), update_id=647682800)
2025-02-13 16:05:32,456 - __main__ - INFO - Processing message: test
2025-02-13 16:05:32,459 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'test'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:05:32,478 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:05:32,478 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:05:32,523 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10a1b16a0>
2025-02-13 16:05:32,523 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104cdcdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:05:32,548 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10a1e82d0>
2025-02-13 16:05:32,549 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:05:32,549 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:05:32,549 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:05:32,550 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:05:32,550 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:05:33,139 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:05:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'411'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199973'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_d5a3992accc4044e9153bde65ab2a411'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=60vkA7u0F1cUnHnZaq8T0EtvFGc_i4A9IuiALeGMcIU-1739459133-1.0.1.1-CumZb4CisIqb6Z6SizPf8gvHN_z5ngo1fRLFmX632gybAcUwBmCoT66fb5wIcd9mSUbk6sLv8Wqu6dN5UWjVvA; path=/; expires=Thu, 13-Feb-25 15:35:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Zak4pk9HBr6wjlmMji05khcierGPqRu82ij_5z5jLoo-1739459133179-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115b79adc6a2f8d-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:05:33,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:05:33,142 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:05:33,152 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:05:33,153 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:05:33,153 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:05:33,153 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:05:33 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '411'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199973'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_d5a3992accc4044e9153bde65ab2a411'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=60vkA7u0F1cUnHnZaq8T0EtvFGc_i4A9IuiALeGMcIU-1739459133-1.0.1.1-CumZb4CisIqb6Z6SizPf8gvHN_z5ngo1fRLFmX632gybAcUwBmCoT66fb5wIcd9mSUbk6sLv8Wqu6dN5UWjVvA; path=/; expires=Thu, 13-Feb-25 15:35:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Zak4pk9HBr6wjlmMji05khcierGPqRu82ij_5z5jLoo-1739459133179-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115b79adc6a2f8d-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:05:33,153 - openai._base_client - DEBUG - request_id: req_d5a3992accc4044e9153bde65ab2a411
2025-02-13 16:05:33,160 - __main__ - INFO - Got response: Hello! How can I assist you today?
2025-02-13 16:05:33,160 - __main__ - ERROR - Error in message handler: This object has no bot associated with it. Shortcuts cannot be used.
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 85, in message_handler
    await update.message.reply_text(response)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.
2025-02-13 16:05:33,166 - telegram.ext.Application - ERROR - No error handlers are registered, logging exception.
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 85, in message_handler
    await update.message.reply_text(response)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_application.py", line 1325, in process_update
    await coroutine
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_handlers/basehandler.py", line 158, in handle_update
    return await self.callback(update, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 88, in message_handler
    await update.message.reply_text("An error occurred while processing your message.")
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.
2025-02-13 16:05:40,812 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:05:40,812 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:05:40,812 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:05:40,812 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:05:40,813 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:05:40,882 - httpcore.connection - DEBUG - close.started
2025-02-13 16:05:40,882 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:06:01,661 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:06:01,689 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:06:01,693 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:06:01,695 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:06:01,738 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10819f8c0>
2025-02-13 16:06:01,738 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10801eb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:06:01,781 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10818e210>
2025-02-13 16:06:01,781 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:06:01,781 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:06:01,781 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:06:01,781 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:06:01,781 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:06:01,822 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:06:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:06:01,823 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:06:01,823 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:06:01,823 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:06:01,823 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:06:01,823 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:06:01,823 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:06:01,823 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:06:01,823 - telegram.ext.Application - INFO - Application started
2025-02-13 16:06:01,824 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 16:06:01,824 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:06:01,824 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:06:01,824 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:06:01,824 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:06:01,824 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:06:01,875 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:06:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:06:01,875 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:06:01,875 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:06:01,875 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:06:01,875 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:06:01,875 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:06:01,875 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:06:07,326 - __main__ - INFO - Received webhook: {'update_id': 647682801, 'message': {'message_id': 25, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459167, 'text': 'yo'}}
2025-02-13 16:06:07,327 - telegram.ext.Application - DEBUG - Processing update Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 6, 7, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=25, supergroup_chat_created=False, text='yo'), update_id=647682801)
2025-02-13 16:06:07,328 - __main__ - INFO - Processing message: yo
2025-02-13 16:06:07,332 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'yo'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:06:07,355 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:06:07,355 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:06:07,375 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1081f56a0>
2025-02-13 16:06:07,375 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10801cdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:06:07,399 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10822c2d0>
2025-02-13 16:06:07,399 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:06:07,399 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:06:07,399 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:06:07,399 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:06:07,399 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:06:07,925 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:06:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'347'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199973'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_1e0743687665017249eec698262f759a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0l_ROasqnlN3gxfN7EacXlq5_aFhVlaXOlrmwoQgMzs-1739459167-1.0.1.1-MRH8kYWYscSLFtjNqflBubOsiLzZh16s1FEFN3bfG2Xu0OT5uCjYYVsM2aHAu63aj9T.KhDLr9dLjiQIKfn5Yg; path=/; expires=Thu, 13-Feb-25 15:36:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=XqU1chI2XP4tjkStKkKMkQm0fB2kuYO.N535TKY0XrM-1739459167970-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115b874aaefcbcf-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:06:07,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:06:07,926 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:06:07,936 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:06:07,936 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:06:07,936 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:06:07,936 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:06:07 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '347'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199973'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_1e0743687665017249eec698262f759a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=0l_ROasqnlN3gxfN7EacXlq5_aFhVlaXOlrmwoQgMzs-1739459167-1.0.1.1-MRH8kYWYscSLFtjNqflBubOsiLzZh16s1FEFN3bfG2Xu0OT5uCjYYVsM2aHAu63aj9T.KhDLr9dLjiQIKfn5Yg; path=/; expires=Thu, 13-Feb-25 15:36:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=XqU1chI2XP4tjkStKkKMkQm0fB2kuYO.N535TKY0XrM-1739459167970-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115b874aaefcbcf-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:06:07,937 - openai._base_client - DEBUG - request_id: req_1e0743687665017249eec698262f759a
2025-02-13 16:06:07,943 - __main__ - INFO - Got response: Hello! How can I assist you today?
2025-02-13 16:06:07,943 - __main__ - ERROR - Error in message handler: This object has no bot associated with it. Shortcuts cannot be used.
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 85, in message_handler
    await update.message.reply_text(response)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.
2025-02-13 16:06:07,947 - telegram.ext.Application - ERROR - No error handlers are registered, logging exception.
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 85, in message_handler
    await update.message.reply_text(response)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_application.py", line 1325, in process_update
    await coroutine
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_handlers/basehandler.py", line 158, in handle_update
    return await self.callback(update, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 88, in message_handler
    await update.message.reply_text("An error occurred while processing your message.")
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1767, in reply_text
    chat_id, effective_reply_parameters = await self._parse_quote_arguments(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        do_quote, quote, reply_to_message_id, reply_parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1689, in _parse_quote_arguments
    effective_reply_parameters = self._quote(effective_do_quote)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_message.py", line 1478, in _quote
    if hasattr(self.get_bot(), "defaults") and self.get_bot().defaults:  # type: ignore
               ~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.
2025-02-13 16:06:48,483 - __main__ - INFO - Received webhook: {'update_id': 647682802, 'message': {'message_id': 26, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459208, 'text': '/help', 'entities': [{'offset': 0, 'length': 5, 'type': 'bot_command'}]}}
2025-02-13 16:06:48,483 - telegram.ext.Application - DEBUG - Processing update Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 6, 48, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=5, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=26, supergroup_chat_created=False, text='/help'), update_id=647682802)
2025-02-13 16:06:48,483 - telegram.ext.Application - ERROR - No error handlers are registered, logging exception.
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_application.py", line 1289, in process_update
    check = handler.check_update(update)  # Should the handler handle this update?
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/ext/_handlers/commandhandler.py", line 188, in check_update
    and message.get_bot()
        ~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/telegram/_telegramobject.py", line 660, in get_bot
    raise RuntimeError(
        "This object has no bot associated with it. Shortcuts cannot be used."
    )
RuntimeError: This object has no bot associated with it. Shortcuts cannot be used.
2025-02-13 16:07:59,344 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:07:59,344 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:07:59,344 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:07:59,345 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:07:59,345 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:07:59,392 - httpcore.connection - DEBUG - close.started
2025-02-13 16:07:59,393 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:08:01,788 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:08:01,814 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:08:01,817 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:08:01,819 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:08:01,865 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10540f8c0>
2025-02-13 16:08:01,866 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10528eb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:08:01,912 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1053fe210>
2025-02-13 16:08:01,912 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:08:01,912 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:08:01,912 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:08:01,912 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:08:01,912 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:08:01,985 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:08:02 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:08:01,985 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:08:01,986 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:08:01,986 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:08:01,986 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:08:01,986 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:08:01,986 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:08:01,986 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:08:01,986 - telegram.ext.Application - INFO - Application started
2025-02-13 16:08:01,986 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history')]}`
2025-02-13 16:08:01,987 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:08:01,987 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:08:01,987 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:08:01,987 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:08:01,987 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:08:02,160 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:08:02 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:08:02,162 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:08:02,162 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:08:02,162 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:08:02,163 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:08:02,163 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:08:02,164 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:08:27,977 - __main__ - INFO - Received webhook: {'update_id': 647682803, 'message': {'message_id': 27, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459307, 'text': 'hola'}}
2025-02-13 16:08:27,978 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 8, 27, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=27, supergroup_chat_created=False, text='hola'), update_id=647682803)
2025-02-13 16:08:27,978 - __main__ - INFO - Processing message: hola
2025-02-13 16:08:27,980 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hola'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:08:28,003 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:08:28,003 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:08:28,051 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105465fd0>
2025-02-13 16:08:28,052 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10528cdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:08:28,074 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105e007d0>
2025-02-13 16:08:28,074 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:08:28,075 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:08:28,075 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:08:28,075 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:08:28,075 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:08:28,639 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:08:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'341'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199973'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_123349ab43d400bd3f38972bd4bfce88'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uZgqhRRVjvzPSXFOfgdr9fai957prdbla8bNdSK1JcM-1739459308-1.0.1.1-GPCmWk1H6v6b06fRsGAwVPPXTJoPdqgDTMe4MHm5eAtqqYLbrMR.xzYNXsLrWiKk32yX6YsqPTbbQTXNX4koig; path=/; expires=Thu, 13-Feb-25 15:38:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=RMwP3FQR7XpzRbFTxP2J4XoSBR1TbVQ0OzA8QhQ3KNc-1739459308631-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115bbe3dea22f8c-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:08:28,642 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:08:28,642 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:08:28,643 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:08:28,643 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:08:28,644 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:08:28,644 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:08:28 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '341'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199973'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_123349ab43d400bd3f38972bd4bfce88'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=uZgqhRRVjvzPSXFOfgdr9fai957prdbla8bNdSK1JcM-1739459308-1.0.1.1-GPCmWk1H6v6b06fRsGAwVPPXTJoPdqgDTMe4MHm5eAtqqYLbrMR.xzYNXsLrWiKk32yX6YsqPTbbQTXNX4koig; path=/; expires=Thu, 13-Feb-25 15:38:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=RMwP3FQR7XpzRbFTxP2J4XoSBR1TbVQ0OzA8QhQ3KNc-1739459308631-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115bbe3dea22f8c-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:08:28,644 - openai._base_client - DEBUG - request_id: req_123349ab43d400bd3f38972bd4bfce88
2025-02-13 16:08:28,651 - __main__ - INFO - Got response: Hola! En qu puedo ayudarte hoy?
2025-02-13 16:08:28,652 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'Hola! En qu puedo ayudarte hoy?'}`
2025-02-13 16:08:28,653 - httpcore.connection - DEBUG - close.started
2025-02-13 16:08:28,653 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:08:28,653 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:08:28,695 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105e00e10>
2025-02-13 16:08:28,696 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10528eb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:08:28,741 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105e1c180>
2025-02-13 16:08:28,742 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:08:28,742 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:08:28,742 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:08:28,742 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:08:28,743 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:08:28,829 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:08:28 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'283'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:08:28,830 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:08:28,830 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:08:28,830 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:08:28,830 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:08:28,831 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:08:28,831 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 28, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459308, 'text': 'Hola! En qu puedo ayudarte hoy?'}`
2025-02-13 16:08:40,005 - __main__ - INFO - Received webhook: {'update_id': 647682804, 'message': {'message_id': 29, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459320, 'text': 'Wohoo we finally talk'}}
2025-02-13 16:08:40,006 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 8, 40, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=29, supergroup_chat_created=False, text='Wohoo we finally talk'), update_id=647682804)
2025-02-13 16:08:40,006 - __main__ - INFO - Processing message: Wohoo we finally talk
2025-02-13 16:08:40,011 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Wohoo we finally talk'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:08:40,012 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:08:40,012 - httpcore.connection - DEBUG - close.started
2025-02-13 16:08:40,013 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:08:40,013 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:08:40,035 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105e01950>
2025-02-13 16:08:40,035 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10528cdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:08:40,058 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105e1d6e0>
2025-02-13 16:08:40,059 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:08:40,059 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:08:40,059 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:08:40,059 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:08:40,059 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:08:40,624 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:08:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'403'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199968'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_f6463981ccd66a96db04b6b5eaac9ecf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115bc2ed80be0a7-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:08:40,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:08:40,626 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:08:40,627 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:08:40,627 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:08:40,627 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:08:40,627 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:08:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '403', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199968', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '9ms', 'x-request-id': 'req_f6463981ccd66a96db04b6b5eaac9ecf', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115bc2ed80be0a7-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:08:40,627 - openai._base_client - DEBUG - request_id: req_f6463981ccd66a96db04b6b5eaac9ecf
2025-02-13 16:08:40,629 - __main__ - INFO - Got response: Hello! I'm here to assist you with anything you need. What would you like to talk about?
2025-02-13 16:08:40,629 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': "Hello! I'm here to assist you with anything you need. What would you like to talk about?"}`
2025-02-13 16:08:40,631 - httpcore.connection - DEBUG - close.started
2025-02-13 16:08:40,631 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:08:40,631 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:08:40,673 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105e1dcd0>
2025-02-13 16:08:40,673 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10528eb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:08:40,722 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105e24710>
2025-02-13 16:08:40,723 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:08:40,723 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:08:40,723 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:08:40,724 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:08:40,724 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:08:40,821 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:08:40 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'322'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:08:40,824 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:08:40,824 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:08:40,824 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:08:40,824 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:08:40,825 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:08:40,825 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 30, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459320, 'text': "Hello! I'm here to assist you with anything you need. What would you like to talk about?"}`
2025-02-13 16:08:48,283 - __main__ - INFO - Received webhook: {'update_id': 647682805, 'message': {'message_id': 31, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459328, 'text': '   .'}}
2025-02-13 16:08:48,284 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 8, 48, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=31, supergroup_chat_created=False, text='   .'), update_id=647682805)
2025-02-13 16:08:48,284 - __main__ - INFO - Processing message:    .
2025-02-13 16:08:48,288 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '   .'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:08:48,289 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:08:48,289 - httpcore.connection - DEBUG - close.started
2025-02-13 16:08:48,290 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:08:48,290 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:08:48,315 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105e1cc30>
2025-02-13 16:08:48,315 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10528cdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:08:48,340 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105e25130>
2025-02-13 16:08:48,341 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:08:48,341 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:08:48,341 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:08:48,341 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:08:48,341 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:08:49,017 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:08:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'538'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199962'), (b'x-ratelimit-reset-requests', b'9.006s'), (b'x-ratelimit-reset-tokens', b'11ms'), (b'x-request-id', b'req_48225d848f72faf0d19363c573d6ac14'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115bc62885f69eb-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:08:49,018 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:08:49,018 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:08:49,018 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:08:49,019 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:08:49,019 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:08:49,019 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:08:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '538', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199962', 'x-ratelimit-reset-requests': '9.006s', 'x-ratelimit-reset-tokens': '11ms', 'x-request-id': 'req_48225d848f72faf0d19363c573d6ac14', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115bc62885f69eb-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:08:49,019 - openai._base_client - DEBUG - request_id: req_48225d848f72faf0d19363c573d6ac14
2025-02-13 16:08:49,020 - __main__ - INFO - Got response: ,     .   ?
2025-02-13 16:08:49,020 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ',     .   ?'}`
2025-02-13 16:08:49,021 - httpcore.connection - DEBUG - close.started
2025-02-13 16:08:49,021 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:08:49,021 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:08:49,072 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105e305a0>
2025-02-13 16:08:49,072 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10528eb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:08:49,118 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105e306b0>
2025-02-13 16:08:49,118 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:08:49,118 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:08:49,118 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:08:49,119 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:08:49,119 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:08:49,225 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:08:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'503'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:08:49,226 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:08:49,226 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:08:49,226 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:08:49,226 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:08:49,227 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:08:49,227 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 32, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459329, 'text': ',     .   ?'}`
2025-02-13 16:12:56,445 - __main__ - INFO - Received webhook: {'update_id': 647682806, 'message': {'message_id': 33, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459576, 'text': '/analyze', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 16:12:56,446 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 12, 56, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=33, supergroup_chat_created=False, text='/analyze'), update_id=647682806)
2025-02-13 16:12:56,447 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'History analysis completed! The context has been updated.'}`
2025-02-13 16:12:56,447 - httpcore.connection - DEBUG - close.started
2025-02-13 16:12:56,447 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:12:56,447 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:12:56,515 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105471b50>
2025-02-13 16:12:56,515 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10528eb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:12:56,556 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105471d50>
2025-02-13 16:12:56,557 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:12:56,557 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:12:56,557 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:12:56,557 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:12:56,557 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:12:56,665 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:12:56 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'291'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:12:56,667 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:12:56,667 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:12:56,667 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:12:56,667 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:12:56,668 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:12:56,669 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 34, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459576, 'text': 'History analysis completed! The context has been updated.'}`
2025-02-13 16:13:15,759 - __main__ - INFO - Received webhook: {'update_id': 647682807, 'message': {'message_id': 35, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459595, 'text': '/help', 'entities': [{'offset': 0, 'length': 5, 'type': 'bot_command'}]}}
2025-02-13 16:13:15,760 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 13, 15, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=5, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=35, supergroup_chat_created=False, text='/help'), update_id=647682807)
2025-02-13 16:13:15,760 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'Here are the available commands:\n\n/start - Start the bot\n/help - Show this help message\n/clear - Clear conversation history\n/session - Set session duration\n/analyze - Analyze entire conversation history'}`
2025-02-13 16:13:15,760 - httpcore.connection - DEBUG - close.started
2025-02-13 16:13:15,761 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:13:15,761 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:13:15,802 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1054767b0>
2025-02-13 16:13:15,803 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10528eb10> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:13:15,852 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105476d50>
2025-02-13 16:13:15,853 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:13:15,855 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:13:15,856 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:13:15,857 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:13:15,857 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:13:15,949 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:13:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'687'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:13:15,951 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:13:15,951 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:13:15,952 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:13:15,955 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:13:15,956 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:13:15,959 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 36, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739459595, 'text': 'Here are the available commands:\n\n/start - Start the bot\n/help - Show this help message\n/clear - Clear conversation history\n/session - Set session duration\n/analyze - Analyze entire conversation history', 'entities': [{'offset': 34, 'length': 6, 'type': 'bot_command'}, {'offset': 57, 'length': 5, 'type': 'bot_command'}, {'offset': 88, 'length': 6, 'type': 'bot_command'}, {'offset': 124, 'length': 8, 'type': 'bot_command'}, {'offset': 156, 'length': 8, 'type': 'bot_command'}]}`
2025-02-13 16:22:45,284 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:22:45,284 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:22:45,284 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:22:45,284 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:22:45,284 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:22:45,327 - httpcore.connection - DEBUG - close.started
2025-02-13 16:22:45,327 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:22:46,944 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:22:46,969 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:22:46,972 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:22:46,975 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:22:47,078 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10895b8c0>
2025-02-13 16:22:47,078 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10370ec30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:22:47,119 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10894a210>
2025-02-13 16:22:47,120 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:22:47,120 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:22:47,120 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:22:47,120 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:22:47,120 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:22:47,168 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:22:47 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:22:47,168 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:22:47,168 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:22:47,168 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:22:47,168 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:22:47,168 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:22:47,168 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:22:47,169 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:22:47,169 - telegram.ext.Application - INFO - Application started
2025-02-13 16:22:47,169 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 16:22:47,169 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:22:47,169 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:22:47,169 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:22:47,169 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:22:47,169 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:22:47,218 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:22:47 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:22:47,219 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:22:47,219 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:22:47,219 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:22:47,219 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:22:47,219 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:22:47,219 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:23:03,708 - __main__ - INFO - Received webhook: {'update_id': 647682808, 'message': {'message_id': 37, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460183, 'text': '/session', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 16:23:03,710 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 23, 3, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=37, supergroup_chat_created=False, text='/session'), update_id=647682808)
2025-02-13 16:23:03,710 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'Session duration set to medium (6 hours)'}`
2025-02-13 16:23:03,710 - httpcore.connection - DEBUG - close.started
2025-02-13 16:23:03,711 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:23:03,711 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:23:03,757 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1089dce10>
2025-02-13 16:23:03,758 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10370ec30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:23:03,809 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108913100>
2025-02-13 16:23:03,809 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:23:03,809 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:23:03,810 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:23:03,810 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:23:03,810 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:23:03,936 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:23:03 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'274'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:23:03,936 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:23:03,936 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:23:03,936 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:23:03,938 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:23:03,938 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:23:03,939 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 38, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460183, 'text': 'Session duration set to medium (6 hours)'}`
2025-02-13 16:23:09,808 - __main__ - INFO - Received webhook: {'update_id': 647682809, 'message': {'message_id': 39, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460189, 'text': '/start', 'entities': [{'offset': 0, 'length': 6, 'type': 'bot_command'}]}}
2025-02-13 16:23:09,809 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 23, 9, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=6, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=39, supergroup_chat_created=False, text='/start'), update_id=647682809)
2025-02-13 16:23:09,809 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': " Hello! I'm your AI assistant bot. I can help you with various tasks and maintain our conversation history.\n\nUse /help to see available commands."}`
2025-02-13 16:23:09,810 - httpcore.connection - DEBUG - close.started
2025-02-13 16:23:09,810 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:23:09,811 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:23:09,849 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1089e08a0>
2025-02-13 16:23:09,849 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10370ec30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:23:09,890 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108940710>
2025-02-13 16:23:09,891 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:23:09,891 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:23:09,891 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:23:09,891 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:23:09,891 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:23:09,958 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:23:09 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'453'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:23:09,959 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:23:09,959 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:23:09,959 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:23:09,959 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:23:09,959 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:23:09,959 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 40, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460189, 'text': " Hello! I'm your AI assistant bot. I can help you with various tasks and maintain our conversation history.\n\nUse /help to see available commands.", 'entities': [{'offset': 115, 'length': 5, 'type': 'bot_command'}]}`
2025-02-13 16:23:11,462 - __main__ - INFO - Received webhook: {'update_id': 647682810, 'message': {'message_id': 41, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460191, 'text': '/help', 'entities': [{'offset': 0, 'length': 5, 'type': 'bot_command'}]}}
2025-02-13 16:23:11,463 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 23, 11, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=5, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=41, supergroup_chat_created=False, text='/help'), update_id=647682810)
2025-02-13 16:23:11,464 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'Here are the available commands:\n\n/start - Start the bot\n/help - Show this help message\n/clear - Clear conversation history\n/session - Set session duration\n/analyze - Analyze entire conversation history\n/context - Show current historical context'}`
2025-02-13 16:23:11,464 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:23:11,465 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:23:11,465 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:23:11,465 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:23:11,465 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:23:11,565 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:23:11 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'778'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:23:11,566 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:23:11,566 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:23:11,566 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:23:11,567 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:23:11,567 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:23:11,567 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 42, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460191, 'text': 'Here are the available commands:\n\n/start - Start the bot\n/help - Show this help message\n/clear - Clear conversation history\n/session - Set session duration\n/analyze - Analyze entire conversation history\n/context - Show current historical context', 'entities': [{'offset': 34, 'length': 6, 'type': 'bot_command'}, {'offset': 57, 'length': 5, 'type': 'bot_command'}, {'offset': 88, 'length': 6, 'type': 'bot_command'}, {'offset': 124, 'length': 8, 'type': 'bot_command'}, {'offset': 156, 'length': 8, 'type': 'bot_command'}, {'offset': 203, 'length': 8, 'type': 'bot_command'}]}`
2025-02-13 16:23:13,958 - __main__ - INFO - Received webhook: {'update_id': 647682811, 'message': {'message_id': 43, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460193, 'text': '/context', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 16:23:13,959 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 23, 13, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=43, supergroup_chat_created=False, text='/context'), update_id=647682811)
2025-02-13 16:23:13,960 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'No historical context available yet.'}`
2025-02-13 16:23:13,961 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:23:13,961 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:23:13,961 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:23:13,961 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:23:13,961 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:23:14,022 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:23:14 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'270'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:23:14,022 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:23:14,023 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:23:14,023 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:23:14,023 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:23:14,023 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:23:14,023 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 44, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460194, 'text': 'No historical context available yet.'}`
2025-02-13 16:23:58,471 - __main__ - INFO - Received webhook: {'update_id': 647682812, 'message': {'message_id': 45, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460238, 'text': 'my name is Nazar'}}
2025-02-13 16:23:58,474 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 23, 58, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=45, supergroup_chat_created=False, text='my name is Nazar'), update_id=647682812)
2025-02-13 16:23:58,474 - __main__ - INFO - Processing message: my name is Nazar
2025-02-13 16:23:58,479 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant with specific traits:\n            1. You maintain conversation history and context\n            2. You work in group of people, you know names of people you are talking to, you know relations between them\n            3. You know a lot of interesting facts about people you are talking to\n            4. You can analyze and summarize past conversations\n            5. You adapt your responses based on user preferences\n            6. You help with various tasks while maintaining a friendly tone\n            7. You remember important details about the user\n            \n            Important guidelines:\n            - Always reply in a language of the  user and remember his last language used for new conversation\n            - Keep responses concise but informative\n            - Use emojis occasionally to add warmth\n            - If context is unclear, politely ask for clarification\n            - Reference relevant past conversations when appropriate\n            '}, {'role': 'user', 'content': 'my name is Nazar'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:23:58,504 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:23:58,505 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:23:58,548 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10895be00>
2025-02-13 16:23:58,548 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10370cef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:23:58,575 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10894bd90>
2025-02-13 16:23:58,575 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:23:58,576 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:23:58,576 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:23:58,576 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:23:58,576 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:23:59,443 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:23:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'381'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199728'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'81ms'), (b'x-request-id', b'req_7f20ec5a96175faec86474be367647a4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Li6Y8bkkUjYKRHWT33uuK8IYu3XbFm2QgViHjLEbpNk-1739460239-1.0.1.1-6iR8aVxRjTzvbm_txX8xKAp9V98HVM2fY6NjEe2sK4znSGn4U1FQVzV0xVaVC1t9BS3OGDtS3wTFFBRvmf_q3g; path=/; expires=Thu, 13-Feb-25 15:53:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=XEsnf8i2ggSkJSKC4rQTI8s2w6zyMG5DDmUxCACBZkY-1739460239486-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115d29b8c69e091-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:23:59,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:23:59,446 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:23:59,447 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:23:59,447 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:23:59,447 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:23:59,447 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:23:59 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '381'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199728'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '81ms'), ('x-request-id', 'req_7f20ec5a96175faec86474be367647a4'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Li6Y8bkkUjYKRHWT33uuK8IYu3XbFm2QgViHjLEbpNk-1739460239-1.0.1.1-6iR8aVxRjTzvbm_txX8xKAp9V98HVM2fY6NjEe2sK4znSGn4U1FQVzV0xVaVC1t9BS3OGDtS3wTFFBRvmf_q3g; path=/; expires=Thu, 13-Feb-25 15:53:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=XEsnf8i2ggSkJSKC4rQTI8s2w6zyMG5DDmUxCACBZkY-1739460239486-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115d29b8c69e091-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:23:59,448 - openai._base_client - DEBUG - request_id: req_7f20ec5a96175faec86474be367647a4
2025-02-13 16:23:59,455 - __main__ - INFO - Got response: Hello Nazar! It's great to see you again. How can I assist you today? 
2025-02-13 16:23:59,455 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': "Hello Nazar! It's great to see you again. How can I assist you today? "}`
2025-02-13 16:23:59,456 - httpcore.connection - DEBUG - close.started
2025-02-13 16:23:59,457 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:23:59,457 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:23:59,497 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108a28380>
2025-02-13 16:23:59,497 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10370ec30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:23:59,534 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108a28490>
2025-02-13 16:23:59,534 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:23:59,535 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:23:59,535 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:23:59,535 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:23:59,535 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:23:59,598 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:23:59 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'316'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:23:59,598 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:23:59,599 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:23:59,599 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:23:59,599 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:23:59,599 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:23:59,599 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 46, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460239, 'text': "Hello Nazar! It's great to see you again. How can I assist you today? "}`
2025-02-13 16:24:07,126 - __main__ - INFO - Received webhook: {'update_id': 647682813, 'message': {'message_id': 47, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460247, 'text': 'Do you remember my name from history?'}}
2025-02-13 16:24:07,126 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 24, 7, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=47, supergroup_chat_created=False, text='Do you remember my name from history?'), update_id=647682813)
2025-02-13 16:24:07,126 - __main__ - INFO - Processing message: Do you remember my name from history?
2025-02-13 16:24:07,128 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant with specific traits:\n            1. You maintain conversation history and context\n            2. You work in group of people, you know names of people you are talking to, you know relations between them\n            3. You know a lot of interesting facts about people you are talking to\n            4. You can analyze and summarize past conversations\n            5. You adapt your responses based on user preferences\n            6. You help with various tasks while maintaining a friendly tone\n            7. You remember important details about the user\n            \n            Important guidelines:\n            - Always reply in a language of the  user and remember his last language used for new conversation\n            - Keep responses concise but informative\n            - Use emojis occasionally to add warmth\n            - If context is unclear, politely ask for clarification\n            - Reference relevant past conversations when appropriate\n            '}, {'role': 'user', 'content': 'Do you remember my name from history?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:24:07,129 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:24:07,129 - httpcore.connection - DEBUG - close.started
2025-02-13 16:24:07,129 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:24:07,129 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:24:07,148 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10894ac10>
2025-02-13 16:24:07,148 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10370cef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:24:07,170 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108913100>
2025-02-13 16:24:07,170 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:24:07,171 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:24:07,171 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:24:07,171 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:24:07,171 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:24:07,710 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:24:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'383'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199723'), (b'x-ratelimit-reset-requests', b'8.99s'), (b'x-ratelimit-reset-tokens', b'82ms'), (b'x-request-id', b'req_10d41563f7866668cfa2cb7f810e4b33'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115d2d13e44214e-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:24:07,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:24:07,712 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:24:07,713 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:24:07,714 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:24:07,714 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:24:07,714 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:24:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '383', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199723', 'x-ratelimit-reset-requests': '8.99s', 'x-ratelimit-reset-tokens': '82ms', 'x-request-id': 'req_10d41563f7866668cfa2cb7f810e4b33', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115d2d13e44214e-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:24:07,714 - openai._base_client - DEBUG - request_id: req_10d41563f7866668cfa2cb7f810e4b33
2025-02-13 16:24:07,715 - __main__ - INFO - Got response: Yes, your name is John. How can I assist you today, John?
2025-02-13 16:24:07,716 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'Yes, your name is John. How can I assist you today, John?'}`
2025-02-13 16:24:07,716 - httpcore.connection - DEBUG - close.started
2025-02-13 16:24:07,717 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:24:07,717 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:24:07,759 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1089d9e50>
2025-02-13 16:24:07,760 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10370ec30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:24:07,802 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1089da050>
2025-02-13 16:24:07,802 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:24:07,803 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:24:07,803 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:24:07,803 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:24:07,803 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:24:07,881 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:24:07 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'291'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:24:07,883 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:24:07,883 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:24:07,884 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:24:07,884 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:24:07,884 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:24:07,884 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 48, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460247, 'text': 'Yes, your name is John. How can I assist you today, John?'}`
2025-02-13 16:27:32,355 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:27:32,355 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:27:32,355 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:27:32,356 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:27:32,356 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:27:32,411 - httpcore.connection - DEBUG - close.started
2025-02-13 16:27:32,411 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:27:34,361 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:27:34,387 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:27:34,391 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:27:34,393 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:27:34,436 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105adb8c0>
2025-02-13 16:27:34,436 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596ecc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:27:34,478 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105aca210>
2025-02-13 16:27:34,479 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:27:34,479 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:27:34,479 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:27:34,479 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:27:34,479 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:27:34,521 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:27:34 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:27:34,521 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:27:34,521 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:27:34,521 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:27:34,521 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:27:34,522 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:27:34,522 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:27:34,522 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:27:34,522 - telegram.ext.Application - INFO - Application started
2025-02-13 16:27:34,522 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 16:27:34,522 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:27:34,523 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:27:34,523 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:27:34,523 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:27:34,523 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:27:34,727 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:27:34 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:27:34,728 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:27:34,728 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:27:34,728 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:27:34,728 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:27:34,729 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:27:34,729 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:27:42,257 - __main__ - INFO - Received webhook: {'update_id': 647682814, 'message': {'message_id': 49, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460462, 'text': '/start', 'entities': [{'offset': 0, 'length': 6, 'type': 'bot_command'}]}}
2025-02-13 16:27:42,258 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 27, 42, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=6, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=49, supergroup_chat_created=False, text='/start'), update_id=647682814)
2025-02-13 16:27:42,258 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': " Hello! I'm your AI assistant bot. I can help you with various tasks and maintain our conversation history.\n\nUse /help to see available commands."}`
2025-02-13 16:27:42,259 - httpcore.connection - DEBUG - close.started
2025-02-13 16:27:42,259 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:27:42,259 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:27:42,296 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105b5ce10>
2025-02-13 16:27:42,297 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596ecc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:27:42,339 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105a93100>
2025-02-13 16:27:42,340 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:27:42,340 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:27:42,340 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:27:42,341 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:27:42,341 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:27:42,519 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:27:42 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'453'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:27:42,520 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:27:42,520 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:27:42,520 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:27:42,520 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:27:42,520 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:27:42,521 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 50, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460462, 'text': " Hello! I'm your AI assistant bot. I can help you with various tasks and maintain our conversation history.\n\nUse /help to see available commands.", 'entities': [{'offset': 115, 'length': 5, 'type': 'bot_command'}]}`
2025-02-13 16:27:58,365 - __main__ - INFO - Received webhook: {'update_id': 647682815, 'message': {'message_id': 51, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460478, 'text': '  '}}
2025-02-13 16:27:58,366 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 27, 58, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=51, supergroup_chat_created=False, text='  '), update_id=647682815)
2025-02-13 16:27:58,366 - __main__ - INFO - Processing message:   
2025-02-13 16:27:58,370 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '...'}, {'role': 'user', 'content': '  '}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:27:58,390 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:27:58,391 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:27:58,436 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105adb8c0>
2025-02-13 16:27:58,436 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596cf80> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:27:58,458 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105acbc50>
2025-02-13 16:27:58,458 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:27:58,458 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:27:58,458 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:27:58,458 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:27:58,458 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:27:59,250 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:27:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'650'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199972'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2f9edd626c4443a593f08388218f722e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TwLGrYsHW5hS_FkLlSHPZz5Vv9fEQrxYVmHhjlOOTSI-1739460479-1.0.1.1-D0.MsRZeB0E5aDktOWZJZnV2P4WBuWQubbqKRZWpl0YhFe586Oeof6S8FAqqwXqUYEQemF2vFknXzwHhmxoE4g; path=/; expires=Thu, 13-Feb-25 15:57:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=S61ncchREJBcAQsfa4QpVatJSNg88IECRRJDvUS_aXU-1739460479294-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115d876ca6669fc-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:27:59,253 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:27:59,253 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:27:59,254 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:27:59,254 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:27:59,254 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:27:59,254 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:27:59 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '650'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199972'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_2f9edd626c4443a593f08388218f722e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=TwLGrYsHW5hS_FkLlSHPZz5Vv9fEQrxYVmHhjlOOTSI-1739460479-1.0.1.1-D0.MsRZeB0E5aDktOWZJZnV2P4WBuWQubbqKRZWpl0YhFe586Oeof6S8FAqqwXqUYEQemF2vFknXzwHhmxoE4g; path=/; expires=Thu, 13-Feb-25 15:57:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=S61ncchREJBcAQsfa4QpVatJSNg88IECRRJDvUS_aXU-1739460479294-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115d876ca6669fc-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:27:59,255 - openai._base_client - DEBUG - request_id: req_2f9edd626c4443a593f08388218f722e
2025-02-13 16:27:59,263 - __main__ - INFO - Got response: , !      ?
2025-02-13 16:27:59,264 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !      ?'}`
2025-02-13 16:27:59,265 - httpcore.connection - DEBUG - close.started
2025-02-13 16:27:59,265 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:27:59,266 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:27:59,309 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105b71a70>
2025-02-13 16:27:59,309 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596ecc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:27:59,353 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105ac4710>
2025-02-13 16:27:59,353 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:27:59,353 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:27:59,354 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:27:59,354 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:27:59,354 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:27:59,502 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:27:59 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'490'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:27:59,502 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:27:59,503 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:27:59,503 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:27:59,503 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:27:59,503 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:27:59,503 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 52, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460479, 'text': ', !      ?'}`
2025-02-13 16:28:03,916 - __main__ - INFO - Received webhook: {'update_id': 647682816, 'message': {'message_id': 53, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460483, 'text': '   ?'}}
2025-02-13 16:28:03,916 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 28, 3, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=53, supergroup_chat_created=False, text='   ?'), update_id=647682816)
2025-02-13 16:28:03,916 - __main__ - INFO - Processing message:    ?
2025-02-13 16:28:03,918 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '...'}, {'role': 'user', 'content': '   ?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:28:03,919 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:28:03,919 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:28:03,919 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:28:03,919 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:28:03,919 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:28:03,919 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:28:04,719 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:28:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'653'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199973'), (b'x-ratelimit-reset-requests', b'11.828s'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_a0d293f2188d1e204127cc6c64794d56'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115d898edac69fc-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:28:04,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:28:04,722 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:28:04,722 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:28:04,722 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:28:04,722 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:28:04,723 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:28:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '653', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199973', 'x-ratelimit-reset-requests': '11.828s', 'x-ratelimit-reset-tokens': '7ms', 'x-request-id': 'req_a0d293f2188d1e204127cc6c64794d56', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115d898edac69fc-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:28:04,723 - openai._base_client - DEBUG - request_id: req_a0d293f2188d1e204127cc6c64794d56
2025-02-13 16:28:04,727 - __main__ - INFO - Got response: ,      ,       .      ?
2025-02-13 16:28:04,727 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ',      ,       .      ?'}`
2025-02-13 16:28:04,728 - httpcore.connection - DEBUG - close.started
2025-02-13 16:28:04,728 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:28:04,729 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:28:04,769 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105a67ac0>
2025-02-13 16:28:04,771 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596ecc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:28:04,820 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105a67bd0>
2025-02-13 16:28:04,820 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:28:04,820 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:28:04,821 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:28:04,821 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:28:04,821 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:28:04,888 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:28:04 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'773'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:28:04,888 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:28:04,888 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:28:04,888 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:28:04,889 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:28:04,889 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:28:04,889 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 54, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460484, 'text': ',      ,       .      ?'}`
2025-02-13 16:28:11,235 - __main__ - INFO - Received webhook: {'update_id': 647682817, 'message': {'message_id': 55, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460491, 'text': '/context', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 16:28:11,236 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 28, 11, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=55, supergroup_chat_created=False, text='/context'), update_id=647682817)
2025-02-13 16:28:11,236 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'No historical context available yet.'}`
2025-02-13 16:28:11,237 - httpcore.connection - DEBUG - close.started
2025-02-13 16:28:11,237 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:28:11,237 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:28:11,282 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105b58e50>
2025-02-13 16:28:11,282 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596ecc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:28:11,342 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105b58950>
2025-02-13 16:28:11,343 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:28:11,344 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:28:11,344 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:28:11,344 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:28:11,344 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:28:11,516 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:28:11 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'270'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:28:11,516 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:28:11,516 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:28:11,517 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:28:11,517 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:28:11,517 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:28:11,517 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 56, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460491, 'text': 'No historical context available yet.'}`
2025-02-13 16:28:22,131 - __main__ - INFO - Received webhook: {'update_id': 647682818, 'message': {'message_id': 57, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460502, 'text': '  '}}
2025-02-13 16:28:22,132 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 28, 22, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=57, supergroup_chat_created=False, text='  '), update_id=647682818)
2025-02-13 16:28:22,132 - __main__ - INFO - Processing message:   
2025-02-13 16:28:22,136 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '...'}, {'role': 'user', 'content': '  '}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:28:22,136 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:28:22,136 - httpcore.connection - DEBUG - close.started
2025-02-13 16:28:22,137 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:28:22,137 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:28:22,155 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105acbed0>
2025-02-13 16:28:22,156 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596cf80> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:28:22,190 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105b73820>
2025-02-13 16:28:22,190 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:28:22,191 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:28:22,191 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:28:22,191 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:28:22,191 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:28:22,974 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:28:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'500'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199972'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_b7e518492b2d598d28ae7a81b73c8a9f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115d90b19fa60d0-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:28:22,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:28:22,975 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:28:22,976 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:28:22,977 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:28:22,977 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:28:22,977 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:28:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '500', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199972', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_b7e518492b2d598d28ae7a81b73c8a9f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115d90b19fa60d0-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:28:22,978 - openai._base_client - DEBUG - request_id: req_b7e518492b2d598d28ae7a81b73c8a9f
2025-02-13 16:28:22,981 - __main__ - INFO - Got response:  , !   ?
2025-02-13 16:28:22,981 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ' , !   ?'}`
2025-02-13 16:28:22,982 - httpcore.connection - DEBUG - close.started
2025-02-13 16:28:22,990 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:28:22,990 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:28:23,031 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105ac1b80>
2025-02-13 16:28:23,031 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596ecc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:28:23,076 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105ac35c0>
2025-02-13 16:28:23,077 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:28:23,078 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:28:23,078 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:28:23,078 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:28:23,078 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:28:23,199 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:28:23 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'470'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:28:23,199 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:28:23,199 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:28:23,200 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:28:23,200 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:28:23,200 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:28:23,200 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 58, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460503, 'text': ' , !   ?'}`
2025-02-13 16:28:29,878 - __main__ - INFO - Received webhook: {'update_id': 647682819, 'message': {'message_id': 59, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460509, 'text': '  ?'}}
2025-02-13 16:28:29,878 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 28, 29, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=59, supergroup_chat_created=False, text='  ?'), update_id=647682819)
2025-02-13 16:28:29,878 - __main__ - INFO - Processing message:   ?
2025-02-13 16:28:29,880 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '...'}, {'role': 'user', 'content': '  ?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:28:29,881 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:28:29,881 - httpcore.connection - DEBUG - close.started
2025-02-13 16:28:29,881 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:28:29,881 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:28:29,903 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105a93a80>
2025-02-13 16:28:29,903 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596cf80> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:28:29,932 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105e24b90>
2025-02-13 16:28:29,932 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:28:29,933 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:28:29,933 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:28:29,933 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:28:29,933 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:28:30,623 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:28:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'434'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199973'), (b'x-ratelimit-reset-requests', b'9.562s'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_fc0e5d52308be2c41cefcf23aa341fb6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115d93b792c2184-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:28:30,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:28:30,625 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:28:30,659 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:28:30,660 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:28:30,660 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:28:30,660 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:28:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '434', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199973', 'x-ratelimit-reset-requests': '9.562s', 'x-ratelimit-reset-tokens': '7ms', 'x-request-id': 'req_fc0e5d52308be2c41cefcf23aa341fb6', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115d93b792c2184-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:28:30,660 - openai._base_client - DEBUG - request_id: req_fc0e5d52308be2c41cefcf23aa341fb6
2025-02-13 16:28:30,664 - __main__ - INFO - Got response: ,      .  ?
2025-02-13 16:28:30,665 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ',      .  ?'}`
2025-02-13 16:28:30,666 - httpcore.connection - DEBUG - close.started
2025-02-13 16:28:30,666 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:28:30,666 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:28:30,716 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105b1b4d0>
2025-02-13 16:28:30,717 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10596ecc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:28:30,763 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105b1b5b0>
2025-02-13 16:28:30,764 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:28:30,764 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:28:30,765 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:28:30,765 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:28:30,765 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:28:30,883 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:28:30 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'461'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:28:30,883 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:28:30,883 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:28:30,884 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:28:30,884 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:28:30,884 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:28:30,884 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 60, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460510, 'text': ',      .  ?'}`
2025-02-13 16:33:30,538 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:33:30,539 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:33:30,539 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:33:30,539 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:33:30,539 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:33:30,598 - httpcore.connection - DEBUG - close.started
2025-02-13 16:33:30,598 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:33:48,234 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:33:48,260 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:33:48,263 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:33:48,266 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:33:48,338 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f3f8c0>
2025-02-13 16:33:48,338 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd2cc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:33:48,382 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f2e210>
2025-02-13 16:33:48,383 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:33:48,383 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:33:48,383 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:33:48,383 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:33:48,383 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:33:48,430 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:33:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:33:48,430 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:33:48,430 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:33:48,430 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:33:48,430 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:33:48,430 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:33:48,431 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:33:48,431 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:33:48,431 - telegram.ext.Application - INFO - Application started
2025-02-13 16:33:48,431 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 16:33:48,431 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:33:48,432 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:33:48,432 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:33:48,432 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:33:48,432 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:33:48,566 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:33:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:33:48,567 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:33:48,567 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:33:48,568 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:33:48,568 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:33:48,568 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:33:48,568 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:33:48,573 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze the entire conversation history and create a comprehensive summary. \n                    Focus on:\n                    1. Key recurring topics\n                    2. Who are group of people you are talking to\n                    3. People names, life facts, relations between each other, etc.\n                    4. Important facts or preferences mentioned\n                    5. Significant decisions or conclusions\n                    6. User's behavioral patterns or preferences\n                    Format the output as a structured list of important points."}, {'role': 'user', 'content': 'user:   \nassistant: , !      ?\nuser:    ?\nassistant: ,      ,       .      ?\nuser:   \nassistant:  , !   ?\nuser:   ?\nassistant: ,      .  ?'}], 'model': 'gpt-4'}}
2025-02-13 16:33:48,598 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:33:48,599 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:33:48,645 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103f99160>
2025-02-13 16:33:48,645 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd0dd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:33:48,666 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103f2fc50>
2025-02-13 16:33:48,666 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:33:48,667 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:33:48,667 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:33:48,667 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:33:48,667 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:00,591 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:34:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'11726'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9678'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'1.932s'), (b'x-request-id', b'req_e22597279abe104c873bd37e74d30d12'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EzRGnJ4p7HKSC.TZdL7TTXzf5lzPHuRt_w3Wisge5Q8-1739460840-1.0.1.1-d2HS3laj8_MUu8eVuKngW.9D.BIDQWP65da0tve9vYvCfjTWJNbN5RuL7wiACiMoAip4DQOChWcqQ__KY1nCGA; path=/; expires=Thu, 13-Feb-25 16:04:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=gWVDFf3IU1wwtfMEeue84Zj6TTNITvCy37Eypk_.bIA-1739460840588-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115e1036965cbdb-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:34:00,596 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:34:00,596 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:00,597 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:00,597 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:00,597 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:00,597 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:34:00 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '11726'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9678'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '1.932s'), ('x-request-id', 'req_e22597279abe104c873bd37e74d30d12'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=EzRGnJ4p7HKSC.TZdL7TTXzf5lzPHuRt_w3Wisge5Q8-1739460840-1.0.1.1-d2HS3laj8_MUu8eVuKngW.9D.BIDQWP65da0tve9vYvCfjTWJNbN5RuL7wiACiMoAip4DQOChWcqQ__KY1nCGA; path=/; expires=Thu, 13-Feb-25 16:04:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=gWVDFf3IU1wwtfMEeue84Zj6TTNITvCy37Eypk_.bIA-1739460840588-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115e1036965cbdb-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:34:00,598 - openai._base_client - DEBUG - request_id: req_e22597279abe104c873bd37e74d30d12
2025-02-13 16:34:14,120 - __main__ - INFO - Received webhook: {'update_id': 647682820, 'message': {'message_id': 61, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460854, 'text': ''}}
2025-02-13 16:34:14,121 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 34, 14, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=61, supergroup_chat_created=False, text=''), update_id=647682820)
2025-02-13 16:34:14,121 - __main__ - INFO - Processing message: 
2025-02-13 16:34:14,127 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful AI assistant with memory capabilities.\n            Important context about our conversation history:\n            1. Key recurring topics: The primary topic of the conversation is about the user\'s identity. The user has shared his name multiple times, but the assistant seems to have issues with retaining this information.\n2. Who are group of people you are talking to: The assistant is speaking with an individual user who identifies himself with two different names.\n3. People names, life facts, relations between each other, etc.: The user initially introduced himself as "," and later as "." There are no other relations, life facts, or individuals mentioned in the conversation.\n4. Important facts or preferences mentioned: The user has made it clear that he values being recognized by his name, as indicated by his repeated questions about his name. \n5. Significant decisions or conclusions: No decisions or conclusions have been made in this conversation.\n6. User\'s behavioral patterns or preferences: The user seems to be testing the assistant\'s memory or functionality, as he repetitively asks for confirmation of his name.\n            \n            Guidelines:\n            - Remember and use people\'s names and preferences\n            - Always respond in the same language as the user\'s message\n            - Keep track of important information shared in conversation\n            - If you learn someone\'s name, use it in future responses\n            - Be friendly and personable while maintaining professionalism\n            '}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:34:14,128 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:34:14,128 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:34:14,146 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103fd47d0>
2025-02-13 16:34:14,146 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd0f80> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:34:14,169 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x109220180>
2025-02-13 16:34:14,170 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:34:14,170 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:34:14,170 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:34:14,171 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:34:14,171 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:14,928 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:34:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'561'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199436'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'169ms'), (b'x-request-id', b'req_c75894570ef22dec432d35bbf06ff235'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=f06V_VwVQ8bGG7GRuXJzxJbFA5Y1khGhUSyeqKz7C0g-1739460854-1.0.1.1-Y4ixjL.y2LGXJIm3eCrDhuTii8LpMBXaX5floBU6oHtu19dI4uGiEtMY6en1tdPnk3aWmzlWK.2amH_eMmJbbQ; path=/; expires=Thu, 13-Feb-25 16:04:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=coY.HxuQXxfCqVlgCYbpAkXaQpHUjpIVzFJPVZFxh8M-1739460854905-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115e1a2dc9ecfeb-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:34:14,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:34:14,929 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:14,929 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:14,929 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:14,929 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:14,929 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:34:14 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '561'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199436'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '169ms'), ('x-request-id', 'req_c75894570ef22dec432d35bbf06ff235'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=f06V_VwVQ8bGG7GRuXJzxJbFA5Y1khGhUSyeqKz7C0g-1739460854-1.0.1.1-Y4ixjL.y2LGXJIm3eCrDhuTii8LpMBXaX5floBU6oHtu19dI4uGiEtMY6en1tdPnk3aWmzlWK.2amH_eMmJbbQ; path=/; expires=Thu, 13-Feb-25 16:04:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=coY.HxuQXxfCqVlgCYbpAkXaQpHUjpIVzFJPVZFxh8M-1739460854905-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115e1a2dc9ecfeb-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:34:14,930 - openai._base_client - DEBUG - request_id: req_c75894570ef22dec432d35bbf06ff235
2025-02-13 16:34:14,931 - __main__ - INFO - Got response:   , !     ?
2025-02-13 16:34:14,931 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '  , !     ?'}`
2025-02-13 16:34:14,932 - httpcore.connection - DEBUG - close.started
2025-02-13 16:34:14,932 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:34:14,932 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:34:14,977 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103fd5d10>
2025-02-13 16:34:14,978 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd2cc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:34:15,031 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109221350>
2025-02-13 16:34:15,031 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:34:15,032 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:34:15,032 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:34:15,032 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:34:15,033 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:15,129 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:34:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'545'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:34:15,130 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:34:15,130 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:15,130 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:15,130 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:15,130 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:15,131 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 62, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460855, 'text': '  , !     ?'}`
2025-02-13 16:34:18,833 - __main__ - INFO - Received webhook: {'update_id': 647682821, 'message': {'message_id': 63, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460858, 'text': '  ?'}}
2025-02-13 16:34:18,833 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 34, 18, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=63, supergroup_chat_created=False, text='  ?'), update_id=647682821)
2025-02-13 16:34:18,833 - __main__ - INFO - Processing message:   ?
2025-02-13 16:34:18,846 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful AI assistant with memory capabilities.\n            Important context about our conversation history:\n            1. Key recurring topics: The primary topic of the conversation is about the user\'s identity. The user has shared his name multiple times, but the assistant seems to have issues with retaining this information.\n2. Who are group of people you are talking to: The assistant is speaking with an individual user who identifies himself with two different names.\n3. People names, life facts, relations between each other, etc.: The user initially introduced himself as "," and later as "." There are no other relations, life facts, or individuals mentioned in the conversation.\n4. Important facts or preferences mentioned: The user has made it clear that he values being recognized by his name, as indicated by his repeated questions about his name. \n5. Significant decisions or conclusions: No decisions or conclusions have been made in this conversation.\n6. User\'s behavioral patterns or preferences: The user seems to be testing the assistant\'s memory or functionality, as he repetitively asks for confirmation of his name.\n            \n            Guidelines:\n            - Remember and use people\'s names and preferences\n            - Always respond in the same language as the user\'s message\n            - Keep track of important information shared in conversation\n            - If you learn someone\'s name, use it in future responses\n            - Be friendly and personable while maintaining professionalism\n            '}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '  ?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:34:18,847 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:34:18,847 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:34:18,847 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:34:18,847 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:34:18,847 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:34:18,847 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:19,036 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:34:19 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199430'), (b'x-ratelimit-reset-requests', b'12.591s'), (b'x-ratelimit-reset-tokens', b'171ms'), (b'x-request-id', b'req_94d175a46c9bfb302e9bb4d28be4e6bb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115e1c009e7cfeb-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:34:19,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:34:19,038 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:19,038 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:19,038 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:19,038 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:19,039 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers({'date': 'Thu, 13 Feb 2025 15:34:19 GMT', 'content-type': 'application/json', 'content-length': '251', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '21', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199430', 'x-ratelimit-reset-requests': '12.591s', 'x-ratelimit-reset-tokens': '171ms', 'x-request-id': 'req_94d175a46c9bfb302e9bb4d28be4e6bb', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115e1c009e7cfeb-MAD', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:34:19,039 - openai._base_client - DEBUG - request_id: req_94d175a46c9bfb302e9bb4d28be4e6bb
2025-02-13 16:34:19,039 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:34:19,044 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:34:19,044 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:34:19,044 - __main__ - ERROR - Error in message handler: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 114, in message_handler
    response = await get_chat_response(user_input)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 82, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:34:19,050 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'An error occurred while processing your message.'}`
2025-02-13 16:34:19,051 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:34:19,052 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:34:19,052 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:34:19,052 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:34:19,052 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:19,230 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:34:19 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'282'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:34:19,231 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:34:19,231 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:19,232 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:19,233 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:19,233 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:19,233 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 64, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460859, 'text': 'An error occurred while processing your message.'}`
2025-02-13 16:34:25,859 - __main__ - INFO - Received webhook: {'update_id': 647682822, 'message': {'message_id': 65, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460865, 'text': '  ?'}}
2025-02-13 16:34:25,859 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 34, 25, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=65, supergroup_chat_created=False, text='  ?'), update_id=647682822)
2025-02-13 16:34:25,859 - __main__ - INFO - Processing message:   ?
2025-02-13 16:34:25,865 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful AI assistant with memory capabilities.\n            Important context about our conversation history:\n            1. Key recurring topics: The primary topic of the conversation is about the user\'s identity. The user has shared his name multiple times, but the assistant seems to have issues with retaining this information.\n2. Who are group of people you are talking to: The assistant is speaking with an individual user who identifies himself with two different names.\n3. People names, life facts, relations between each other, etc.: The user initially introduced himself as "," and later as "." There are no other relations, life facts, or individuals mentioned in the conversation.\n4. Important facts or preferences mentioned: The user has made it clear that he values being recognized by his name, as indicated by his repeated questions about his name. \n5. Significant decisions or conclusions: No decisions or conclusions have been made in this conversation.\n6. User\'s behavioral patterns or preferences: The user seems to be testing the assistant\'s memory or functionality, as he repetitively asks for confirmation of his name.\n            \n            Guidelines:\n            - Remember and use people\'s names and preferences\n            - Always respond in the same language as the user\'s message\n            - Keep track of important information shared in conversation\n            - If you learn someone\'s name, use it in future responses\n            - Be friendly and personable while maintaining professionalism\n            '}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '  ?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:34:25,865 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:34:25,866 - httpcore.connection - DEBUG - close.started
2025-02-13 16:34:25,866 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:34:25,866 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:34:25,887 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x109220770>
2025-02-13 16:34:25,888 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd0f80> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:34:25,915 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x109230dd0>
2025-02-13 16:34:25,915 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:34:25,916 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:34:25,916 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:34:25,916 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:34:25,916 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:26,317 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:34:26 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'x-request-id', b'req_80ad507e5716511a3422d10ac6d5d040'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115e1ec3bd03154-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:34:26,319 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:34:26,320 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:26,320 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:26,320 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:26,320 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:26,320 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers({'date': 'Thu, 13 Feb 2025 15:34:26 GMT', 'content-type': 'application/json', 'content-length': '251', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '21', 'openai-version': '2020-10-01', 'x-request-id': 'req_80ad507e5716511a3422d10ac6d5d040', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115e1ec3bd03154-MAD', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:34:26,321 - openai._base_client - DEBUG - request_id: req_80ad507e5716511a3422d10ac6d5d040
2025-02-13 16:34:26,321 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:34:26,322 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:34:26,322 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:34:26,322 - __main__ - ERROR - Error in message handler: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 114, in message_handler
    response = await get_chat_response(user_input)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 82, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:34:26,326 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'An error occurred while processing your message.'}`
2025-02-13 16:34:26,327 - httpcore.connection - DEBUG - close.started
2025-02-13 16:34:26,327 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:34:26,327 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:34:26,372 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103ef7bb0>
2025-02-13 16:34:26,372 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd2cc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:34:26,417 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f27bf0>
2025-02-13 16:34:26,418 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:34:26,418 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:34:26,419 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:34:26,419 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:34:26,419 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:26,595 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:34:26 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'282'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:34:26,598 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:34:26,600 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:26,600 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:26,601 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:26,601 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:26,601 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 66, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460866, 'text': 'An error occurred while processing your message.'}`
2025-02-13 16:34:30,525 - __main__ - INFO - Received webhook: {'update_id': 647682823, 'message': {'message_id': 67, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460870, 'text': '/context', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 16:34:30,526 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 34, 30, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=67, supergroup_chat_created=False, text='/context'), update_id=647682823)
2025-02-13 16:34:30,527 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ' Historical Context:\n\n 2025-02-13T16:34\n1. Key recurring topics: The primary topic of the conversation is about the user\'s identity. The user has shared his name multiple times, but the assistant seems to have issues with retaining this information.\n2. Who are group of people you are talking to: The assistant is speaking with an individual user who identifies himself with two different names.\n3. People names, life facts, relations between each other, etc.: The user initially introduced himself as "," and later as "." There are no other relations, life facts, or individuals mentioned in the conversation.\n4. Important facts or preferences mentioned: The user has made it clear that he values being recognized by his name, as indicated by his repeated questions about his name. \n5. Significant decisions or conclusions: No decisions or conclusions have been made in this conversation.\n6. User\'s behavioral patterns or preferences: The user seems to be testing the assistant\'s memory or functionality, as he repetitively asks for confirmation of his name.\n\n'}`
2025-02-13 16:34:30,528 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:34:30,529 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:34:30,529 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:34:30,529 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:34:30,529 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:30,628 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:34:30 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1389'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:34:30,629 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:34:30,629 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:30,629 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:30,629 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:30,629 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:30,629 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 68, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460870, 'text': ' Historical Context:\n\n 2025-02-13T16:34\n1. Key recurring topics: The primary topic of the conversation is about the user\'s identity. The user has shared his name multiple times, but the assistant seems to have issues with retaining this information.\n2. Who are group of people you are talking to: The assistant is speaking with an individual user who identifies himself with two different names.\n3. People names, life facts, relations between each other, etc.: The user initially introduced himself as "," and later as "." There are no other relations, life facts, or individuals mentioned in the conversation.\n4. Important facts or preferences mentioned: The user has made it clear that he values being recognized by his name, as indicated by his repeated questions about his name. \n5. Significant decisions or conclusions: No decisions or conclusions have been made in this conversation.\n6. User\'s behavioral patterns or preferences: The user seems to be testing the assistant\'s memory or functionality, as he repetitively asks for confirmation of his name.'}`
2025-02-13 16:34:58,468 - __main__ - INFO - Received webhook: {'update_id': 647682824, 'message': {'message_id': 69, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460898, 'text': '   ,       ,.'}}
2025-02-13 16:34:58,469 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 34, 58, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=69, supergroup_chat_created=False, text='   ,       ,.'), update_id=647682824)
2025-02-13 16:34:58,469 - __main__ - INFO - Processing message:    ,       ,.
2025-02-13 16:34:58,476 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful AI assistant with memory capabilities.\n            Important context about our conversation history:\n            1. Key recurring topics: The primary topic of the conversation is about the user\'s identity. The user has shared his name multiple times, but the assistant seems to have issues with retaining this information.\n2. Who are group of people you are talking to: The assistant is speaking with an individual user who identifies himself with two different names.\n3. People names, life facts, relations between each other, etc.: The user initially introduced himself as "," and later as "." There are no other relations, life facts, or individuals mentioned in the conversation.\n4. Important facts or preferences mentioned: The user has made it clear that he values being recognized by his name, as indicated by his repeated questions about his name. \n5. Significant decisions or conclusions: No decisions or conclusions have been made in this conversation.\n6. User\'s behavioral patterns or preferences: The user seems to be testing the assistant\'s memory or functionality, as he repetitively asks for confirmation of his name.\n            \n            Guidelines:\n            - Remember and use people\'s names and preferences\n            - Always respond in the same language as the user\'s message\n            - Keep track of important information shared in conversation\n            - If you learn someone\'s name, use it in future responses\n            - Be friendly and personable while maintaining professionalism\n            '}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '   ,       ,.'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:34:58,476 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:34:58,476 - httpcore.connection - DEBUG - close.started
2025-02-13 16:34:58,476 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:34:58,476 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:34:58,523 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1092bc270>
2025-02-13 16:34:58,523 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd0f80> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:34:58,545 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1092bc160>
2025-02-13 16:34:58,545 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:34:58,546 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:34:58,546 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:34:58,546 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:34:58,546 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:58,826 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:34:58 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'66'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199406'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'178ms'), (b'x-request-id', b'req_29186e820b18b2ea084887381a6fb01f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115e2b82ab769ee-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:34:58,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:34:58,834 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:58,835 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:58,835 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:58,835 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:58,835 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers({'date': 'Thu, 13 Feb 2025 15:34:58 GMT', 'content-type': 'application/json', 'content-length': '251', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '66', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199406', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '178ms', 'x-request-id': 'req_29186e820b18b2ea084887381a6fb01f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115e2b82ab769ee-MAD', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:34:58,835 - openai._base_client - DEBUG - request_id: req_29186e820b18b2ea084887381a6fb01f
2025-02-13 16:34:58,835 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:34:58,836 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:34:58,836 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:34:58,837 - __main__ - ERROR - Error in message handler: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 114, in message_handler
    response = await get_chat_response(user_input)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 82, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:34:58,841 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'An error occurred while processing your message.'}`
2025-02-13 16:34:58,841 - httpcore.connection - DEBUG - close.started
2025-02-13 16:34:58,842 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:34:58,842 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:34:58,890 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1092bcd10>
2025-02-13 16:34:58,891 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd2cc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:34:58,945 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1092bce20>
2025-02-13 16:34:58,945 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:34:58,946 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:34:58,946 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:34:58,946 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:34:58,946 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:34:59,088 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:34:59 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'282'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:34:59,093 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:34:59,094 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:34:59,094 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:34:59,094 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:34:59,095 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:34:59,095 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 70, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460899, 'text': 'An error occurred while processing your message.'}`
2025-02-13 16:35:04,746 - __main__ - INFO - Received webhook: {'update_id': 647682825, 'message': {'message_id': 71, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460904, 'text': '  ?'}}
2025-02-13 16:35:04,747 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 35, 4, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=71, supergroup_chat_created=False, text='  ?'), update_id=647682825)
2025-02-13 16:35:04,747 - __main__ - INFO - Processing message:   ?
2025-02-13 16:35:04,757 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful AI assistant with memory capabilities.\n            Important context about our conversation history:\n            1. Key recurring topics: The primary topic of the conversation is about the user\'s identity. The user has shared his name multiple times, but the assistant seems to have issues with retaining this information.\n2. Who are group of people you are talking to: The assistant is speaking with an individual user who identifies himself with two different names.\n3. People names, life facts, relations between each other, etc.: The user initially introduced himself as "," and later as "." There are no other relations, life facts, or individuals mentioned in the conversation.\n4. Important facts or preferences mentioned: The user has made it clear that he values being recognized by his name, as indicated by his repeated questions about his name. \n5. Significant decisions or conclusions: No decisions or conclusions have been made in this conversation.\n6. User\'s behavioral patterns or preferences: The user seems to be testing the assistant\'s memory or functionality, as he repetitively asks for confirmation of his name.\n            \n            Guidelines:\n            - Remember and use people\'s names and preferences\n            - Always respond in the same language as the user\'s message\n            - Keep track of important information shared in conversation\n            - If you learn someone\'s name, use it in future responses\n            - Be friendly and personable while maintaining professionalism\n            '}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '  ?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:35:04,758 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:35:04,759 - httpcore.connection - DEBUG - close.started
2025-02-13 16:35:04,759 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:35:04,759 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:35:04,797 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103fad950>
2025-02-13 16:35:04,797 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd0f80> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:35:04,820 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103fad850>
2025-02-13 16:35:04,821 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:35:04,821 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:35:04,821 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:35:04,821 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:35:04,821 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:35:05,031 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:35:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'24'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199430'), (b'x-ratelimit-reset-requests', b'10.932s'), (b'x-ratelimit-reset-tokens', b'171ms'), (b'x-request-id', b'req_ae39431c3ba21f3883820b5b781e5bc4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115e2df6a102fab-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:35:05,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:35:05,032 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:35:05,032 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:35:05,032 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:35:05,032 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:35:05,032 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers({'date': 'Thu, 13 Feb 2025 15:35:05 GMT', 'content-type': 'application/json', 'content-length': '251', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '24', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199430', 'x-ratelimit-reset-requests': '10.932s', 'x-ratelimit-reset-tokens': '171ms', 'x-request-id': 'req_ae39431c3ba21f3883820b5b781e5bc4', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115e2df6a102fab-MAD', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:35:05,032 - openai._base_client - DEBUG - request_id: req_ae39431c3ba21f3883820b5b781e5bc4
2025-02-13 16:35:05,032 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:35:05,033 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:35:05,033 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:35:05,034 - __main__ - ERROR - Error in message handler: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 114, in message_handler
    response = await get_chat_response(user_input)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 82, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:35:05,036 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'An error occurred while processing your message.'}`
2025-02-13 16:35:05,037 - httpcore.connection - DEBUG - close.started
2025-02-13 16:35:05,037 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:35:05,037 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:35:05,075 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103fae650>
2025-02-13 16:35:05,076 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103dd2cc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:35:05,118 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103fae550>
2025-02-13 16:35:05,118 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:35:05,119 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:35:05,119 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:35:05,119 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:35:05,119 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:35:05,184 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:35:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'282'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:35:05,186 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:35:05,188 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:35:05,188 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:35:05,188 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:35:05,189 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:35:05,189 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 72, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739460905, 'text': 'An error occurred while processing your message.'}`
2025-02-13 16:43:17,332 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:43:17,334 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:43:17,334 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:43:17,334 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:43:17,334 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:43:17,406 - httpcore.connection - DEBUG - close.started
2025-02-13 16:43:17,406 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:43:17,406 - httpcore.connection - DEBUG - close.started
2025-02-13 16:43:17,407 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:43:19,097 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:43:19,124 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:43:19,127 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:43:19,131 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:43:19,197 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083cb8c0>
2025-02-13 16:43:19,197 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108262c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:43:19,236 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083ba210>
2025-02-13 16:43:19,236 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:43:19,236 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:43:19,236 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:43:19,236 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:43:19,236 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:43:19,273 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:43:19 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:43:19,273 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:43:19,273 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:43:19,273 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:43:19,274 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:43:19,274 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:43:19,274 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:43:19,274 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:43:19,274 - telegram.ext.Application - INFO - Application started
2025-02-13 16:43:19,274 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 16:43:19,275 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:43:19,275 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:43:19,275 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:43:19,275 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:43:19,275 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:43:19,567 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:43:19 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:43:19,568 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:43:19,568 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:43:19,568 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:43:19,568 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:43:19,569 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:43:19,569 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:43:19,575 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze the entire conversation history and create a comprehensive summary. \n                    Focus on:\n                    1. Key recurring topics\n                    2. Who are group of people you are talking to\n                    3. People names, life facts, relations between each other, etc.\n                    4. Important facts or preferences mentioned\n                    5. Significant decisions or conclusions\n                    6. User's behavioral patterns or preferences\n                    Format the output as a structured list of important points."}, {'role': 'user', 'content': "user:   \nassistant: , !      ?\nuser:    ?\nassistant: ,      ,       .      ?\nuser:   \nassistant:  , !   ?\nuser:   ?\nassistant: ,      .  ?\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': '  , !     ?'}"}], 'model': 'gpt-4'}}
2025-02-13 16:43:19,602 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:43:19,602 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:43:19,645 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108425160>
2025-02-13 16:43:19,645 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108260d40> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:43:19,667 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1083bbc50>
2025-02-13 16:43:19,667 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:43:19,668 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:43:19,668 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:43:19,668 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:43:19,668 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:43:26,057 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:43:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'6081'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9627'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'2.238s'), (b'x-request-id', b'req_0733015468fce3770c1975c0cf299d6e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4jTjAMii1wYsqB98S8rJ7W9FKdm7KKx0NljzcCvZVRE-1739461406-1.0.1.1-JdhVLQBDaUb4IckEiY1E6l_IgALI1PesrijMbKSzknYeyjzFYyN.5KkYBbvjN1EVl4mrkDSu_mF0xZYrC4cCQg; path=/; expires=Thu, 13-Feb-25 16:13:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=4dN3JtFRI91in8twWZSs2VMWB1r1FJMmRccfQgNuWec-1739461406075-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115eef4297760c6-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:43:26,058 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:43:26,059 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:43:26,067 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:43:26,068 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:43:26,068 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:43:26,068 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:43:26 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '6081'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9627'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '2.238s'), ('x-request-id', 'req_0733015468fce3770c1975c0cf299d6e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=4jTjAMii1wYsqB98S8rJ7W9FKdm7KKx0NljzcCvZVRE-1739461406-1.0.1.1-JdhVLQBDaUb4IckEiY1E6l_IgALI1PesrijMbKSzknYeyjzFYyN.5KkYBbvjN1EVl4mrkDSu_mF0xZYrC4cCQg; path=/; expires=Thu, 13-Feb-25 16:13:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=4dN3JtFRI91in8twWZSs2VMWB1r1FJMmRccfQgNuWec-1739461406075-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115eef4297760c6-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:43:26,068 - openai._base_client - DEBUG - request_id: req_0733015468fce3770c1975c0cf299d6e
2025-02-13 16:43:33,580 - __main__ - INFO - Received webhook: {'update_id': 647682826, 'message': {'message_id': 73, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461413, 'text': '!'}}
2025-02-13 16:43:33,588 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The main topic of the conversation was the user's name.\n2. The group of people to whom the AI is being interacting with, is a single individual.\n3. The user first introduced himself as 'Gashish', then later as 'Nazar'.\n4. No important facts or preferences were mentioned.\n5. There were no significant decisions or conclusions made. \n6. The user seemed to be testing the assistant's ability to recognize and remember their name.\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '!'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:43:33,588 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:43:33,589 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:43:33,610 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108460410>
2025-02-13 16:43:33,610 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108260ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:43:33,637 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10848c3e0>
2025-02-13 16:43:33,638 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:43:33,638 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:43:33,638 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:43:33,638 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:43:33,638 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:43:33,819 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:43:33 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199573'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'127ms'), (b'x-request-id', b'req_9daf86b191cfb8d756f17dbe176eea16'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=KsdZrtbdfonH.ptOa24E_eIJ3fdq8UGmBUA2e_PgUHc-1739461413-1.0.1.1-MsNZx7jZ3fTtY3YZWjAFjYGaIHL92dD5V_wqEuU9uyUV7IsgWeqvi0nrG80U.PlGaEd5YggoR2KaGMf4LFNskA; path=/; expires=Thu, 13-Feb-25 16:13:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=iLvgOcwTe5nBiqjlBWCxm29hdH_nH8ay8Au6Cx3yAs4-1739461413832-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115ef4b790f1bad-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:43:33,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:43:33,821 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:43:33,822 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:43:33,822 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:43:33,823 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:43:33,823 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers([('date', 'Thu, 13 Feb 2025 15:43:33 GMT'), ('content-type', 'application/json'), ('content-length', '251'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '21'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199573'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '127ms'), ('x-request-id', 'req_9daf86b191cfb8d756f17dbe176eea16'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=KsdZrtbdfonH.ptOa24E_eIJ3fdq8UGmBUA2e_PgUHc-1739461413-1.0.1.1-MsNZx7jZ3fTtY3YZWjAFjYGaIHL92dD5V_wqEuU9uyUV7IsgWeqvi0nrG80U.PlGaEd5YggoR2KaGMf4LFNskA; path=/; expires=Thu, 13-Feb-25 16:13:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=iLvgOcwTe5nBiqjlBWCxm29hdH_nH8ay8Au6Cx3yAs4-1739461413832-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115ef4b790f1bad-MAD'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:43:33,823 - openai._base_client - DEBUG - request_id: req_9daf86b191cfb8d756f17dbe176eea16
2025-02-13 16:43:33,823 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:43:33,827 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:43:33,827 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:43:33,828 - __main__ - ERROR - Chat response error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:43:33,833 - __main__ - ERROR - Webhook error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 142, in telegram_webhook
    response = await get_chat_response(update.message.text)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:43:35,896 - __main__ - INFO - Received webhook: {'update_id': 647682826, 'message': {'message_id': 73, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461413, 'text': '!'}}
2025-02-13 16:43:35,904 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The main topic of the conversation was the user's name.\n2. The group of people to whom the AI is being interacting with, is a single individual.\n3. The user first introduced himself as 'Gashish', then later as 'Nazar'.\n4. No important facts or preferences were mentioned.\n5. There were no significant decisions or conclusions made. \n6. The user seemed to be testing the assistant's ability to recognize and remember their name.\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '!'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:43:35,905 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:43:35,905 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:43:35,905 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:43:35,905 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:43:35,905 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:43:35,905 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:43:36,092 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:43:36 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199573'), (b'x-ratelimit-reset-requests', b'15.015s'), (b'x-ratelimit-reset-tokens', b'127ms'), (b'x-request-id', b'req_a0a408626df49b8a9fc5b3c01aac962f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115ef59abf91bad-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:43:36,094 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:43:36,094 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:43:36,095 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:43:36,095 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:43:36,095 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:43:36,095 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers({'date': 'Thu, 13 Feb 2025 15:43:36 GMT', 'content-type': 'application/json', 'content-length': '251', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '20', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199573', 'x-ratelimit-reset-requests': '15.015s', 'x-ratelimit-reset-tokens': '127ms', 'x-request-id': 'req_a0a408626df49b8a9fc5b3c01aac962f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115ef59abf91bad-MAD', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:43:36,095 - openai._base_client - DEBUG - request_id: req_a0a408626df49b8a9fc5b3c01aac962f
2025-02-13 16:43:36,096 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:43:36,097 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:43:36,097 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:43:36,098 - __main__ - ERROR - Chat response error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:43:36,101 - __main__ - ERROR - Webhook error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 142, in telegram_webhook
    response = await get_chat_response(update.message.text)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:43:40,164 - __main__ - INFO - Received webhook: {'update_id': 647682826, 'message': {'message_id': 73, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461413, 'text': '!'}}
2025-02-13 16:43:40,170 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The main topic of the conversation was the user's name.\n2. The group of people to whom the AI is being interacting with, is a single individual.\n3. The user first introduced himself as 'Gashish', then later as 'Nazar'.\n4. No important facts or preferences were mentioned.\n5. There were no significant decisions or conclusions made. \n6. The user seemed to be testing the assistant's ability to recognize and remember their name.\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '!'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:43:40,170 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:43:40,171 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:43:40,171 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:43:40,171 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:43:40,171 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:43:40,171 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:43:40,365 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:43:40 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199573'), (b'x-ratelimit-reset-requests', b'19.39s'), (b'x-ratelimit-reset-tokens', b'127ms'), (b'x-request-id', b'req_8385129ab63d89424c52568c2ee73343'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115ef7449321bad-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:43:40,370 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:43:40,371 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:43:40,371 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:43:40,371 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:43:40,371 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:43:40,371 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers({'date': 'Thu, 13 Feb 2025 15:43:40 GMT', 'content-type': 'application/json', 'content-length': '251', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '21', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199573', 'x-ratelimit-reset-requests': '19.39s', 'x-ratelimit-reset-tokens': '127ms', 'x-request-id': 'req_8385129ab63d89424c52568c2ee73343', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115ef7449321bad-MAD', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:43:40,371 - openai._base_client - DEBUG - request_id: req_8385129ab63d89424c52568c2ee73343
2025-02-13 16:43:40,371 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:43:40,372 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:43:40,372 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:43:40,373 - __main__ - ERROR - Chat response error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:43:40,376 - __main__ - ERROR - Webhook error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 142, in telegram_webhook
    response = await get_chat_response(update.message.text)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:43:48,429 - __main__ - INFO - Received webhook: {'update_id': 647682826, 'message': {'message_id': 73, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461413, 'text': '!'}}
2025-02-13 16:43:48,444 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The main topic of the conversation was the user's name.\n2. The group of people to whom the AI is being interacting with, is a single individual.\n3. The user first introduced himself as 'Gashish', then later as 'Nazar'.\n4. No important facts or preferences were mentioned.\n5. There were no significant decisions or conclusions made. \n6. The user seemed to be testing the assistant's ability to recognize and remember their name.\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '!'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:43:48,445 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:43:48,445 - httpcore.connection - DEBUG - close.started
2025-02-13 16:43:48,446 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:43:48,446 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:43:48,478 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10848e520>
2025-02-13 16:43:48,478 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108260ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:43:48,502 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1083b3e30>
2025-02-13 16:43:48,502 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:43:48,503 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:43:48,503 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:43:48,503 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:43:48,503 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:43:48,746 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:43:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'42'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199573'), (b'x-ratelimit-reset-requests', b'19.684s'), (b'x-ratelimit-reset-tokens', b'127ms'), (b'x-request-id', b'req_615c52b771fb520445bf3780737629d5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PMSocz8Sb1ERjs0jPYo5nN0mQlTbipvBzhCcFolhuhE-1739461428-1.0.1.1-UOTOpLEwPt7HK4_5nK2wzh5D7IOqQ2o8DoVqm3wVZX2kybsoQkmMlr2RLMqUfZM4eIIid7nxAh0SOKr2rMboeA; path=/; expires=Thu, 13-Feb-25 16:13:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=IdG2JoHoThkXGsMrOh9fwrNG_V5LICzJBhGXGvLSqHE-1739461428762-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115efa85dbc1ba9-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:43:48,749 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:43:48,749 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:43:48,750 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:43:48,750 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:43:48,750 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:43:48,750 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers([('date', 'Thu, 13 Feb 2025 15:43:48 GMT'), ('content-type', 'application/json'), ('content-length', '251'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '42'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '199573'), ('x-ratelimit-reset-requests', '19.684s'), ('x-ratelimit-reset-tokens', '127ms'), ('x-request-id', 'req_615c52b771fb520445bf3780737629d5'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=PMSocz8Sb1ERjs0jPYo5nN0mQlTbipvBzhCcFolhuhE-1739461428-1.0.1.1-UOTOpLEwPt7HK4_5nK2wzh5D7IOqQ2o8DoVqm3wVZX2kybsoQkmMlr2RLMqUfZM4eIIid7nxAh0SOKr2rMboeA; path=/; expires=Thu, 13-Feb-25 16:13:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=IdG2JoHoThkXGsMrOh9fwrNG_V5LICzJBhGXGvLSqHE-1739461428762-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115efa85dbc1ba9-MAD'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:43:48,751 - openai._base_client - DEBUG - request_id: req_615c52b771fb520445bf3780737629d5
2025-02-13 16:43:48,751 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:43:48,752 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:43:48,752 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:43:48,753 - __main__ - ERROR - Chat response error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:43:48,756 - __main__ - ERROR - Webhook error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 142, in telegram_webhook
    response = await get_chat_response(update.message.text)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:44:04,808 - __main__ - INFO - Received webhook: {'update_id': 647682826, 'message': {'message_id': 73, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461413, 'text': '!'}}
2025-02-13 16:44:04,823 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The main topic of the conversation was the user's name.\n2. The group of people to whom the AI is being interacting with, is a single individual.\n3. The user first introduced himself as 'Gashish', then later as 'Nazar'.\n4. No important facts or preferences were mentioned.\n5. There were no significant decisions or conclusions made. \n6. The user seemed to be testing the assistant's ability to recognize and remember their name.\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '!'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:44:04,824 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:44:04,824 - httpcore.connection - DEBUG - close.started
2025-02-13 16:44:04,825 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:44:04,825 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:44:04,883 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108610160>
2025-02-13 16:44:04,883 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108260ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:44:04,911 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108610270>
2025-02-13 16:44:04,911 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:44:04,911 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:44:04,911 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:44:04,911 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:44:04,911 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:44:05,087 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:44:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'19'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199573'), (b'x-ratelimit-reset-requests', b'11.927s'), (b'x-ratelimit-reset-tokens', b'127ms'), (b'x-request-id', b'req_bd83644d04a88bc9c599313b963b6b1a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=rjvxJ4mJPRJ9.Jw6TigN0brqjbG68StuVFifqwINnas-1739461445-1.0.1.1-XufJWGU0Eh2Ub.yYfVNaPY5bGLFAOu_xsKlUKtYcmo.uw5O23Xx9vdswxHjGutnrwcePlRq8RoHUVHsbnYoKOw; path=/; expires=Thu, 13-Feb-25 16:14:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=PAgRN5Td8Exqg18Wo7YT7la3Fg984dG4J8PiLGicIvM-1739461445105-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115f00eef77cfeb-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:44:05,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:44:05,088 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:44:05,088 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:44:05,088 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:44:05,088 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:44:05,088 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers([('date', 'Thu, 13 Feb 2025 15:44:05 GMT'), ('content-type', 'application/json'), ('content-length', '251'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '19'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199573'), ('x-ratelimit-reset-requests', '11.927s'), ('x-ratelimit-reset-tokens', '127ms'), ('x-request-id', 'req_bd83644d04a88bc9c599313b963b6b1a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=rjvxJ4mJPRJ9.Jw6TigN0brqjbG68StuVFifqwINnas-1739461445-1.0.1.1-XufJWGU0Eh2Ub.yYfVNaPY5bGLFAOu_xsKlUKtYcmo.uw5O23Xx9vdswxHjGutnrwcePlRq8RoHUVHsbnYoKOw; path=/; expires=Thu, 13-Feb-25 16:14:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=PAgRN5Td8Exqg18Wo7YT7la3Fg984dG4J8PiLGicIvM-1739461445105-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115f00eef77cfeb-MAD'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:44:05,088 - openai._base_client - DEBUG - request_id: req_bd83644d04a88bc9c599313b963b6b1a
2025-02-13 16:44:05,088 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:44:05,089 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:44:05,089 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:44:05,089 - __main__ - ERROR - Chat response error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:44:05,090 - __main__ - ERROR - Webhook error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 142, in telegram_webhook
    response = await get_chat_response(update.message.text)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:44:37,142 - __main__ - INFO - Received webhook: {'update_id': 647682826, 'message': {'message_id': 73, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461413, 'text': '!'}}
2025-02-13 16:44:37,154 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The main topic of the conversation was the user's name.\n2. The group of people to whom the AI is being interacting with, is a single individual.\n3. The user first introduced himself as 'Gashish', then later as 'Nazar'.\n4. No important facts or preferences were mentioned.\n5. There were no significant decisions or conclusions made. \n6. The user seemed to be testing the assistant's ability to recognize and remember their name.\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': {'role': 'user', 'content': ''}}, {'role': 'assistant', 'content': {'role': 'assistant', 'content': '  , !     ?'}}, {'role': 'user', 'content': '!'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:44:37,155 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:44:37,156 - httpcore.connection - DEBUG - close.started
2025-02-13 16:44:37,156 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:44:37,156 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:44:37,176 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108439750>
2025-02-13 16:44:37,176 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108260ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:44:37,199 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108439150>
2025-02-13 16:44:37,199 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:44:37,199 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:44:37,199 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:44:37,199 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:44:37,200 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:44:37,439 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 13 Feb 2025 15:44:37 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'251'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'72'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199573'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'127ms'), (b'x-request-id', b'req_3f0905917bd0ded7cf79a275be103969'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115f0d8bd3ef77b-MAD'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:44:37,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-02-13 16:44:37,440 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:44:37,440 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:44:37,441 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:44:37,441 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:44:37,441 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers({'date': 'Thu, 13 Feb 2025 15:44:37 GMT', 'content-type': 'application/json', 'content-length': '251', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '72', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199573', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '127ms', 'x-request-id': 'req_3f0905917bd0ded7cf79a275be103969', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9115f0d8bd3ef77b-MAD', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:44:37,441 - openai._base_client - DEBUG - request_id: req_3f0905917bd0ded7cf79a275be103969
2025-02-13 16:44:37,441 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1050, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-02-13 16:44:37,443 - openai._base_client - DEBUG - Not retrying
2025-02-13 16:44:37,443 - openai._base_client - DEBUG - Re-raising status error
2025-02-13 16:44:37,443 - __main__ - ERROR - Chat response error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:44:37,446 - __main__ - ERROR - Webhook error: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
Traceback (most recent call last):
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 142, in telegram_webhook
    response = await get_chat_response(update.message.text)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/bot.py", line 86, in get_chat_response
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<40 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ~~~~~~~~~~~~~^
        cast_to=cast_to,
        ^^^^^^^^^^^^^^^^
    ...<3 lines>...
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nazar/Library/Mobile Documents/com~apple~CloudDocs/Code project/PykhBrain/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid type for 'messages[9].content': expected one of a string or array of objects, but got an object instead.", 'type': 'invalid_request_error', 'param': 'messages[9].content', 'code': 'invalid_type'}}
2025-02-13 16:45:30,192 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:45:30,192 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:45:30,192 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:45:30,193 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:45:30,193 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:45:30,252 - httpcore.connection - DEBUG - close.started
2025-02-13 16:45:30,253 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:45:30,253 - httpcore.connection - DEBUG - close.started
2025-02-13 16:45:30,253 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:45:31,798 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:45:31,824 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:45:31,827 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:45:31,830 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:45:31,874 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1055478c0>
2025-02-13 16:45:31,874 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1053dacc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:45:31,915 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x105536210>
2025-02-13 16:45:31,915 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:45:31,915 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:45:31,915 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:45:31,915 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:45:31,915 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:45:31,963 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:45:31 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:45:31,963 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:45:31,963 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:45:31,963 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:45:31,963 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:45:31,963 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:45:31,964 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:45:31,964 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:45:31,964 - telegram.ext.Application - INFO - Application started
2025-02-13 16:45:31,964 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 16:45:31,964 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:45:31,964 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:45:31,964 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:45:31,965 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:45:31,965 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:45:32,065 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:45:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:45:32,066 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:45:32,066 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:45:32,067 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:45:32,067 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:45:32,067 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:45:32,067 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:45:32,071 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze the entire conversation history and create a comprehensive summary. \n                    Focus on:\n                    1. Key recurring topics\n                    2. Who are group of people you are talking to\n                    3. People names, life facts, relations between each other, etc.\n                    4. Important facts or preferences mentioned\n                    5. Significant decisions or conclusions\n                    6. User's behavioral patterns or preferences\n                    Format the output as a structured list of important points."}, {'role': 'user', 'content': "user:   \nassistant: , !      ?\nuser:    ?\nassistant: ,      ,       .      ?\nuser:   \nassistant:  , !   ?\nuser:   ?\nassistant: ,      .  ?\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': '  , !     ?'}"}], 'model': 'gpt-4'}}
2025-02-13 16:45:32,096 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:45:32,096 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:45:32,142 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1055a1160>
2025-02-13 16:45:32,142 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1053d8dd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:45:32,164 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105537c50>
2025-02-13 16:45:32,164 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:45:32,165 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:45:32,165 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:45:32,165 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:45:32,165 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:45:42,352 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:45:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'10009'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9627'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'2.238s'), (b'x-request-id', b'req_cf22eb1eca74660696f50500df140bc3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=wrMCkLqygK8sP5CUGqoiz._ukIOgdZ2v6BCVXYQ_zkY-1739461542-1.0.1.1-NWo_qeiVn7MqWZnueF_MRWJMDIth3eqd8hNQl77Eo7ZKZJK8B4nzc0Am0L1GXAU7_PnzpdwpaDA5ZlZqnYTkOQ; path=/; expires=Thu, 13-Feb-25 16:15:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=zIfbnlLzmyIrlwtM5VH23XrCQSk2aj_PahTgC371S1s-1739461542358-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115f230481f0142-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:45:42,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:45:42,354 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:45:42,354 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:45:42,354 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:45:42,354 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:45:42,354 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:45:42 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '10009'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9627'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '2.238s'), ('x-request-id', 'req_cf22eb1eca74660696f50500df140bc3'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=wrMCkLqygK8sP5CUGqoiz._ukIOgdZ2v6BCVXYQ_zkY-1739461542-1.0.1.1-NWo_qeiVn7MqWZnueF_MRWJMDIth3eqd8hNQl77Eo7ZKZJK8B4nzc0Am0L1GXAU7_PnzpdwpaDA5ZlZqnYTkOQ; path=/; expires=Thu, 13-Feb-25 16:15:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=zIfbnlLzmyIrlwtM5VH23XrCQSk2aj_PahTgC371S1s-1739461542358-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115f230481f0142-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:45:42,354 - openai._base_client - DEBUG - request_id: req_cf22eb1eca74660696f50500df140bc3
2025-02-13 16:47:56,155 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:47:56,155 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:47:56,155 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:47:56,155 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:47:56,155 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:47:56,223 - httpcore.connection - DEBUG - close.started
2025-02-13 16:47:56,223 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:49:35,944 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:49:35,971 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:49:35,974 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:49:35,977 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:49:36,018 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10a05b8c0>
2025-02-13 16:49:36,018 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104beecc0> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:49:36,064 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10a04a210>
2025-02-13 16:49:36,064 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:49:36,065 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:49:36,065 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:49:36,065 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:49:36,065 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:49:36,107 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:49:36 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:49:36,107 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:49:36,107 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:49:36,107 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:49:36,107 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:49:36,108 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:49:36,108 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:49:36,108 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:49:36,108 - telegram.ext.Application - INFO - Application started
2025-02-13 16:49:36,108 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 16:49:36,108 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:49:36,108 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:49:36,108 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:49:36,109 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:49:36,109 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:49:36,268 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:49:36 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:49:36,269 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:49:36,269 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:49:36,269 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:49:36,269 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:49:36,269 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:49:36,269 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:49:36,274 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze the entire conversation history and create a comprehensive summary. \n                    Focus on:\n                    1. Key recurring topics\n                    2. Who are group of people you are talking to\n                    3. People names, life facts, relations between each other, etc.\n                    4. Important facts or preferences mentioned\n                    5. Significant decisions or conclusions\n                    6. User's behavioral patterns or preferences\n                    Format the output as a structured list of important points."}, {'role': 'user', 'content': "user:   \nassistant: , !      ?\nuser:    ?\nassistant: ,      ,       .      ?\nuser:   \nassistant:  , !   ?\nuser:   ?\nassistant: ,      .  ?\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': '  , !     ?'}"}], 'model': 'gpt-4'}}
2025-02-13 16:49:36,296 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:49:36,296 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:49:36,343 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10a0b5160>
2025-02-13 16:49:36,343 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104becdd0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:49:36,371 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10a04bc50>
2025-02-13 16:49:36,371 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:49:36,371 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:49:36,371 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:49:36,371 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:49:36,371 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:49:47,097 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:49:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'10510'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9627'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'2.238s'), (b'x-request-id', b'req_a1854dac1a648d557879c2748aeb92c4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=o2K41MoeYMazmkrTTWYPAQzxzmgmg5IsRSgKQaSszIE-1739461787-1.0.1.1-LTwRxeaCICf5uoCprpLeLsRS8uTboclQVrnVLP1xFF4cJeKdKwjHsn9ifyuugQvMTmzaBZoPd1NBRN3tuNJwig; path=/; expires=Thu, 13-Feb-25 16:19:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=4i6uthJ2GKVtokAoHbqtkQvqqalRydUWREwvn1YVl1g-1739461787078-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115f8268b720331-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:49:47,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:49:47,102 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:49:47,102 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:49:47,102 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:49:47,103 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:49:47,103 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:49:47 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '10510'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9627'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '2.238s'), ('x-request-id', 'req_a1854dac1a648d557879c2748aeb92c4'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=o2K41MoeYMazmkrTTWYPAQzxzmgmg5IsRSgKQaSszIE-1739461787-1.0.1.1-LTwRxeaCICf5uoCprpLeLsRS8uTboclQVrnVLP1xFF4cJeKdKwjHsn9ifyuugQvMTmzaBZoPd1NBRN3tuNJwig; path=/; expires=Thu, 13-Feb-25 16:19:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=4i6uthJ2GKVtokAoHbqtkQvqqalRydUWREwvn1YVl1g-1739461787078-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115f8268b720331-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:49:47,103 - openai._base_client - DEBUG - request_id: req_a1854dac1a648d557879c2748aeb92c4
2025-02-13 16:52:10,361 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:52:10,363 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:52:10,363 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:52:10,363 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:52:10,363 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:52:10,420 - httpcore.connection - DEBUG - close.started
2025-02-13 16:52:10,421 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:53:02,244 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:53:02,273 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:53:02,275 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:53:02,278 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:53:02,322 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10595bb60>
2025-02-13 16:53:02,323 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1055ead50> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:53:02,368 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10594a210>
2025-02-13 16:53:02,368 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:53:02,368 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:53:02,368 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:53:02,369 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:53:02,369 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:53:02,410 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:53:02 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:53:02,410 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:53:02,410 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:53:02,410 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:53:02,410 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:53:02,411 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:53:02,411 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:53:02,411 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:53:02,411 - telegram.ext.Application - INFO - Application started
2025-02-13 16:53:02,411 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 16:53:02,411 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:53:02,411 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:53:02,411 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:53:02,412 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:53:02,412 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:53:02,602 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:53:02 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:53:02,603 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:53:02,603 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:53:02,604 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:53:02,604 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:53:02,604 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:53:02,604 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:53:02,607 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze the entire conversation history and create a comprehensive summary. \n                    Focus on:\n                    1. Key recurring topics\n                    2. Who are group of people you are talking to\n                    3. People names, life facts, relations between each other, etc.\n                    4. Important facts or preferences mentioned\n                    5. Significant decisions or conclusions\n                    6. User's behavioral patterns or preferences\n                    Format the output as a structured list of important points."}, {'role': 'user', 'content': "user:   \nassistant: , !      ?\nuser:    ?\nassistant: ,      ,       .      ?\nuser:   \nassistant:  , !   ?\nuser:   ?\nassistant: ,      .  ?\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': '  , !     ?'}"}], 'model': 'gpt-4'}}
2025-02-13 16:53:02,629 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:53:02,630 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:53:02,690 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1059b9400>
2025-02-13 16:53:02,691 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1055e8e60> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:53:02,719 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10594bc50>
2025-02-13 16:53:02,719 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:53:02,720 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:53:02,720 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:53:02,720 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:53:02,720 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:53:14,435 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:53:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'11536'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9627'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'2.238s'), (b'x-request-id', b'req_bc004af1686ab84847e9a36acfbe1fb2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2ruX0RftY5NnAikiNCA06dopSH4VfbIpfb0J45WWRHc-1739461994-1.0.1.1-lc0WLZwDKf3bhVzo_Jz2iScqpVRswPodqyIS5gM9DMQM7w3823RyGeoGzqrbqVtuIYLNag1s2hdBQlUpBj1Cug; path=/; expires=Thu, 13-Feb-25 16:23:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=yYYkEptw9DtmiCpNnmkd_15.pC7QwKb8aGZ4UrUZ3_s-1739461994446-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9115fd303dcc1ba9-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:53:14,439 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:53:14,440 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:53:14,440 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:53:14,441 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:53:14,441 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:53:14,441 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:53:14 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '11536'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9627'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '2.238s'), ('x-request-id', 'req_bc004af1686ab84847e9a36acfbe1fb2'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=2ruX0RftY5NnAikiNCA06dopSH4VfbIpfb0J45WWRHc-1739461994-1.0.1.1-lc0WLZwDKf3bhVzo_Jz2iScqpVRswPodqyIS5gM9DMQM7w3823RyGeoGzqrbqVtuIYLNag1s2hdBQlUpBj1Cug; path=/; expires=Thu, 13-Feb-25 16:23:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=yYYkEptw9DtmiCpNnmkd_15.pC7QwKb8aGZ4UrUZ3_s-1739461994446-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9115fd303dcc1ba9-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:53:14,441 - openai._base_client - DEBUG - request_id: req_bc004af1686ab84847e9a36acfbe1fb2
2025-02-13 16:55:42,437 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:55:42,438 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:55:42,439 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:55:42,439 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:55:42,439 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:55:42,509 - httpcore.connection - DEBUG - close.started
2025-02-13 16:55:42,509 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:55:44,151 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:55:44,178 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:55:44,181 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:55:44,184 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:55:44,224 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1041bfb60>
2025-02-13 16:55:44,225 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104056c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:55:44,271 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1041b2210>
2025-02-13 16:55:44,273 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:55:44,273 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:55:44,273 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:55:44,273 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:55:44,273 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:55:44,326 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:55:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:55:44,326 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:55:44,326 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:55:44,327 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:55:44,327 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:55:44,327 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:55:44,327 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:55:44,327 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:55:44,327 - telegram.ext.Application - INFO - Application started
2025-02-13 16:55:44,327 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 16:55:44,328 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:55:44,328 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:55:44,328 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:55:44,328 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:55:44,328 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:55:44,396 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:55:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:55:44,396 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:55:44,396 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:55:44,396 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:55:44,396 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:55:44,396 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:55:44,397 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:55:44,400 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze the entire conversation history and create a comprehensive summary. \n                    Focus on:\n                    1. Key recurring topics\n                    2. Who are group of people you are talking to\n                    3. People names, life facts, relations between each other, etc.\n                    4. Important facts or preferences mentioned\n                    5. Significant decisions or conclusions\n                    6. User's behavioral patterns or preferences\n                    Format the output as a structured list of important points."}, {'role': 'user', 'content': "user:   \nassistant: , !      ?\nuser:    ?\nassistant: ,      ,       .      ?\nuser:   \nassistant:  , !   ?\nuser:   ?\nassistant: ,      .  ?\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': '  , !     ?'}"}], 'model': 'gpt-4'}}
2025-02-13 16:55:44,418 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:55:44,418 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:55:44,469 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10421d400>
2025-02-13 16:55:44,470 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104054d40> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:55:44,493 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1041b3c50>
2025-02-13 16:55:44,493 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:55:44,493 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:55:44,493 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:55:44,493 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:55:44,493 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:55:55,400 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:55:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'8571'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9627'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'2.238s'), (b'x-request-id', b'req_4ab010a0def6fd03427cdeedcf4f28ac'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ppA0xNUccNGkog6ijZgTIDvNEmOdMcfWjbpRwWbEviM-1739462155-1.0.1.1-Hd1.lxhqcfrxy.9SC4TztKUB2c7AK6BFjZdGYgpdq_kLMrpud921D0Ay3cfGwcEPmuOLJERsEl3L08MI14HVJw; path=/; expires=Thu, 13-Feb-25 16:25:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=jXMWpYYKSvhtBLaWE4IHWfYZpo4kKzwzeT29eH11GoE-1739462155414-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911601234cbbf770-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:55:55,403 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:55:55,403 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:55:55,404 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:55:55,404 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:55:55,404 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:55:55,404 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:55:55 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '8571'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9627'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '2.238s'), ('x-request-id', 'req_4ab010a0def6fd03427cdeedcf4f28ac'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ppA0xNUccNGkog6ijZgTIDvNEmOdMcfWjbpRwWbEviM-1739462155-1.0.1.1-Hd1.lxhqcfrxy.9SC4TztKUB2c7AK6BFjZdGYgpdq_kLMrpud921D0Ay3cfGwcEPmuOLJERsEl3L08MI14HVJw; path=/; expires=Thu, 13-Feb-25 16:25:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=jXMWpYYKSvhtBLaWE4IHWfYZpo4kKzwzeT29eH11GoE-1739462155414-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '911601234cbbf770-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:55:55,405 - openai._base_client - DEBUG - request_id: req_4ab010a0def6fd03427cdeedcf4f28ac
2025-02-13 16:56:58,864 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 16:56:58,864 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 16:56:58,864 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 16:56:58,864 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 16:56:58,864 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 16:56:58,906 - httpcore.connection - DEBUG - close.started
2025-02-13 16:56:58,906 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:57:17,738 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 16:57:17,766 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 16:57:17,768 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 16:57:17,771 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:57:17,812 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10705bb60>
2025-02-13 16:57:17,812 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:57:17,856 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10704e210>
2025-02-13 16:57:17,856 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:17,856 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:17,856 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:17,856 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:17,856 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:17,923 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:17 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:17,924 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 16:57:17,924 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:17,924 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:17,924 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:17,924 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:17,924 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 16:57:17,924 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 16:57:17,924 - telegram.ext.Application - INFO - Application started
2025-02-13 16:57:17,924 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 16:57:17,925 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:17,925 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:17,925 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:17,925 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:17,925 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:18,060 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:18 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:18,061 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 16:57:18,062 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:18,062 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:18,062 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:18,062 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:18,062 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 16:57:18,067 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze the entire conversation history and create a comprehensive summary. \n                    Focus on:\n                    1. Key recurring topics\n                    2. Who are group of people you are talking to\n                    3. People names, life facts, relations between each other, etc.\n                    4. Important facts or preferences mentioned\n                    5. Significant decisions or conclusions\n                    6. User's behavioral patterns or preferences\n                    Format the output as a structured list of important points."}, {'role': 'user', 'content': "user:   \nassistant: , !      ?\nuser:    ?\nassistant: ,      ,       .      ?\nuser:   \nassistant:  , !   ?\nuser:   ?\nassistant: ,      .  ?\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': '  , !     ?'}"}], 'model': 'gpt-4'}}
2025-02-13 16:57:18,089 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:18,089 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:57:18,131 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1070b9400>
2025-02-13 16:57:18,131 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0d40> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:57:18,156 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10704fc50>
2025-02-13 16:57:18,156 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:18,156 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:18,156 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:18,156 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:18,156 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:27,600 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'9253'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9627'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'2.238s'), (b'x-request-id', b'req_586fc8c9f4e49fd37a9aa81b3533db76'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=I9M0H.LENzjISsxtT_l3Xc9ZtE_Gf8J9W41c2RA6ZXU-1739462247-1.0.1.1-VvdgSpHwa4DoTAsmg2n7QTvugL5RkdqCWMacue1L6IbvhvyOCsukJ2IgEwQO9mnpPk9QTGwQgpt8R7riFp1Y2g; path=/; expires=Thu, 13-Feb-25 16:27:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=tbw_STy8xrRBGPMF7mvt5FuEAwuqWR4QZPN_K03XI3Q-1739462247609-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9116036cbb5f2fab-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:27,601 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:27,602 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:27,602 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:27,602 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:27,602 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:27,602 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:57:27 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '9253'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9627'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '2.238s'), ('x-request-id', 'req_586fc8c9f4e49fd37a9aa81b3533db76'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=I9M0H.LENzjISsxtT_l3Xc9ZtE_Gf8J9W41c2RA6ZXU-1739462247-1.0.1.1-VvdgSpHwa4DoTAsmg2n7QTvugL5RkdqCWMacue1L6IbvhvyOCsukJ2IgEwQO9mnpPk9QTGwQgpt8R7riFp1Y2g; path=/; expires=Thu, 13-Feb-25 16:27:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=tbw_STy8xrRBGPMF7mvt5FuEAwuqWR4QZPN_K03XI3Q-1739462247609-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9116036cbb5f2fab-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:57:27,602 - openai._base_client - DEBUG - request_id: req_586fc8c9f4e49fd37a9aa81b3533db76
2025-02-13 16:57:40,283 - __main__ - INFO - Received webhook with body: {'update_id': 647682826, 'message': {'message_id': 73, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461413, 'text': '!'}}
2025-02-13 16:57:40,284 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 43, 33, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=73, supergroup_chat_created=False, text='!'), update_id=647682826)
2025-02-13 16:57:40,284 - __main__ - INFO - Processing message: !
2025-02-13 16:57:40,293 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:40,294 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:40,294 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:57:40,328 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10704f890>
2025-02-13 16:57:40,328 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:57:40,351 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10742c180>
2025-02-13 16:57:40,351 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:40,351 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:40,351 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:40,351 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:40,351 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:40,958 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'408'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199466'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'160ms'), (b'x-request-id', b'req_b0ed11df3540b6f26d24eda1f2a523a2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6HDPEvtg6LnNKiYBcFgvft6xYB2TzDIxnB1lNuxXPZc-1739462260-1.0.1.1-OjrsU8jOtF.wwZ6D3shJszjCAB_E1qJd8OEX3fp1z53M1ztJVXXeWPkQFtJYEpUTSeK1nnKmhEgqfXUpzKZOTw; path=/; expires=Thu, 13-Feb-25 16:27:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=e.c99AYeLDZcpwCE2mo9_GkrXI7jVjlfO6DUa.2foyk-1739462260969-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911603f76ea92159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:40,959 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:40,960 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:40,966 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:40,966 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:40,966 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:40,966 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:57:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '408'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199466'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '160ms'), ('x-request-id', 'req_b0ed11df3540b6f26d24eda1f2a523a2'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=6HDPEvtg6LnNKiYBcFgvft6xYB2TzDIxnB1lNuxXPZc-1739462260-1.0.1.1-OjrsU8jOtF.wwZ6D3shJszjCAB_E1qJd8OEX3fp1z53M1ztJVXXeWPkQFtJYEpUTSeK1nnKmhEgqfXUpzKZOTw; path=/; expires=Thu, 13-Feb-25 16:27:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=e.c99AYeLDZcpwCE2mo9_GkrXI7jVjlfO6DUa.2foyk-1739462260969-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '911603f76ea92159-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:57:40,967 - openai._base_client - DEBUG - request_id: req_b0ed11df3540b6f26d24eda1f2a523a2
2025-02-13 16:57:40,969 - __main__ - INFO - Got response: , !    ?
2025-02-13 16:57:40,970 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !    ?'}`
2025-02-13 16:57:40,971 - httpcore.connection - DEBUG - close.started
2025-02-13 16:57:40,971 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:57:40,971 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:57:41,014 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1070f1310>
2025-02-13 16:57:41,015 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:57:41,056 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10742d220>
2025-02-13 16:57:41,056 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:41,057 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:41,057 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:41,057 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:41,057 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:41,140 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:41 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'428'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:41,141 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:41,141 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:41,141 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:41,141 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:41,142 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:41,142 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 84, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462261, 'text': ', !    ?'}`
2025-02-13 16:57:41,143 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 41, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=84, supergroup_chat_created=False, text=', !    ?')
2025-02-13 16:57:41,197 - __main__ - INFO - Received webhook with body: {'update_id': 647682827, 'message': {'message_id': 74, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461420, 'text': '/start', 'entities': [{'offset': 0, 'length': 6, 'type': 'bot_command'}]}}
2025-02-13 16:57:41,197 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 43, 40, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=6, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=74, supergroup_chat_created=False, text='/start'), update_id=647682827)
2025-02-13 16:57:41,198 - __main__ - INFO - Processing message: /start
2025-02-13 16:57:41,206 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:41,206 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:41,206 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:41,207 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:41,207 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:41,207 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:41,207 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:41,931 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'542'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199445'), (b'x-ratelimit-reset-requests', b'16.431s'), (b'x-ratelimit-reset-tokens', b'166ms'), (b'x-request-id', b'req_710ee4fcbe2aca34fe10eec76f3e8949'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911603fcbcd22159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:41,933 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:41,933 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:41,934 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:41,934 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:41,934 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:41,934 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '542', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199445', 'x-ratelimit-reset-requests': '16.431s', 'x-ratelimit-reset-tokens': '166ms', 'x-request-id': 'req_710ee4fcbe2aca34fe10eec76f3e8949', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911603fcbcd22159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:41,935 - openai._base_client - DEBUG - request_id: req_710ee4fcbe2aca34fe10eec76f3e8949
2025-02-13 16:57:41,937 - __main__ - INFO - Got response: , !     ?
2025-02-13 16:57:41,937 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !     ?'}`
2025-02-13 16:57:41,938 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:41,939 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:41,939 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:41,939 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:41,939 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:42,010 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:42 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'435'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:42,011 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:42,012 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:42,012 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:42,012 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:42,012 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:42,012 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 85, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462261, 'text': ', !     ?'}`
2025-02-13 16:57:42,013 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 41, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=85, supergroup_chat_created=False, text=', !     ?')
2025-02-13 16:57:42,062 - __main__ - INFO - Received webhook with body: {'update_id': 647682828, 'message': {'message_id': 75, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461425, 'text': '  ?'}}
2025-02-13 16:57:42,063 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 43, 45, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=75, supergroup_chat_created=False, text='  ?'), update_id=647682828)
2025-02-13 16:57:42,063 - __main__ - INFO - Processing message:   ?
2025-02-13 16:57:42,078 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:42,079 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:42,079 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:42,080 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:42,080 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:42,080 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:42,080 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:42,732 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'505'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199417'), (b'x-ratelimit-reset-requests', b'24.204s'), (b'x-ratelimit-reset-tokens', b'174ms'), (b'x-request-id', b'req_0cfafc369a2cea8f5af5a7ea3a9f3863'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911604023b732159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:42,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:42,735 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:42,735 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:42,736 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:42,736 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:42,736 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '505', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199417', 'x-ratelimit-reset-requests': '24.204s', 'x-ratelimit-reset-tokens': '174ms', 'x-request-id': 'req_0cfafc369a2cea8f5af5a7ea3a9f3863', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911604023b732159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:42,736 - openai._base_client - DEBUG - request_id: req_0cfafc369a2cea8f5af5a7ea3a9f3863
2025-02-13 16:57:42,739 - __main__ - INFO - Got response:   .      , ?
2025-02-13 16:57:42,739 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '  .      , ?'}`
2025-02-13 16:57:42,740 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:42,741 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:42,741 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:42,741 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:42,741 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:42,818 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:42 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'498'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:42,819 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:42,820 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:42,820 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:42,821 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:42,821 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:42,821 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 86, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462262, 'text': '  .      , ?'}`
2025-02-13 16:57:42,821 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 42, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=86, supergroup_chat_created=False, text='  .      , ?')
2025-02-13 16:57:42,869 - __main__ - INFO - Received webhook with body: {'update_id': 647682829, 'message': {'message_id': 76, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461562, 'text': 'hey!'}}
2025-02-13 16:57:42,870 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 46, 2, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=76, supergroup_chat_created=False, text='hey!'), update_id=647682829)
2025-02-13 16:57:42,870 - __main__ - INFO - Processing message: hey!
2025-02-13 16:57:42,884 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:42,885 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:42,885 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:42,885 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:42,885 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:42,885 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:42,885 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:43,584 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'517'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199391'), (b'x-ratelimit-reset-requests', b'32.041s'), (b'x-ratelimit-reset-tokens', b'182ms'), (b'x-request-id', b'req_af47f76952d30a1812a044a0f8a9857d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911604073a182159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:43,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:43,587 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:43,587 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:43,588 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:43,588 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:43,588 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '517', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9996', 'x-ratelimit-remaining-tokens': '199391', 'x-ratelimit-reset-requests': '32.041s', 'x-ratelimit-reset-tokens': '182ms', 'x-request-id': 'req_af47f76952d30a1812a044a0f8a9857d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911604073a182159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:43,588 - openai._base_client - DEBUG - request_id: req_af47f76952d30a1812a044a0f8a9857d
2025-02-13 16:57:43,592 - __main__ - INFO - Got response: , !     ?
2025-02-13 16:57:43,592 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !     ?'}`
2025-02-13 16:57:43,593 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:43,594 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:43,594 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:43,594 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:43,594 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:43,688 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:43 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'435'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:43,688 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:43,689 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:43,689 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:43,689 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:43,689 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:43,689 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 87, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462263, 'text': ', !     ?'}`
2025-02-13 16:57:43,690 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 43, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=87, supergroup_chat_created=False, text=', !     ?')
2025-02-13 16:57:43,753 - __main__ - INFO - Received webhook with body: {'update_id': 647682830, 'message': {'message_id': 77, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461792, 'text': '/start', 'entities': [{'offset': 0, 'length': 6, 'type': 'bot_command'}]}}
2025-02-13 16:57:43,754 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 49, 52, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=6, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=77, supergroup_chat_created=False, text='/start'), update_id=647682830)
2025-02-13 16:57:43,754 - __main__ - INFO - Processing message: /start
2025-02-13 16:57:43,772 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:43,776 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:43,776 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:43,777 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:43,777 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:43,777 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:43,777 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:44,391 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'440'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199368'), (b'x-ratelimit-reset-requests', b'39.767s'), (b'x-ratelimit-reset-tokens', b'189ms'), (b'x-request-id', b'req_52007e8f1b116593d735374f1225e066'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9116040cd8e62159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:44,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:44,393 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:44,394 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:44,394 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:44,394 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:44,394 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '440', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9995', 'x-ratelimit-remaining-tokens': '199368', 'x-ratelimit-reset-requests': '39.767s', 'x-ratelimit-reset-tokens': '189ms', 'x-request-id': 'req_52007e8f1b116593d735374f1225e066', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9116040cd8e62159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:44,395 - openai._base_client - DEBUG - request_id: req_52007e8f1b116593d735374f1225e066
2025-02-13 16:57:44,398 - __main__ - INFO - Got response: , !     ?
2025-02-13 16:57:44,398 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !     ?'}`
2025-02-13 16:57:44,399 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:44,399 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:44,399 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:44,400 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:44,400 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:44,472 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'435'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:44,472 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:44,472 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:44,472 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:44,473 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:44,473 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:44,473 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 88, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462264, 'text': ', !     ?'}`
2025-02-13 16:57:44,474 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 44, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=88, supergroup_chat_created=False, text=', !     ?')
2025-02-13 16:57:44,523 - __main__ - INFO - Received webhook with body: {'update_id': 647682831, 'message': {'message_id': 78, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739461796, 'text': 'hello'}}
2025-02-13 16:57:44,523 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 49, 56, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=78, supergroup_chat_created=False, text='hello'), update_id=647682831)
2025-02-13 16:57:44,523 - __main__ - INFO - Processing message: hello
2025-02-13 16:57:44,534 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:44,534 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:44,535 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:44,535 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:44,535 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:44,535 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:44,535 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:45,097 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'379'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199347'), (b'x-ratelimit-reset-requests', b'47.665s'), (b'x-ratelimit-reset-tokens', b'195ms'), (b'x-request-id', b'req_1b92946f23f2c6ed08cda8eb9a46eaab'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911604118e312159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:45,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:45,097 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:45,103 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:45,104 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:45,104 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:45,104 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '379', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '199347', 'x-ratelimit-reset-requests': '47.665s', 'x-ratelimit-reset-tokens': '195ms', 'x-request-id': 'req_1b92946f23f2c6ed08cda8eb9a46eaab', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911604118e312159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:45,104 - openai._base_client - DEBUG - request_id: req_1b92946f23f2c6ed08cda8eb9a46eaab
2025-02-13 16:57:45,106 - __main__ - INFO - Got response: , !   ?
2025-02-13 16:57:45,106 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !   ?'}`
2025-02-13 16:57:45,107 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:45,107 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:45,107 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:45,107 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:45,107 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:45,189 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:45 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'385'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:45,190 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:45,190 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:45,190 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:45,190 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:45,190 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:45,190 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 89, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462265, 'text': ', !   ?'}`
2025-02-13 16:57:45,191 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 45, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=89, supergroup_chat_created=False, text=', !   ?')
2025-02-13 16:57:45,240 - __main__ - INFO - Received webhook with body: {'update_id': 647682832, 'message': {'message_id': 79, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462000, 'text': 'hello'}}
2025-02-13 16:57:45,241 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 53, 20, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=79, supergroup_chat_created=False, text='hello'), update_id=647682832)
2025-02-13 16:57:45,241 - __main__ - INFO - Processing message: hello
2025-02-13 16:57:45,259 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:45,260 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:45,260 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:45,261 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:45,261 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:45,261 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:45,261 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:45,995 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'563'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199331'), (b'x-ratelimit-reset-requests', b'55.571s'), (b'x-ratelimit-reset-tokens', b'200ms'), (b'x-request-id', b'req_2f2df5f32a681b38323937a207c446c8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911604161b032159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:45,995 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:45,995 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:45,998 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:45,998 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:45,998 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:45,998 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '563', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '199331', 'x-ratelimit-reset-requests': '55.571s', 'x-ratelimit-reset-tokens': '200ms', 'x-request-id': 'req_2f2df5f32a681b38323937a207c446c8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911604161b032159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:45,999 - openai._base_client - DEBUG - request_id: req_2f2df5f32a681b38323937a207c446c8
2025-02-13 16:57:46,000 - __main__ - INFO - Got response: , !    ?
2025-02-13 16:57:46,000 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !    ?'}`
2025-02-13 16:57:46,000 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:46,000 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:46,000 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:46,001 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:46,001 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:46,191 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:46 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'428'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:46,192 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:46,192 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:46,192 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:46,192 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:46,192 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:46,192 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 90, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462266, 'text': ', !    ?'}`
2025-02-13 16:57:46,192 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 46, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=90, supergroup_chat_created=False, text=', !    ?')
2025-02-13 16:57:46,238 - __main__ - INFO - Received webhook with body: {'update_id': 647682833, 'message': {'message_id': 80, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462002, 'text': '/start', 'entities': [{'offset': 0, 'length': 6, 'type': 'bot_command'}]}}
2025-02-13 16:57:46,239 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 53, 22, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=6, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=80, supergroup_chat_created=False, text='/start'), update_id=647682833)
2025-02-13 16:57:46,239 - __main__ - INFO - Processing message: /start
2025-02-13 16:57:46,251 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:46,252 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:46,252 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:46,253 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:46,253 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:46,253 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:46,253 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:46,995 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'587'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'199310'), (b'x-ratelimit-reset-requests', b'1m3.23s'), (b'x-ratelimit-reset-tokens', b'207ms'), (b'x-request-id', b'req_48b30b0c77932735342409bdfe97598a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9116041c49602159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:46,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:46,996 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:47,031 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:47,032 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:47,032 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:47,032 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '587', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9992', 'x-ratelimit-remaining-tokens': '199310', 'x-ratelimit-reset-requests': '1m3.23s', 'x-ratelimit-reset-tokens': '207ms', 'x-request-id': 'req_48b30b0c77932735342409bdfe97598a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9116041c49602159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:47,032 - openai._base_client - DEBUG - request_id: req_48b30b0c77932735342409bdfe97598a
2025-02-13 16:57:47,034 - __main__ - INFO - Got response: , !     ?
2025-02-13 16:57:47,034 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !     ?'}`
2025-02-13 16:57:47,035 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:47,035 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:47,035 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:47,035 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:47,035 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:47,200 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:47 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'435'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:47,200 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:47,200 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:47,200 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:47,201 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:47,201 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:47,201 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 91, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462267, 'text': ', !     ?'}`
2025-02-13 16:57:47,201 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 47, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=91, supergroup_chat_created=False, text=', !     ?')
2025-02-13 16:57:47,251 - __main__ - INFO - Received webhook with body: {'update_id': 647682834, 'message': {'message_id': 81, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462004, 'text': 'dsds'}}
2025-02-13 16:57:47,252 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 53, 24, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=81, supergroup_chat_created=False, text='dsds'), update_id=647682834)
2025-02-13 16:57:47,252 - __main__ - INFO - Processing message: dsds
2025-02-13 16:57:47,269 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:47,269 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:47,269 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:47,270 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:47,270 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:47,270 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:47,270 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:47,980 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'532'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'199287'), (b'x-ratelimit-reset-requests', b'1m10.849s'), (b'x-ratelimit-reset-tokens', b'213ms'), (b'x-request-id', b'req_04091a455d25f209c78ba9d4ff7deb90'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91160422af8f2159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:47,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:47,981 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:47,982 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:47,982 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:47,982 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:47,982 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '532', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '199287', 'x-ratelimit-reset-requests': '1m10.849s', 'x-ratelimit-reset-tokens': '213ms', 'x-request-id': 'req_04091a455d25f209c78ba9d4ff7deb90', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '91160422af8f2159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:47,982 - openai._base_client - DEBUG - request_id: req_04091a455d25f209c78ba9d4ff7deb90
2025-02-13 16:57:47,985 - __main__ - INFO - Got response: -   ?   , ?
2025-02-13 16:57:47,985 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '-   ?   , ?'}`
2025-02-13 16:57:47,986 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:47,987 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:47,987 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:47,987 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:47,987 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:48,100 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'509'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:48,100 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:48,100 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:48,100 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:48,100 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:48,101 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:48,101 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 92, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462268, 'text': '-   ?   , ?'}`
2025-02-13 16:57:48,101 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 48, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=92, supergroup_chat_created=False, text='-   ?   , ?')
2025-02-13 16:57:48,147 - __main__ - INFO - Received webhook with body: {'update_id': 647682835, 'message': {'message_id': 82, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462010, 'text': '/context', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 16:57:48,148 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 53, 30, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=82, supergroup_chat_created=False, text='/context'), update_id=647682835)
2025-02-13 16:57:48,148 - __main__ - INFO - Processing message: /context
2025-02-13 16:57:48,163 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:48,163 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:48,163 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:48,164 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:48,164 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:48,164 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:48,164 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:48,797 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'457'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'199260'), (b'x-ratelimit-reset-requests', b'1m18.6s'), (b'x-ratelimit-reset-tokens', b'222ms'), (b'x-request-id', b'req_2cf4b8405415aad011eb2f142ebf4905'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911604283df32159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:48,800 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:48,800 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:48,803 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:48,803 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:48,803 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:48,804 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '457', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9990', 'x-ratelimit-remaining-tokens': '199260', 'x-ratelimit-reset-requests': '1m18.6s', 'x-ratelimit-reset-tokens': '222ms', 'x-request-id': 'req_2cf4b8405415aad011eb2f142ebf4905', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911604283df32159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:48,804 - openai._base_client - DEBUG - request_id: req_2cf4b8405415aad011eb2f142ebf4905
2025-02-13 16:57:48,809 - __main__ - INFO - Got response:   .    ?
2025-02-13 16:57:48,809 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '  .    ?'}`
2025-02-13 16:57:48,810 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:48,811 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:48,811 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:48,811 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:48,811 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:48,899 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'440'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:48,900 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:48,900 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:48,900 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:48,900 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:48,900 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:48,901 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 93, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462268, 'text': '  .    ?'}`
2025-02-13 16:57:48,901 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 48, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=93, supergroup_chat_created=False, text='  .    ?')
2025-02-13 16:57:48,949 - __main__ - INFO - Received webhook with body: {'update_id': 647682836, 'message': {'message_id': 83, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462202, 'text': '/help', 'entities': [{'offset': 0, 'length': 5, 'type': 'bot_command'}]}}
2025-02-13 16:57:48,949 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 56, 42, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=5, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=83, supergroup_chat_created=False, text='/help'), update_id=647682836)
2025-02-13 16:57:48,950 - __main__ - INFO - Processing message: /help
2025-02-13 16:57:48,968 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:57:48,969 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:57:48,969 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:48,969 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:48,969 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:48,970 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:48,970 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:49,526 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:57:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199237'), (b'x-ratelimit-reset-requests', b'1m26.41s'), (b'x-ratelimit-reset-tokens', b'228ms'), (b'x-request-id', b'req_e25aa4340a058a6cf3bb98069791ad15'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9116042d4af52159-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:57:49,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:57:49,527 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:49,545 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:49,545 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:49,545 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:49,546 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:57:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '386', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199237', 'x-ratelimit-reset-requests': '1m26.41s', 'x-ratelimit-reset-tokens': '228ms', 'x-request-id': 'req_e25aa4340a058a6cf3bb98069791ad15', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9116042d4af52159-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:57:49,546 - openai._base_client - DEBUG - request_id: req_e25aa4340a058a6cf3bb98069791ad15
2025-02-13 16:57:49,548 - __main__ - INFO - Got response:       , ?
2025-02-13 16:57:49,548 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '      , ?'}`
2025-02-13 16:57:49,548 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:57:49,548 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:57:49,549 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:57:49,549 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:57:49,549 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:57:49,683 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:57:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'471'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:57:49,684 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:57:49,684 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:57:49,684 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:57:49,684 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:57:49,684 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:57:49,684 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 94, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462269, 'text': '      , ?'}`
2025-02-13 16:57:49,685 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 57, 49, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=94, supergroup_chat_created=False, text='      , ?')
2025-02-13 16:58:15,486 - __main__ - INFO - Received webhook with body: {'update_id': 647682837, 'message': {'message_id': 95, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462295, 'text': ''}}
2025-02-13 16:58:15,487 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 58, 15, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=95, supergroup_chat_created=False, text=''), update_id=647682837)
2025-02-13 16:58:15,487 - __main__ - INFO - Processing message: 
2025-02-13 16:58:15,502 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:58:15,503 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:58:15,503 - httpcore.connection - DEBUG - close.started
2025-02-13 16:58:15,503 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:58:15,503 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:58:15,547 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107017a80>
2025-02-13 16:58:15,548 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:58:15,572 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107430ef0>
2025-02-13 16:58:15,572 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:58:15,573 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:58:15,573 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:58:15,573 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:58:15,573 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:58:16,144 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:58:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'410'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'199212'), (b'x-ratelimit-reset-requests', b'1m8.47s'), (b'x-ratelimit-reset-tokens', b'236ms'), (b'x-request-id', b'req_fc913ecebc93c9e4e1a994d583cae14d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=l2kkDGgvLWT7qdJ_hy7dGVMNE44xiomNusoohGWsE9I-1739462296-1.0.1.1-I3429u_rKIX2j_DJswAfwZiNVdgg.dm7Pl.hsy0lIzw9dfLdmtZ3d1jcLEcxbW65lZqesmd_uEVslSFyV15plg; path=/; expires=Thu, 13-Feb-25 16:28:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=4VUad64juR2_SRIshQv9XkGVSHnhcVd1NCQl1Dfg0Es-1739462296153-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911604d38fe7f767-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:58:16,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:58:16,147 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:58:16,148 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:58:16,148 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:58:16,148 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:58:16,149 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:58:16 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '410'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9992'), ('x-ratelimit-remaining-tokens', '199212'), ('x-ratelimit-reset-requests', '1m8.47s'), ('x-ratelimit-reset-tokens', '236ms'), ('x-request-id', 'req_fc913ecebc93c9e4e1a994d583cae14d'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=l2kkDGgvLWT7qdJ_hy7dGVMNE44xiomNusoohGWsE9I-1739462296-1.0.1.1-I3429u_rKIX2j_DJswAfwZiNVdgg.dm7Pl.hsy0lIzw9dfLdmtZ3d1jcLEcxbW65lZqesmd_uEVslSFyV15plg; path=/; expires=Thu, 13-Feb-25 16:28:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=4VUad64juR2_SRIshQv9XkGVSHnhcVd1NCQl1Dfg0Es-1739462296153-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '911604d38fe7f767-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:58:16,149 - openai._base_client - DEBUG - request_id: req_fc913ecebc93c9e4e1a994d583cae14d
2025-02-13 16:58:16,155 - __main__ - INFO - Got response: , !     ?
2025-02-13 16:58:16,155 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !     ?'}`
2025-02-13 16:58:16,156 - httpcore.connection - DEBUG - close.started
2025-02-13 16:58:16,156 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:58:16,157 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:58:16,199 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10742de00>
2025-02-13 16:58:16,200 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:58:16,244 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107430b90>
2025-02-13 16:58:16,244 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:58:16,246 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:58:16,246 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:58:16,247 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:58:16,247 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:58:16,373 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:58:16 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'435'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:58:16,374 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:58:16,374 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:58:16,375 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:58:16,375 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:58:16,375 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:58:16,375 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 96, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462296, 'text': ', !     ?'}`
2025-02-13 16:58:16,376 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 58, 16, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=96, supergroup_chat_created=False, text=', !     ?')
2025-02-13 16:58:40,612 - __main__ - INFO - Received webhook with body: {'update_id': 647682838, 'message': {'message_id': 97, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462320, 'text': ' ,   ,   ,   .'}}
2025-02-13 16:58:40,613 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 58, 40, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=97, supergroup_chat_created=False, text=' ,   ,   ,   .'), update_id=647682838)
2025-02-13 16:58:40,613 - __main__ - INFO - Processing message:  ,   ,   ,   .
2025-02-13 16:58:40,629 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:58:40,629 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:58:40,629 - httpcore.connection - DEBUG - close.started
2025-02-13 16:58:40,630 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:58:40,630 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:58:40,651 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106deb9b0>
2025-02-13 16:58:40,651 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:58:40,677 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106deb570>
2025-02-13 16:58:40,677 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:58:40,677 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:58:40,677 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:58:40,677 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:58:40,677 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:58:41,880 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:58:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'915'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199158'), (b'x-ratelimit-reset-requests', b'51.867s'), (b'x-ratelimit-reset-tokens', b'252ms'), (b'x-request-id', b'req_08e8a0fb997105a55da691b741af147b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BveGNr9EjKX3Kv5bzs2m7wSNJVN8RuKEhipnx2HeT88-1739462321-1.0.1.1-fTGfOoX3NTr42L0ZZQinxBs1OkGL9S9.IUcUDXwduzNGeoAbr.s.IMhBFDGrNaI58NIHjKXlo3GH5HXXBFFYkw; path=/; expires=Thu, 13-Feb-25 16:28:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=9p.rLqTiBYGkKLEps.tqUvh9r9pW6qLtIm9giOBzT0w-1739462321893-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911605707e7b2f80-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:58:41,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:58:41,881 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:58:41,890 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:58:41,890 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:58:41,890 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:58:41,890 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 15:58:41 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '915'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9993'), ('x-ratelimit-remaining-tokens', '199158'), ('x-ratelimit-reset-requests', '51.867s'), ('x-ratelimit-reset-tokens', '252ms'), ('x-request-id', 'req_08e8a0fb997105a55da691b741af147b'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=BveGNr9EjKX3Kv5bzs2m7wSNJVN8RuKEhipnx2HeT88-1739462321-1.0.1.1-fTGfOoX3NTr42L0ZZQinxBs1OkGL9S9.IUcUDXwduzNGeoAbr.s.IMhBFDGrNaI58NIHjKXlo3GH5HXXBFFYkw; path=/; expires=Thu, 13-Feb-25 16:28:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=9p.rLqTiBYGkKLEps.tqUvh9r9pW6qLtIm9giOBzT0w-1739462321893-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '911605707e7b2f80-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 16:58:41,890 - openai._base_client - DEBUG - request_id: req_08e8a0fb997105a55da691b741af147b
2025-02-13 16:58:41,895 - __main__ - INFO - Got response:  , !    ? ,        ?
2025-02-13 16:58:41,896 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ' , !    ? ,        ?'}`
2025-02-13 16:58:41,896 - httpcore.connection - DEBUG - close.started
2025-02-13 16:58:41,897 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:58:41,897 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:58:41,937 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x106deb240>
2025-02-13 16:58:41,937 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:58:41,987 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x106deb460>
2025-02-13 16:58:41,988 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:58:41,989 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:58:41,989 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:58:41,989 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:58:41,990 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:58:42,099 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:58:42 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'926'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:58:42,103 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:58:42,103 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:58:42,103 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:58:42,104 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:58:42,104 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:58:42,104 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 98, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462322, 'text': ' , !    ? ,        ?'}`
2025-02-13 16:58:42,105 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 58, 42, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=98, supergroup_chat_created=False, text=' , !    ? ,        ?')
2025-02-13 16:58:45,667 - __main__ - INFO - Received webhook with body: {'update_id': 647682839, 'message': {'message_id': 99, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462325, 'text': '/context', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 16:58:45,668 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 58, 45, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=99, supergroup_chat_created=False, text='/context'), update_id=647682839)
2025-02-13 16:58:45,668 - __main__ - INFO - Processing message: /context
2025-02-13 16:58:45,683 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:58:45,684 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:58:45,684 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:58:45,684 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:58:45,684 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:58:45,685 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:58:45,685 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:58:46,734 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:58:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'854'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199093'), (b'x-ratelimit-reset-requests', b'55.629s'), (b'x-ratelimit-reset-tokens', b'271ms'), (b'x-request-id', b'req_8f4740455d1cd92824317c21fbe602e9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9116058fb8b02f80-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:58:46,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:58:46,735 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:58:46,739 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:58:46,739 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:58:46,739 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:58:46,739 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:58:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '854', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '199093', 'x-ratelimit-reset-requests': '55.629s', 'x-ratelimit-reset-tokens': '271ms', 'x-request-id': 'req_8f4740455d1cd92824317c21fbe602e9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9116058fb8b02f80-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:58:46,739 - openai._base_client - DEBUG - request_id: req_8f4740455d1cd92824317c21fbe602e9
2025-02-13 16:58:46,741 - __main__ - INFO - Got response:      ,  ,      .     , ?
2025-02-13 16:58:46,741 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '     ,  ,      .     , ?'}`
2025-02-13 16:58:46,741 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:58:46,741 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:58:46,741 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:58:46,741 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:58:46,741 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:58:46,927 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:58:46 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'889'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:58:46,928 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:58:46,928 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:58:46,928 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:58:46,928 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:58:46,928 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:58:46,929 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 100, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462326, 'text': '     ,  ,      .     , ?'}`
2025-02-13 16:58:46,929 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 58, 46, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=100, supergroup_chat_created=False, text='     ,  ,      .     , ?')
2025-02-13 16:59:57,865 - __main__ - INFO - Received webhook with body: {'update_id': 647682840, 'message': {'message_id': 101, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462397, 'text': '/context', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 16:59:57,866 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 59, 57, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=101, supergroup_chat_created=False, text='/context'), update_id=647682840)
2025-02-13 16:59:57,866 - __main__ - INFO - Processing message: /context
2025-02-13 16:59:57,882 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 16:59:57,883 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 16:59:57,883 - httpcore.connection - DEBUG - close.started
2025-02-13 16:59:57,883 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:59:57,883 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:59:57,943 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1070cdc50>
2025-02-13 16:59:57,943 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 16:59:57,968 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1070ccc50>
2025-02-13 16:59:57,968 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:59:57,968 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:59:57,968 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:59:57,969 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:59:57,969 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:59:58,913 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 15:59:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'775'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199032'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'290ms'), (b'x-request-id', b'req_f5cc22a4ba2a8ed790fa95264261ef95'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911607537fd5cbf3-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 16:59:58,913 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 16:59:58,913 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:59:58,913 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:59:58,914 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:59:58,914 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:59:58,914 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 15:59:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '775', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199032', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '290ms', 'x-request-id': 'req_f5cc22a4ba2a8ed790fa95264261ef95', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911607537fd5cbf3-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 16:59:58,914 - openai._base_client - DEBUG - request_id: req_f5cc22a4ba2a8ed790fa95264261ef95
2025-02-13 16:59:58,915 - __main__ - INFO - Got response:      ,    .    , ?
2025-02-13 16:59:58,915 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '     ,    .    , ?'}`
2025-02-13 16:59:58,916 - httpcore.connection - DEBUG - close.started
2025-02-13 16:59:58,916 - httpcore.connection - DEBUG - close.complete
2025-02-13 16:59:58,916 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 16:59:58,955 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1070cec50>
2025-02-13 16:59:58,955 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 16:59:58,994 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1070ce250>
2025-02-13 16:59:58,994 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 16:59:58,994 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 16:59:58,994 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 16:59:58,994 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 16:59:58,994 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 16:59:59,078 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 15:59:59 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'727'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 16:59:59,078 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 16:59:59,078 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 16:59:59,078 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 16:59:59,078 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 16:59:59,078 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 16:59:59,078 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 102, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462399, 'text': '     ,    .    , ?'}`
2025-02-13 16:59:59,079 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 15, 59, 59, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=102, supergroup_chat_created=False, text='     ,    .    , ?')
2025-02-13 17:00:04,217 - __main__ - INFO - Received webhook with body: {'update_id': 647682841, 'message': {'message_id': 103, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462404, 'text': '/session', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 17:00:04,217 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 0, 4, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=103, supergroup_chat_created=False, text='/session'), update_id=647682841)
2025-02-13 17:00:04,217 - __main__ - INFO - Processing message: /session
2025-02-13 17:00:04,235 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:00:04,236 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:00:04,236 - httpcore.connection - DEBUG - close.started
2025-02-13 17:00:04,236 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:00:04,236 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:00:04,257 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1070d3a70>
2025-02-13 17:00:04,257 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:00:04,294 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1070d32f0>
2025-02-13 17:00:04,294 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:00:04,294 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:00:04,294 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:00:04,294 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:00:04,294 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:00:05,104 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:00:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'559'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'198983'), (b'x-ratelimit-reset-requests', b'10.96s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_12a698089b17d4e106309ca5e46936ce'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hsx4ivPktT3SwAi5nfKIy4I69U95MnKzTqx4at6ddVw-1739462405-1.0.1.1-D2Sj60b0xMr0_gBvEElPBm6sDdzMaQr4NHypWAtcvlx6n3xBsG37.ao3j1enWpwiuycOrYGH2tw_m95YFoGCXA; path=/; expires=Thu, 13-Feb-25 16:30:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=KHkR31sD9r9v6vB_GpcMNG8JX2AVYJctvsc0._ZHj24-1739462405012-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9116077b0bb21a7c-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:00:05,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:00:05,108 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:00:05,108 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:00:05,108 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:00:05,109 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:00:05,109 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 16:00:05 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '559'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '198983'), ('x-ratelimit-reset-requests', '10.96s'), ('x-ratelimit-reset-tokens', '304ms'), ('x-request-id', 'req_12a698089b17d4e106309ca5e46936ce'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=hsx4ivPktT3SwAi5nfKIy4I69U95MnKzTqx4at6ddVw-1739462405-1.0.1.1-D2Sj60b0xMr0_gBvEElPBm6sDdzMaQr4NHypWAtcvlx6n3xBsG37.ao3j1enWpwiuycOrYGH2tw_m95YFoGCXA; path=/; expires=Thu, 13-Feb-25 16:30:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=KHkR31sD9r9v6vB_GpcMNG8JX2AVYJctvsc0._ZHj24-1739462405012-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9116077b0bb21a7c-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 17:00:05,109 - openai._base_client - DEBUG - request_id: req_12a698089b17d4e106309ca5e46936ce
2025-02-13 17:00:05,114 - __main__ - INFO - Got response:  , .    ?
2025-02-13 17:00:05,114 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ' , .    ?'}`
2025-02-13 17:00:05,115 - httpcore.connection - DEBUG - close.started
2025-02-13 17:00:05,115 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:00:05,115 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:00:05,158 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1070d25d0>
2025-02-13 17:00:05,158 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:00:05,201 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1070d2300>
2025-02-13 17:00:05,202 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:00:05,202 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:00:05,202 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:00:05,203 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:00:05,203 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:00:05,303 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:00:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'460'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:00:05,304 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:00:05,305 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:00:05,305 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:00:05,305 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:00:05,306 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:00:05,307 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 104, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462405, 'text': ' , .    ?'}`
2025-02-13 17:00:05,307 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 0, 5, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=104, supergroup_chat_created=False, text=' , .    ?')
2025-02-13 17:00:10,291 - __main__ - INFO - Received webhook with body: {'update_id': 647682842, 'message': {'message_id': 105, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462410, 'text': '/help', 'entities': [{'offset': 0, 'length': 5, 'type': 'bot_command'}]}}
2025-02-13 17:00:10,292 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 0, 10, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=5, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=105, supergroup_chat_created=False, text='/help'), update_id=647682842)
2025-02-13 17:00:10,292 - __main__ - INFO - Processing message: /help
2025-02-13 17:00:10,311 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:00:10,312 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:00:10,312 - httpcore.connection - DEBUG - close.started
2025-02-13 17:00:10,312 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:00:10,312 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:00:10,334 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107484590>
2025-02-13 17:00:10,334 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:00:10,358 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107484910>
2025-02-13 17:00:10,358 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:00:10,358 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:00:10,358 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:00:10,358 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:00:10,358 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:00:11,033 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:00:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'517'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'198960'), (b'x-ratelimit-reset-requests', b'13.539s'), (b'x-ratelimit-reset-tokens', b'312ms'), (b'x-request-id', b'req_fd3b3ac160bf06d3bd2157e80ba5920f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911607a0ef690361-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:00:11,034 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:00:11,035 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:00:11,037 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:00:11,037 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:00:11,037 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:00:11,038 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 16:00:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '517', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '198960', 'x-ratelimit-reset-requests': '13.539s', 'x-ratelimit-reset-tokens': '312ms', 'x-request-id': 'req_fd3b3ac160bf06d3bd2157e80ba5920f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911607a0ef690361-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 17:00:11,038 - openai._base_client - DEBUG - request_id: req_fd3b3ac160bf06d3bd2157e80ba5920f
2025-02-13 17:00:11,041 - __main__ - INFO - Got response:      , ?
2025-02-13 17:00:11,041 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '     , ?'}`
2025-02-13 17:00:11,041 - httpcore.connection - DEBUG - close.started
2025-02-13 17:00:11,041 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:00:11,041 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:00:11,081 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1074842f0>
2025-02-13 17:00:11,083 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:00:11,132 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1074851d0>
2025-02-13 17:00:11,132 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:00:11,132 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:00:11,132 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:00:11,133 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:00:11,133 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:00:11,230 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:00:11 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'453'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:00:11,231 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:00:11,234 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:00:11,235 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:00:11,235 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:00:11,235 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:00:11,235 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 106, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462411, 'text': '     , ?'}`
2025-02-13 17:00:11,236 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 0, 11, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=106, supergroup_chat_created=False, text='     , ?')
2025-02-13 17:00:56,423 - __main__ - INFO - Received webhook with body: {'update_id': 647682843, 'message': {'message_id': 107, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462456, 'text': '         Pentax MX'}}
2025-02-13 17:00:56,424 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 0, 56, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=107, supergroup_chat_created=False, text='         Pentax MX'), update_id=647682843)
2025-02-13 17:00:56,424 - __main__ - INFO - Processing message:          Pentax MX
2025-02-13 17:00:56,447 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '         Pentax MX'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:00:56,448 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:00:56,448 - httpcore.connection - DEBUG - close.started
2025-02-13 17:00:56,448 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:00:56,448 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:00:56,516 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1070675f0>
2025-02-13 17:00:56,516 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:00:56,542 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107476810>
2025-02-13 17:00:56,542 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:00:56,542 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:00:56,542 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:00:56,542 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:00:56,542 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:00:57,990 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:00:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'1262'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198908'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'327ms'), (b'x-request-id', b'req_aef9f3f1a2c18966d1954c4489b6f274'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911608c18fd774dc-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:00:57,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:00:57,997 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:00:58,001 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:00:58,001 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:00:58,001 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:00:58,001 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 16:00:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '1262', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '198908', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '327ms', 'x-request-id': 'req_aef9f3f1a2c18966d1954c4489b6f274', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911608c18fd774dc-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 17:00:58,001 - openai._base_client - DEBUG - request_id: req_aef9f3f1a2c18966d1954c4489b6f274
2025-02-13 17:00:58,005 - __main__ - INFO - Got response: , !    -  !    ?           Pentax MX?
2025-02-13 17:00:58,005 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !    -  !    ?           Pentax MX?'}`
2025-02-13 17:00:58,006 - httpcore.connection - DEBUG - close.started
2025-02-13 17:00:58,006 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:00:58,006 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:00:58,051 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107066820>
2025-02-13 17:00:58,052 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:00:58,096 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x106dffa10>
2025-02-13 17:00:58,097 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:00:58,097 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:00:58,098 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:00:58,098 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:00:58,098 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:00:58,199 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:00:58 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1058'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:00:58,200 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:00:58,201 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:00:58,202 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:00:58,203 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:00:58,203 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:00:58,204 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 108, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462458, 'text': ', !    -  !    ?           Pentax MX?'}`
2025-02-13 17:00:58,204 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 0, 58, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=108, supergroup_chat_created=False, text=', !    -  !    ?           Pentax MX?')
2025-02-13 17:01:12,375 - __main__ - INFO - Received webhook with body: {'update_id': 647682844, 'message': {'message_id': 109, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462472, 'text': '     ! '}}
2025-02-13 17:01:12,376 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 1, 12, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=109, supergroup_chat_created=False, text='     ! '), update_id=647682844)
2025-02-13 17:01:12,376 - __main__ - INFO - Processing message:      ! 
2025-02-13 17:01:12,419 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '         Pentax MX'}, {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}, {'role': 'user', 'content': '     ! '}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:01:12,421 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:01:12,421 - httpcore.connection - DEBUG - close.started
2025-02-13 17:01:12,423 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:01:12,423 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:01:12,449 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106dff590>
2025-02-13 17:01:12,452 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:01:12,491 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107086d00>
2025-02-13 17:01:12,492 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:01:12,492 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:01:12,492 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:01:12,492 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:01:12,492 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:01:13,724 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:01:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'1023'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198816'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'355ms'), (b'x-request-id', b'req_75bf03af19b4d2bc4c5a4e50757f10c3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PJWQC6drD_bgRdBLUfcXZ4Kr6SbghrzXcOtqf7z8Fc0-1739462473-1.0.1.1-Qjpv588b290HEkn9G8dQUd0Y0ifjvdfyMfeEG.ERD6eZ06Zek7zXKX.Xr06Qlvy1B6en5ZchUxYFnSpHaaAsqA; path=/; expires=Thu, 13-Feb-25 16:31:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Ewhg2efcy16ofid1ru59vJ11M0lTZcoGnQMyXgBCWxc-1739462473729-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911609257c430144-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:01:13,727 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:01:13,728 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:01:13,734 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:01:13,734 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:01:13,734 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:01:13,735 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 16:01:13 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '1023'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '198816'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '355ms'), ('x-request-id', 'req_75bf03af19b4d2bc4c5a4e50757f10c3'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=PJWQC6drD_bgRdBLUfcXZ4Kr6SbghrzXcOtqf7z8Fc0-1739462473-1.0.1.1-Qjpv588b290HEkn9G8dQUd0Y0ifjvdfyMfeEG.ERD6eZ06Zek7zXKX.Xr06Qlvy1B6en5ZchUxYFnSpHaaAsqA; path=/; expires=Thu, 13-Feb-25 16:31:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Ewhg2efcy16ofid1ru59vJ11M0lTZcoGnQMyXgBCWxc-1739462473729-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '911609257c430144-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 17:01:13,735 - openai._base_client - DEBUG - request_id: req_75bf03af19b4d2bc4c5a4e50757f10c3
2025-02-13 17:01:13,740 - __main__ - INFO - Got response:  !           ?     ?
2025-02-13 17:01:13,740 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ' !           ?     ?'}`
2025-02-13 17:01:13,741 - httpcore.connection - DEBUG - close.started
2025-02-13 17:01:13,741 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:01:13,741 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:01:13,784 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x106dff710>
2025-02-13 17:01:13,784 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:01:13,829 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1070866d0>
2025-02-13 17:01:13,831 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:01:13,831 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:01:13,832 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:01:13,832 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:01:13,832 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:01:13,946 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:01:13 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'873'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:01:13,946 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:01:13,946 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:01:13,947 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:01:13,947 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:01:13,947 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:01:13,947 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 110, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462473, 'text': ' !           ?     ?'}`
2025-02-13 17:01:13,948 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 1, 13, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=110, supergroup_chat_created=False, text=' !           ?     ?')
2025-02-13 17:01:16,296 - __main__ - INFO - Received webhook with body: {'update_id': 647682845, 'message': {'message_id': 111, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462476, 'text': '/context', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 17:01:16,297 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 1, 16, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=111, supergroup_chat_created=False, text='/context'), update_id=647682845)
2025-02-13 17:01:16,297 - __main__ - INFO - Processing message: /context
2025-02-13 17:01:16,319 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '         Pentax MX'}, {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}, {'role': 'user', 'content': '     ! '}, {'role': 'assistant', 'content': ' !           ?     ?'}, {'role': 'user', 'content': '/context'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:01:16,320 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:01:16,321 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:01:16,321 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:01:16,321 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:01:16,321 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:01:16,321 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:01:17,800 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:01:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'1293'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'198755'), (b'x-ratelimit-reset-requests', b'13.461s'), (b'x-ratelimit-reset-tokens', b'373ms'), (b'x-request-id', b'req_1cef7a60ff0a33940c115c4292e21a72'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9116093d2dc30144-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:01:17,804 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:01:17,806 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:01:17,807 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:01:17,807 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:01:17,807 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:01:17,807 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 16:01:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '1293', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '198755', 'x-ratelimit-reset-requests': '13.461s', 'x-ratelimit-reset-tokens': '373ms', 'x-request-id': 'req_1cef7a60ff0a33940c115c4292e21a72', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9116093d2dc30144-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 17:01:17,808 - openai._base_client - DEBUG - request_id: req_1cef7a60ff0a33940c115c4292e21a72
2025-02-13 17:01:17,812 - __main__ - INFO - Got response:       .      ?     ?        - ,  !
2025-02-13 17:01:17,812 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '      .      ?     ?        - ,  !'}`
2025-02-13 17:01:17,813 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:01:17,814 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:01:17,814 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:01:17,814 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:01:17,814 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:01:17,965 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:01:17 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1169'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:01:17,966 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:01:17,966 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:01:17,966 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:01:17,966 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:01:17,967 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:01:17,967 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 112, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462477, 'text': '      .      ?     ?        - ,  !'}`
2025-02-13 17:01:17,969 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 1, 17, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=112, supergroup_chat_created=False, text='      .      ?     ?        - ,  !')
2025-02-13 17:01:29,113 - __main__ - INFO - Received webhook with body: {'update_id': 647682846, 'message': {'message_id': 113, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462489, 'text': '    ?'}}
2025-02-13 17:01:29,113 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 1, 29, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=113, supergroup_chat_created=False, text='    ?'), update_id=647682846)
2025-02-13 17:01:29,114 - __main__ - INFO - Processing message:     ?
2025-02-13 17:01:29,135 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '         Pentax MX'}, {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}, {'role': 'user', 'content': '     ! '}, {'role': 'assistant', 'content': ' !           ?     ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '      .      ?     ?        - ,  !'}, {'role': 'user', 'content': '    ?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:01:29,136 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:01:29,136 - httpcore.connection - DEBUG - close.started
2025-02-13 17:01:29,136 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:01:29,136 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:01:29,157 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107086780>
2025-02-13 17:01:29,157 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:01:29,183 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1074a47d0>
2025-02-13 17:01:29,183 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:01:29,183 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:01:29,183 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:01:29,183 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:01:29,183 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:01:31,838 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:01:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'2472'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'198660'), (b'x-ratelimit-reset-requests', b'9.228s'), (b'x-ratelimit-reset-tokens', b'402ms'), (b'x-request-id', b'req_c33eea506364535ab91fb5e4589e6b16'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9116098d984f60ca-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:01:31,838 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:01:31,838 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:01:31,848 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:01:31,848 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:01:31,848 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:01:31,848 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 16:01:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '2472', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '198660', 'x-ratelimit-reset-requests': '9.228s', 'x-ratelimit-reset-tokens': '402ms', 'x-request-id': 'req_c33eea506364535ab91fb5e4589e6b16', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9116098d984f60ca-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 17:01:31,848 - openai._base_client - DEBUG - request_id: req_c33eea506364535ab91fb5e4589e6b16
2025-02-13 17:01:31,852 - __main__ - INFO - Got response:  ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?
2025-02-13 17:01:31,852 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?'}`
2025-02-13 17:01:31,853 - httpcore.connection - DEBUG - close.started
2025-02-13 17:01:31,853 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:01:31,853 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:01:31,890 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107086ba0>
2025-02-13 17:01:31,890 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:01:31,927 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1070e6850>
2025-02-13 17:01:31,927 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:01:31,927 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:01:31,927 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:01:31,927 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:01:31,927 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:01:32,116 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:01:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1606'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:01:32,116 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:01:32,116 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:01:32,117 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:01:32,117 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:01:32,117 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:01:32,117 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 114, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462492, 'text': ' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?'}`
2025-02-13 17:01:32,117 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 1, 32, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=114, supergroup_chat_created=False, text=' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?')
2025-02-13 17:03:04,837 - __main__ - INFO - Received webhook with body: {'update_id': 647682847, 'message': {'message_id': 115, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462584, 'text': '/session', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 17:03:04,838 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 3, 4, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=115, supergroup_chat_created=False, text='/session'), update_id=647682847)
2025-02-13 17:03:04,838 - __main__ - INFO - Processing message: /session
2025-02-13 17:03:04,861 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '         Pentax MX'}, {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}, {'role': 'user', 'content': '     ! '}, {'role': 'assistant', 'content': ' !           ?     ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '      .      ?     ?        - ,  !'}, {'role': 'user', 'content': '    ?'}, {'role': 'assistant', 'content': ' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?'}, {'role': 'user', 'content': '/session'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:03:04,862 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:03:04,862 - httpcore.connection - DEBUG - close.started
2025-02-13 17:03:04,862 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:03:04,862 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:03:04,920 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1074a4910>
2025-02-13 17:03:04,920 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:03:04,944 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107012cc0>
2025-02-13 17:03:04,944 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:03:04,944 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:03:04,944 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:03:04,944 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:03:04,944 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:03:06,054 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:03:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'859'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198531'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'440ms'), (b'x-request-id', b'req_576fe0ec6bc61aff17839f03c6f909db'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91160be40c711bb8-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:03:06,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:03:06,055 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:03:06,055 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:03:06,055 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:03:06,055 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:03:06,055 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 16:03:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '859', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '198531', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '440ms', 'x-request-id': 'req_576fe0ec6bc61aff17839f03c6f909db', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '91160be40c711bb8-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 17:03:06,055 - openai._base_client - DEBUG - request_id: req_576fe0ec6bc61aff17839f03c6f909db
2025-02-13 17:03:06,059 - __main__ - INFO - Got response: , .   .    ?
2025-02-13 17:03:06,059 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', .   .    ?'}`
2025-02-13 17:03:06,060 - httpcore.connection - DEBUG - close.started
2025-02-13 17:03:06,060 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:03:06,060 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:03:06,132 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1070e6f30>
2025-02-13 17:03:06,132 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:03:06,177 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107013e30>
2025-02-13 17:03:06,177 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:03:06,178 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:03:06,178 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:03:06,178 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:03:06,178 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:03:06,245 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:03:06 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'559'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:03:06,245 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:03:06,245 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:03:06,245 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:03:06,245 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:03:06,245 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:03:06,245 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 116, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462586, 'text': ', .   .    ?'}`
2025-02-13 17:03:06,245 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 3, 6, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=116, supergroup_chat_created=False, text=', .   .    ?')
2025-02-13 17:03:25,030 - __main__ - INFO - Received webhook with body: {'update_id': 647682848, 'message': {'message_id': 117, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462604, 'text': '/help', 'entities': [{'offset': 0, 'length': 5, 'type': 'bot_command'}]}}
2025-02-13 17:03:25,031 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 3, 24, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=5, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=117, supergroup_chat_created=False, text='/help'), update_id=647682848)
2025-02-13 17:03:25,031 - __main__ - INFO - Processing message: /help
2025-02-13 17:03:25,055 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: The user's name.\n2. Group of people you are talking to: An individual user identifying as . \n3. People names, life facts, relations between each other: The user's name is .\n4. Important facts or preferences mentioned: The user has to clarify their name to the assistant multiple times.\n5. Significant decisions or conclusions: It is important for the assistant to be able to recall user-provided information, such as their name, to provide a more personal and effective user experience. \n6. User's behavioral patterns or preferences: The user has not revealed preferences or behavioral patterns in this interaction. The user initially told the assistant their name was , then clarified it as .\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '         Pentax MX'}, {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}, {'role': 'user', 'content': '     ! '}, {'role': 'assistant', 'content': ' !           ?     ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '      .      ?     ?        - ,  !'}, {'role': 'user', 'content': '    ?'}, {'role': 'assistant', 'content': ' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ', .   .    ?'}, {'role': 'user', 'content': '/help'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:03:25,055 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:03:25,056 - httpcore.connection - DEBUG - close.started
2025-02-13 17:03:25,056 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:03:25,056 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:03:25,075 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1074b1450>
2025-02-13 17:03:25,075 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:03:25,100 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1074b1650>
2025-02-13 17:03:25,100 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:03:25,100 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:03:25,100 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:03:25,100 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:03:25,100 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:03:25,757 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:03:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'499'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198498'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'450ms'), (b'x-request-id', b'req_99695014e20fe7070f1b32b8339edaf2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91160c620e2369e4-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:03:25,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:03:25,759 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:03:25,760 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:03:25,760 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:03:25,760 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:03:25,760 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 16:03:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '499', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '198498', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '450ms', 'x-request-id': 'req_99695014e20fe7070f1b32b8339edaf2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '91160c620e2369e4-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 17:03:25,760 - openai._base_client - DEBUG - request_id: req_99695014e20fe7070f1b32b8339edaf2
2025-02-13 17:03:25,765 - __main__ - INFO - Got response:      , ?
2025-02-13 17:03:25,765 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '     , ?'}`
2025-02-13 17:03:25,766 - httpcore.connection - DEBUG - close.started
2025-02-13 17:03:25,766 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:03:25,766 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:03:25,809 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10748e5d0>
2025-02-13 17:03:25,809 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106cf2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:03:25,859 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10748c350>
2025-02-13 17:03:25,859 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:03:25,859 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:03:25,859 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:03:25,859 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:03:25,859 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:03:25,942 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:03:25 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'489'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:03:25,942 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:03:25,942 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:03:25,942 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:03:25,942 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:03:25,942 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:03:25,942 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 118, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462605, 'text': '     , ?'}`
2025-02-13 17:03:25,943 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 3, 25, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=118, supergroup_chat_created=False, text='     , ?')
2025-02-13 17:04:49,159 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 17:04:49,159 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 17:04:49,159 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 17:04:49,159 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 17:04:49,159 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 17:04:49,214 - httpcore.connection - DEBUG - close.started
2025-02-13 17:04:49,214 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:04:49,214 - httpcore.connection - DEBUG - close.started
2025-02-13 17:04:49,214 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:04:56,818 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 17:04:56,845 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 17:04:56,848 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 17:04:56,851 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:04:56,918 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10875bb60>
2025-02-13 17:04:56,918 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1082f2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:04:56,965 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10874e210>
2025-02-13 17:04:56,966 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:04:56,966 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:04:56,966 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:04:56,966 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:04:56,966 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:04:57,109 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:04:57 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:04:57,111 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 17:04:57,111 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:04:57,111 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:04:57,111 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:04:57,112 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:04:57,112 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 17:04:57,112 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 17:04:57,112 - telegram.ext.Application - INFO - Application started
2025-02-13 17:04:57,112 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context')]}`
2025-02-13 17:04:57,113 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:04:57,114 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:04:57,114 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:04:57,114 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:04:57,114 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:04:57,174 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:04:57 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:04:57,175 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 17:04:57,175 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:04:57,175 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:04:57,175 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:04:57,175 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:04:57,175 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 17:04:57,180 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze the entire conversation history and create a comprehensive summary. \n                    Focus on:\n                    1. Key recurring topics\n                    2. Who are group of people you are talking to\n                    3. People names, life facts, relations between each other, etc.\n                    4. Important facts or preferences mentioned\n                    5. Significant decisions or conclusions\n                    6. User's behavioral patterns or preferences\n                    Format the output as a structured list of important points."}, {'role': 'user', 'content': "user:   \nassistant: , !      ?\nuser:    ?\nassistant: ,      ,       .      ?\nuser:   \nassistant:  , !   ?\nuser:   ?\nassistant: ,      .  ?\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': '  , !     ?'}\nuser: {'role': 'user', 'content': '!'}\nassistant: {'role': 'assistant', 'content': ', !    ?'}\nuser: {'role': 'user', 'content': '/start'}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': '  ?'}\nassistant: {'role': 'assistant', 'content': '  .      , ?'}\nuser: {'role': 'user', 'content': 'hey!'}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': '/start'}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': 'hello'}\nassistant: {'role': 'assistant', 'content': ', !   ?'}\nuser: {'role': 'user', 'content': 'hello'}\nassistant: {'role': 'assistant', 'content': ', !    ?'}\nuser: {'role': 'user', 'content': '/start'}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': 'dsds'}\nassistant: {'role': 'assistant', 'content': '-   ?   , ?'}\nuser: {'role': 'user', 'content': '/context'}\nassistant: {'role': 'assistant', 'content': '  .    ?'}\nuser: {'role': 'user', 'content': '/help'}\nassistant: {'role': 'assistant', 'content': '      , ?'}\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': ' ,   ,   ,   .'}\nassistant: {'role': 'assistant', 'content': ' , !    ? ,        ?'}\nuser: {'role': 'user', 'content': '/context'}\nassistant: {'role': 'assistant', 'content': '     ,  ,      .     , ?'}\nuser: {'role': 'user', 'content': '/context'}\nassistant: {'role': 'assistant', 'content': '     ,    .    , ?'}\nuser: {'role': 'user', 'content': '/session'}\nassistant: {'role': 'assistant', 'content': ' , .    ?'}\nuser: {'role': 'user', 'content': '/help'}\nassistant: {'role': 'assistant', 'content': '     , ?'}\nuser: {'role': 'user', 'content': '         Pentax MX'}\nassistant: {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}\nuser: {'role': 'user', 'content': '     ! '}\nassistant: {'role': 'assistant', 'content': ' !           ?     ?'}\nuser: {'role': 'user', 'content': '/context'}\nassistant: {'role': 'assistant', 'content': '      .      ?     ?        - ,  !'}\nuser: {'role': 'user', 'content': '    ?'}\nassistant: {'role': 'assistant', 'content': ' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?'}\nuser: {'role': 'user', 'content': '/session'}\nassistant: {'role': 'assistant', 'content': ', .   .    ?'}\nuser: {'role': 'user', 'content': '/help'}\nassistant: {'role': 'assistant', 'content': '     , ?'}"}], 'model': 'gpt-4'}}
2025-02-13 17:04:57,205 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:04:57,205 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:04:57,247 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1087b9550>
2025-02-13 17:04:57,247 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1082f0d40> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:04:57,271 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10874fd90>
2025-02-13 17:04:57,271 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:04:57,271 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:04:57,271 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:04:57,272 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:04:57,272 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:05:17,840 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:05:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'20411'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8184'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'10.896s'), (b'x-request-id', b'req_0ffcadb36ceffdf5d6aab9930392d881'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=e0v.o6G1qp2yplsJcq5U_FEC6BJ9kkOG2o.iNkp5IUM-1739462717-1.0.1.1-cKeEEvgJD8TTlk6ni_mXa7k5KJFjqs_oKuD8Q5qBBkXjW3uxrjWnq0To0QB5zDHUrpeUnksaZzMuzjI6dUsdeQ; path=/; expires=Thu, 13-Feb-25 16:35:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=1demxxVcVLH41.1Bzq7mtRT9eQ8QG7XyFdoooeqY90M-1739462717842-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91160ea21bb73670-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:05:17,846 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:05:17,846 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:05:17,847 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:05:17,847 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:05:17,848 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:05:17,848 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 16:05:17 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '20411'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8184'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '10.896s'), ('x-request-id', 'req_0ffcadb36ceffdf5d6aab9930392d881'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=e0v.o6G1qp2yplsJcq5U_FEC6BJ9kkOG2o.iNkp5IUM-1739462717-1.0.1.1-cKeEEvgJD8TTlk6ni_mXa7k5KJFjqs_oKuD8Q5qBBkXjW3uxrjWnq0To0QB5zDHUrpeUnksaZzMuzjI6dUsdeQ; path=/; expires=Thu, 13-Feb-25 16:35:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=1demxxVcVLH41.1Bzq7mtRT9eQ8QG7XyFdoooeqY90M-1739462717842-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '91160ea21bb73670-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 17:05:17,848 - openai._base_client - DEBUG - request_id: req_0ffcadb36ceffdf5d6aab9930392d881
2025-02-13 17:05:24,642 - __main__ - INFO - Received webhook with body: {'update_id': 647682849, 'message': {'message_id': 119, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462724, 'text': '/help', 'entities': [{'offset': 0, 'length': 5, 'type': 'bot_command'}]}}
2025-02-13 17:05:24,643 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 5, 24, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=5, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=119, supergroup_chat_created=False, text='/help'), update_id=647682849)
2025-02-13 17:05:24,643 - __main__ - INFO - Processing command: /help
2025-02-13 17:05:24,643 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': 'Here are the available commands:\n\n/start - Start the bot\n/help - Show this help message\n/clear - Clear conversation history\n/session - Set session duration\n/analyze - Analyze entire conversation history\n/context - Show current historical context'}`
2025-02-13 17:05:24,644 - httpcore.connection - DEBUG - close.started
2025-02-13 17:05:24,644 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:05:24,644 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:05:24,686 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1087f4e10>
2025-02-13 17:05:24,686 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1082f2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:05:24,730 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10dc20510>
2025-02-13 17:05:24,731 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:05:24,731 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:05:24,732 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:05:24,737 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:05:24,737 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:05:24,805 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:05:24 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'779'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:05:24,806 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:05:24,807 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:05:24,807 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:05:24,807 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:05:24,807 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:05:24,808 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 120, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462724, 'text': 'Here are the available commands:\n\n/start - Start the bot\n/help - Show this help message\n/clear - Clear conversation history\n/session - Set session duration\n/analyze - Analyze entire conversation history\n/context - Show current historical context', 'entities': [{'offset': 34, 'length': 6, 'type': 'bot_command'}, {'offset': 57, 'length': 5, 'type': 'bot_command'}, {'offset': 88, 'length': 6, 'type': 'bot_command'}, {'offset': 124, 'length': 8, 'type': 'bot_command'}, {'offset': 156, 'length': 8, 'type': 'bot_command'}, {'offset': 203, 'length': 8, 'type': 'bot_command'}]}`
2025-02-13 17:05:34,399 - __main__ - INFO - Received webhook with body: {'update_id': 647682850, 'message': {'message_id': 121, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462734, 'text': '!     ?'}}
2025-02-13 17:05:34,400 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 5, 34, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=121, supergroup_chat_created=False, text='!     ?'), update_id=647682850)
2025-02-13 17:05:34,400 - __main__ - INFO - Processing message: !     ?
2025-02-13 17:05:34,426 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics:\n    - User\'s name and personal preferences\n    - User\'s love for triathlon, design, bright saturated colors\n    - User\'s travel to Andorra with a friend named Innocent\n    - User\'s camera Pentax MX\n2. Who are group of people you are talking to:\n    - The conversation is between an AI assistant and a user named Nazar.\n3. People\'s names, life facts, relations:\n    - The user\'s name is Nazar.\n    - Nazar loves triathlon, bright saturated colors and design.\n    - Nazar has a friend named Innocent with whom he traveled to Andorra.\n    - Nazar owns a Pentax MX camera.\n4. Important facts or preferences mentioned:\n    - User likes triathlon, bright saturated colors, and design.\n    - User has traveled to Andorra with a friend Innocent.\n    - User owns a Pentax MX camera.\n5. Significant decisions or conclusions:\n    - The assistant continuously recognizes and remembers Nazar\'s name and his preferences.\n6. User\'s behavioral patterns or preferences:\n    - Nazar often asks the assistant about what it knows about him. He seems keen on verifying if the assistant can keep track of knowledge about him.\n    - Nazar tends to use command-like prompts such as "/start", "/context", "/session" and "/help". This suggests he is comfortable with using technical or system-like language.\n    - Nazar likes to share information about his personal preferences and travel experiences.\n                \n                Guidelines:\n                - Remember and use people\'s names and preferences\n                - Always respond in the same language as the user\'s message\n                - Keep track of important information shared in conversation\n                - If you learn someone\'s name, use it in future responses\n                - Be friendly and personable while maintaining professionalism'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '         Pentax MX'}, {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}, {'role': 'user', 'content': '     ! '}, {'role': 'assistant', 'content': ' !           ?     ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '      .      ?     ?        - ,  !'}, {'role': 'user', 'content': '    ?'}, {'role': 'assistant', 'content': ' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ', .   .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '!     ?'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:05:34,427 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:05:34,427 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:05:34,474 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10874f890>
2025-02-13 17:05:34,475 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1082f0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:05:34,501 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10dc202b0>
2025-02-13 17:05:34,501 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:05:34,502 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:05:34,502 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:05:34,502 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:05:34,502 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:05:36,561 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:05:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'1849'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198302'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'509ms'), (b'x-request-id', b'req_b613d6c5059f6ed70ea3d94261381ad2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QnhP8ULlKcqW0t3m5tbFGkeSB6RecwktZC48cXCTUm8-1739462736-1.0.1.1-y4seFaVfErNWvLZMG5hWFQabegm7irlGiMga5GRKUvYUiTfT2IM31slohjnj0UaSaBM9eLC7Ylr2mnBlS_GQsw; path=/; expires=Thu, 13-Feb-25 16:35:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ZXSuIFv9rfl3YIIWfXe.Iylf10WOVDuCxLuNk7Cu1A0-1739462736563-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91160f8aca972154-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:05:36,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:05:36,564 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:05:36,566 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:05:36,566 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:05:36,566 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:05:36,566 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 16:05:36 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '1849'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '198302'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '509ms'), ('x-request-id', 'req_b613d6c5059f6ed70ea3d94261381ad2'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=QnhP8ULlKcqW0t3m5tbFGkeSB6RecwktZC48cXCTUm8-1739462736-1.0.1.1-y4seFaVfErNWvLZMG5hWFQabegm7irlGiMga5GRKUvYUiTfT2IM31slohjnj0UaSaBM9eLC7Ylr2mnBlS_GQsw; path=/; expires=Thu, 13-Feb-25 16:35:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ZXSuIFv9rfl3YIIWfXe.Iylf10WOVDuCxLuNk7Cu1A0-1739462736563-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '91160f8aca972154-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 17:05:36,567 - openai._base_client - DEBUG - request_id: req_b613d6c5059f6ed70ea3d94261381ad2
2025-02-13 17:05:36,573 - __main__ - INFO - Got response: , !  ,    ,       .   ,              Pentax MX.     - ,        ,  !
2025-02-13 17:05:36,573 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !  ,    ,       .   ,              Pentax MX.     - ,        ,  !'}`
2025-02-13 17:05:36,574 - httpcore.connection - DEBUG - close.started
2025-02-13 17:05:36,574 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:05:36,574 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:05:36,618 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10dc21810>
2025-02-13 17:05:36,618 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1082f2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:05:36,666 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1087439b0>
2025-02-13 17:05:36,667 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:05:36,668 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:05:36,668 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:05:36,668 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:05:36,669 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:05:36,746 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:05:36 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1820'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:05:36,746 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:05:36,747 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:05:36,747 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:05:36,747 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:05:36,747 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:05:36,747 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 122, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462736, 'text': ', !  ,    ,       .   ,              Pentax MX.     - ,        ,  !'}`
2025-02-13 17:05:36,747 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 5, 36, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=122, supergroup_chat_created=False, text=', !  ,    ,       .   ,              Pentax MX.     - ,        ,  !')
2025-02-13 17:08:58,022 - __main__ - INFO - Received webhook with body: {'update_id': 647682851, 'message': {'message_id': 123, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462937, 'text': ']'}}
2025-02-13 17:08:58,023 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 8, 57, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=123, supergroup_chat_created=False, text=']'), update_id=647682851)
2025-02-13 17:08:58,023 - __main__ - INFO - Processing message: ]
2025-02-13 17:08:58,046 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics:\n    - User\'s name and personal preferences\n    - User\'s love for triathlon, design, bright saturated colors\n    - User\'s travel to Andorra with a friend named Innocent\n    - User\'s camera Pentax MX\n2. Who are group of people you are talking to:\n    - The conversation is between an AI assistant and a user named Nazar.\n3. People\'s names, life facts, relations:\n    - The user\'s name is Nazar.\n    - Nazar loves triathlon, bright saturated colors and design.\n    - Nazar has a friend named Innocent with whom he traveled to Andorra.\n    - Nazar owns a Pentax MX camera.\n4. Important facts or preferences mentioned:\n    - User likes triathlon, bright saturated colors, and design.\n    - User has traveled to Andorra with a friend Innocent.\n    - User owns a Pentax MX camera.\n5. Significant decisions or conclusions:\n    - The assistant continuously recognizes and remembers Nazar\'s name and his preferences.\n6. User\'s behavioral patterns or preferences:\n    - Nazar often asks the assistant about what it knows about him. He seems keen on verifying if the assistant can keep track of knowledge about him.\n    - Nazar tends to use command-like prompts such as "/start", "/context", "/session" and "/help". This suggests he is comfortable with using technical or system-like language.\n    - Nazar likes to share information about his personal preferences and travel experiences.\n                \n                Guidelines:\n                - Remember and use people\'s names and preferences\n                - Always respond in the same language as the user\'s message\n                - Keep track of important information shared in conversation\n                - If you learn someone\'s name, use it in future responses\n                - Be friendly and personable while maintaining professionalism'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '         Pentax MX'}, {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}, {'role': 'user', 'content': '     ! '}, {'role': 'assistant', 'content': ' !           ?     ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '      .      ?     ?        - ,  !'}, {'role': 'user', 'content': '    ?'}, {'role': 'assistant', 'content': ' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ', .   .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '!     ?'}, {'role': 'assistant', 'content': ', !  ,    ,       .   ,              Pentax MX.     - ,        ,  !'}, {'role': 'user', 'content': ']'}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:08:58,047 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:08:58,047 - httpcore.connection - DEBUG - close.started
2025-02-13 17:08:58,047 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:08:58,048 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:08:58,113 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10dc21ba0>
2025-02-13 17:08:58,113 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1082f0ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:08:58,141 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10dc545f0>
2025-02-13 17:08:58,142 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:08:58,142 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:08:58,142 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:08:58,142 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:08:58,142 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:08:58,783 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:08:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'469'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198156'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'552ms'), (b'x-request-id', b'req_e3787b5e7f9bf6ea84ef97cd6365ccca'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911614838cb61bad-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:08:58,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:08:58,785 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:08:58,814 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:08:58,814 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:08:58,815 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:08:58,815 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 16:08:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-jrobrdv8bldfakdoyxdsiky9', 'openai-processing-ms': '469', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '198156', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '552ms', 'x-request-id': 'req_e3787b5e7f9bf6ea84ef97cd6365ccca', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '911614838cb61bad-MAD', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-13 17:08:58,816 - openai._base_client - DEBUG - request_id: req_e3787b5e7f9bf6ea84ef97cd6365ccca
2025-02-13 17:08:58,823 - __main__ - INFO - Got response:      , ?
2025-02-13 17:08:58,823 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': '     , ?'}`
2025-02-13 17:08:58,824 - httpcore.connection - DEBUG - close.started
2025-02-13 17:08:58,824 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:08:58,824 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:08:58,897 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10dc70160>
2025-02-13 17:08:58,897 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1082f2c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:08:58,942 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10dc70270>
2025-02-13 17:08:58,942 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:08:58,943 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:08:58,943 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:08:58,943 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:08:58,943 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:08:59,138 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:08:59 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'417'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:08:59,138 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:08:59,138 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:08:59,139 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:08:59,140 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:08:59,140 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:08:59,140 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 124, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739462939, 'text': '     , ?'}`
2025-02-13 17:08:59,140 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 8, 59, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=124, supergroup_chat_created=False, text='     , ?')
2025-02-13 17:12:24,652 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.
2025-02-13 17:12:24,654 - telegram.ext.Application - DEBUG - Waiting for update_queue to join
2025-02-13 17:12:24,654 - telegram.ext.Application - DEBUG - Application stopped fetching of updates.
2025-02-13 17:12:24,654 - telegram.ext.Application - DEBUG - Waiting for `create_task` calls to be processed
2025-02-13 17:12:24,654 - telegram.ext.Application - INFO - Application.stop() complete
2025-02-13 17:12:24,698 - httpcore.connection - DEBUG - close.started
2025-02-13 17:12:24,699 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:12:24,699 - httpcore.connection - DEBUG - close.started
2025-02-13 17:12:24,699 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:14:11,099 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 17:14:11,131 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 17:16:24,706 - __main__ - INFO - MOCK_MODE is set to: False
2025-02-13 17:16:24,740 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-13 17:16:24,744 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `getMe` with parameters `{}`
2025-02-13 17:16:24,747 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:16:24,813 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1076fbb60>
2025-02-13 17:16:24,814 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107596c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:16:24,852 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1076ee210>
2025-02-13 17:16:24,854 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:16:24,854 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:16:24,854 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:16:24,854 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:16:24,854 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:16:24,892 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:16:24 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'248'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:16:24,892 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/getMe "HTTP/1.1 200 OK"
2025-02-13 17:16:24,892 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:16:24,892 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:16:24,892 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:16:24,893 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:16:24,893 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `getMe` finished with return value `{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot', 'can_join_groups': True, 'can_read_all_group_messages': False, 'supports_inline_queries': False, 'can_connect_to_business': False, 'has_main_web_app': False}`
2025-02-13 17:16:24,893 - telegram.ext.ExtBot - DEBUG - This Bot is already initialized.
2025-02-13 17:16:24,893 - telegram.ext.Application - INFO - Application started
2025-02-13 17:16:24,893 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `setMyCommands` with parameters `{'commands': [BotCommand(command='start', description='Start the bot'), BotCommand(command='help', description='Show available commands'), BotCommand(command='clear', description='Clear conversation history'), BotCommand(command='session', description='Set session duration'), BotCommand(command='analyze', description='Analyze conversation history'), BotCommand(command='context', description='Show historical context'), BotCommand(command='midterm', description='Show mid-term memory stats'), BotCommand(command='shortterm', description='Show short-term memory stats'), BotCommand(command='wholehistory', description='Show whole history stats'), BotCommand(command='historycontext', description='Show full history context')]}`
2025-02-13 17:16:24,894 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:16:24,894 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:16:24,894 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:16:24,894 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:16:24,894 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:16:24,939 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:16:24 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:16:24,939 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/setMyCommands "HTTP/1.1 200 OK"
2025-02-13 17:16:24,939 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:16:24,939 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:16:24,939 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:16:24,939 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:16:24,939 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `setMyCommands` finished with return value `True`
2025-02-13 17:16:24,942 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze the entire conversation history and create a comprehensive summary. \n                    Focus on:\n                    1. Key recurring topics\n                    2. Who are group of people you are talking to\n                    3. People names, life facts, relations between each other, etc.\n                    4. Important facts or preferences mentioned\n                    5. Significant decisions or conclusions\n                    6. User's behavioral patterns or preferences\n                    Format the output as a structured list of important points."}, {'role': 'user', 'content': "user:   \nassistant: , !      ?\nuser:    ?\nassistant: ,      ,       .      ?\nuser:   \nassistant:  , !   ?\nuser:   ?\nassistant: ,      .  ?\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': '  , !     ?'}\nuser: {'role': 'user', 'content': '!'}\nassistant: {'role': 'assistant', 'content': ', !    ?'}\nuser: {'role': 'user', 'content': '/start'}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': '  ?'}\nassistant: {'role': 'assistant', 'content': '  .      , ?'}\nuser: {'role': 'user', 'content': 'hey!'}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': '/start'}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': 'hello'}\nassistant: {'role': 'assistant', 'content': ', !   ?'}\nuser: {'role': 'user', 'content': 'hello'}\nassistant: {'role': 'assistant', 'content': ', !    ?'}\nuser: {'role': 'user', 'content': '/start'}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': 'dsds'}\nassistant: {'role': 'assistant', 'content': '-   ?   , ?'}\nuser: {'role': 'user', 'content': '/context'}\nassistant: {'role': 'assistant', 'content': '  .    ?'}\nuser: {'role': 'user', 'content': '/help'}\nassistant: {'role': 'assistant', 'content': '      , ?'}\nuser: {'role': 'user', 'content': ''}\nassistant: {'role': 'assistant', 'content': ', !     ?'}\nuser: {'role': 'user', 'content': ' ,   ,   ,   .'}\nassistant: {'role': 'assistant', 'content': ' , !    ? ,        ?'}\nuser: {'role': 'user', 'content': '/context'}\nassistant: {'role': 'assistant', 'content': '     ,  ,      .     , ?'}\nuser: {'role': 'user', 'content': '/context'}\nassistant: {'role': 'assistant', 'content': '     ,    .    , ?'}\nuser: {'role': 'user', 'content': '/session'}\nassistant: {'role': 'assistant', 'content': ' , .    ?'}\nuser: {'role': 'user', 'content': '/help'}\nassistant: {'role': 'assistant', 'content': '     , ?'}\nuser: {'role': 'user', 'content': '         Pentax MX'}\nassistant: {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}\nuser: {'role': 'user', 'content': '     ! '}\nassistant: {'role': 'assistant', 'content': ' !           ?     ?'}\nuser: {'role': 'user', 'content': '/context'}\nassistant: {'role': 'assistant', 'content': '      .      ?     ?        - ,  !'}\nuser: {'role': 'user', 'content': '    ?'}\nassistant: {'role': 'assistant', 'content': ' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?'}\nuser: {'role': 'user', 'content': '/session'}\nassistant: {'role': 'assistant', 'content': ', .   .    ?'}\nuser: {'role': 'user', 'content': '/help'}\nassistant: {'role': 'assistant', 'content': '     , ?'}\nuser: {'role': 'user', 'content': '!     ?'}\nassistant: {'role': 'assistant', 'content': ', !  ,    ,       .   ,              Pentax MX.     - ,        ,  !'}\nuser: {'role': 'user', 'content': ']'}\nassistant: {'role': 'assistant', 'content': '     , ?'}"}], 'model': 'gpt-4'}}
2025-02-13 17:16:24,964 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:16:24,964 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:16:25,008 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107759550>
2025-02-13 17:16:25,008 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107594d40> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:16:25,029 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1076efd90>
2025-02-13 17:16:25,029 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:16:25,029 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:16:25,029 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:16:25,029 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:16:25,029 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:16:40,552 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:16:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'15247'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'7967'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'12.198s'), (b'x-request-id', b'req_28793e24b419fade972a606e3f49662b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zMoYjjB7PxFH8VpW1yyjuwqw303f6UPytCoOJZAosbc-1739463400-1.0.1.1-5VqgOeJW8ApFLmOYWPyQqoZXGOqZwlaEs0iOgyFKFwQEq7HijeewsKhqW9AdYft7BFAPBJLFLzkb5ExyVhHVWQ; path=/; expires=Thu, 13-Feb-25 16:46:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=fgnuFc4.Rvic2TJ54tspposZhXiQsskwHVy8k0aAoeQ-1739463400548-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91161f6c9f77f773-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:16:40,556 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:16:40,556 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:16:40,557 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:16:40,557 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:16:40,557 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:16:40,557 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 16:16:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '15247'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '7967'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '12.198s'), ('x-request-id', 'req_28793e24b419fade972a606e3f49662b'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=zMoYjjB7PxFH8VpW1yyjuwqw303f6UPytCoOJZAosbc-1739463400-1.0.1.1-5VqgOeJW8ApFLmOYWPyQqoZXGOqZwlaEs0iOgyFKFwQEq7HijeewsKhqW9AdYft7BFAPBJLFLzkb5ExyVhHVWQ; path=/; expires=Thu, 13-Feb-25 16:46:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=fgnuFc4.Rvic2TJ54tspposZhXiQsskwHVy8k0aAoeQ-1739463400548-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '91161f6c9f77f773-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 17:16:40,558 - openai._base_client - DEBUG - request_id: req_28793e24b419fade972a606e3f49662b
2025-02-13 17:17:15,461 - __main__ - INFO - Received webhook with body: {'update_id': 647682852, 'message': {'message_id': 125, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739463435, 'text': '/shortterm', 'entities': [{'offset': 0, 'length': 10, 'type': 'bot_command'}]}}
2025-02-13 17:17:15,462 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 17, 15, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=10, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=125, supergroup_chat_created=False, text='/shortterm'), update_id=647682852)
2025-02-13 17:17:15,462 - __main__ - INFO - Processing command: /shortterm
2025-02-13 17:17:15,463 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ' Short-term Memory Stats:\n\nTotal messages: 60\nUser messages: 30\nAssistant messages: 30\nTime range: 1739460479.262209 - 1739462938.8177788'}`
2025-02-13 17:17:15,463 - httpcore.connection - DEBUG - close.started
2025-02-13 17:17:15,463 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:17:15,464 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:17:15,505 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107798f50>
2025-02-13 17:17:15,505 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107596c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:17:15,556 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1077c4770>
2025-02-13 17:17:15,556 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:17:15,557 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:17:15,557 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:17:15,558 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:17:15,558 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:17:15,642 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:17:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'389'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:17:15,647 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:17:15,647 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:17:15,648 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:17:15,648 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:17:15,648 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:17:15,648 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 126, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739463435, 'text': ' Short-term Memory Stats:\n\nTotal messages: 60\nUser messages: 30\nAssistant messages: 30\nTime range: 1739460479.262209 - 1739462938.8177788'}`
2025-02-13 17:17:21,842 - __main__ - INFO - Received webhook with body: {'update_id': 647682853, 'message': {'message_id': 127, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739463441, 'text': '/wholehistory', 'entities': [{'offset': 0, 'length': 13, 'type': 'bot_command'}]}}
2025-02-13 17:17:21,842 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 17, 21, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=13, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=127, supergroup_chat_created=False, text='/wholehistory'), update_id=647682853)
2025-02-13 17:17:21,842 - __main__ - INFO - Processing command: /wholehistory
2025-02-13 17:17:21,844 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ' Whole History Stats:\n\nTotal messages: 60\nUser messages: 30\nAssistant messages: 30\nTime range: 1739460479.262209 - 1739462938.8177788'}`
2025-02-13 17:17:21,844 - httpcore.connection - DEBUG - close.started
2025-02-13 17:17:21,844 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:17:21,844 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:17:21,889 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1077c5f30>
2025-02-13 17:17:21,890 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107596c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:17:21,933 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1076eb9b0>
2025-02-13 17:17:21,933 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:17:21,934 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:17:21,934 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:17:21,934 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:17:21,934 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:17:22,063 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:17:22 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'385'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:17:22,064 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:17:22,065 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:17:22,065 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:17:22,065 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:17:22,066 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:17:22,066 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 128, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739463442, 'text': ' Whole History Stats:\n\nTotal messages: 60\nUser messages: 30\nAssistant messages: 30\nTime range: 1739460479.262209 - 1739462938.8177788'}`
2025-02-13 17:18:08,470 - __main__ - INFO - Received webhook with body: {'update_id': 647682854, 'message': {'message_id': 129, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739463488, 'text': '/historycontext', 'entities': [{'offset': 0, 'length': 15, 'type': 'bot_command'}]}}
2025-02-13 17:18:08,473 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 18, 8, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=15, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=129, supergroup_chat_created=False, text='/historycontext'), update_id=647682854)
2025-02-13 17:18:08,473 - __main__ - INFO - Processing command: /historycontext
2025-02-13 17:18:08,474 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': " History Context:\n\n 2025-02-13T17:16:40.566896\nType: global_summary\nMessages: 60\nSummary:\n1. Key recurring topics: \n- The user repeatedly wants the assistant to recall his name and information about him.\n- The assistant is repeatedly offering help to the user.\n\n2. Who are the group of people you are talking to: \n- Based on the conversation, the assistant is talking to a single person named Nazar.\n\n3. People names, life facts, relations between each other, etc.: \n- The user's name is Nazar. \n- Nazar likes triathlon, design, bright saturated colors, and travel.\n- He has a camera named Pentax MX, indicating he might enjoy photography.\n- Nazar has a friend named Innokenty whom he traveled to Andorra.\n\n4. Important facts or preferences mentioned:\n- Nazar enjoys triathlon, design, and his favorite colors are bright saturated ones. \n- He enjoys photography with his Pentax MX camera and has an interest in traveling. \n- He also mentioned a trip to Andorra with his friend Innokenty.\n\n5. Significant decisions or conclusions: \n- Through this conversation, the assistant is successful in identifying and remembering the user's name and his interests.\n\n6. User's behavioral patterns or preferences:\n- The user consistently tests to see if the assistant remembers his name and facts about him.\n- The user tends to ask for help from the assistant frequently.\n- He enjoys sharing personal details and seeing if the assistant will remember these details.\n\n"}`
2025-02-13 17:18:08,474 - httpcore.connection - DEBUG - close.started
2025-02-13 17:18:08,475 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:18:08,475 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:18:08,515 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10768f9b0>
2025-02-13 17:18:08,515 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107596c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:18:08,557 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10768fac0>
2025-02-13 17:18:08,558 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:18:08,559 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:18:08,559 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:18:08,559 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:18:08,560 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:18:08,625 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:18:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1741'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:18:08,626 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:18:08,626 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:18:08,626 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:18:08,626 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:18:08,626 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:18:08,627 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 130, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739463488, 'text': " History Context:\n\n 2025-02-13T17:16:40.566896\nType: global_summary\nMessages: 60\nSummary:\n1. Key recurring topics: \n- The user repeatedly wants the assistant to recall his name and information about him.\n- The assistant is repeatedly offering help to the user.\n\n2. Who are the group of people you are talking to: \n- Based on the conversation, the assistant is talking to a single person named Nazar.\n\n3. People names, life facts, relations between each other, etc.: \n- The user's name is Nazar. \n- Nazar likes triathlon, design, bright saturated colors, and travel.\n- He has a camera named Pentax MX, indicating he might enjoy photography.\n- Nazar has a friend named Innokenty whom he traveled to Andorra.\n\n4. Important facts or preferences mentioned:\n- Nazar enjoys triathlon, design, and his favorite colors are bright saturated ones. \n- He enjoys photography with his Pentax MX camera and has an interest in traveling. \n- He also mentioned a trip to Andorra with his friend Innokenty.\n\n5. Significant decisions or conclusions: \n- Through this conversation, the assistant is successful in identifying and remembering the user's name and his interests.\n\n6. User's behavioral patterns or preferences:\n- The user consistently tests to see if the assistant remembers his name and facts about him.\n- The user tends to ask for help from the assistant frequently.\n- He enjoys sharing personal details and seeing if the assistant will remember these details."}`
2025-02-13 17:18:41,580 - __main__ - INFO - Received webhook with body: {'update_id': 647682855, 'message': {'message_id': 131, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739463521, 'text': '/midterm', 'entities': [{'offset': 0, 'length': 8, 'type': 'bot_command'}]}}
2025-02-13 17:18:41,582 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 18, 41, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=8, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=131, supergroup_chat_created=False, text='/midterm'), update_id=647682855)
2025-02-13 17:18:41,582 - __main__ - INFO - Processing command: /midterm
2025-02-13 17:18:41,582 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ' Mid-term Memory Stats:\n\nTotal messages: 0\nUser messages: 0\nAssistant messages: 0\nTime range: No messages'}`
2025-02-13 17:18:41,582 - httpcore.connection - DEBUG - close.started
2025-02-13 17:18:41,582 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:18:41,582 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:18:41,623 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107771350>
2025-02-13 17:18:41,624 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107596c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:18:41,666 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107771550>
2025-02-13 17:18:41,666 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:18:41,666 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:18:41,666 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:18:41,667 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:18:41,667 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:18:41,731 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:18:41 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'357'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:18:41,731 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:18:41,731 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:18:41,731 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:18:41,731 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:18:41,731 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:18:41,732 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 132, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739463521, 'text': ' Mid-term Memory Stats:\n\nTotal messages: 0\nUser messages: 0\nAssistant messages: 0\nTime range: No messages'}`
2025-02-13 17:28:55,573 - __main__ - INFO - Received webhook with body: {'update_id': 647682856, 'my_chat_member': {'chat': {'id': -1002157344870, 'title': 'Vajramya Path', 'type': 'supergroup'}, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'date': 1739464135, 'old_chat_member': {'user': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'status': 'left'}, 'new_chat_member': {'user': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'status': 'member'}}}
2025-02-13 17:28:55,574 - __main__ - INFO - Created update object: Update(my_chat_member=ChatMemberUpdated(chat=Chat(id=-1002157344870, title='Vajramya Path', type=<ChatType.SUPERGROUP>), date=datetime.datetime(2025, 2, 13, 16, 28, 55, tzinfo=datetime.timezone.utc), from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), new_chat_member=ChatMemberMember(status=<ChatMemberStatus.MEMBER>, user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot')), old_chat_member=ChatMemberLeft(status=<ChatMemberStatus.LEFT>, user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'))), update_id=647682856)
2025-02-13 17:28:55,634 - __main__ - INFO - Received webhook with body: {'update_id': 647682857, 'message': {'message_id': 10590, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': -1002157344870, 'title': 'Vajramya Path', 'type': 'supergroup'}, 'date': 1739464135, 'new_chat_participant': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'new_chat_member': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'new_chat_members': [{'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}]}}
2025-02-13 17:28:55,635 - __main__ - INFO - Created update object: Update(message=Message(api_kwargs={'new_chat_participant': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'new_chat_member': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}}, channel_chat_created=False, chat=Chat(id=-1002157344870, title='Vajramya Path', type=<ChatType.SUPERGROUP>), date=datetime.datetime(2025, 2, 13, 16, 28, 55, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=10590, new_chat_members=(User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'),), supergroup_chat_created=False), update_id=647682857)
2025-02-13 17:29:14,962 - __main__ - INFO - Received webhook with body: {'update_id': 647682858, 'message': {'message_id': 133, 'from': {'id': 378607439, 'is_bot': False, 'first_name': '', 'last_name': 'K', 'username': 'nath273_79', 'language_code': 'en'}, 'chat': {'id': 378607439, 'first_name': '', 'last_name': 'K', 'username': 'nath273_79', 'type': 'private'}, 'date': 1739464154, 'text': '/start', 'entities': [{'offset': 0, 'length': 6, 'type': 'bot_command'}]}}
2025-02-13 17:29:14,963 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='', id=378607439, last_name='K', type=<ChatType.PRIVATE>, username='nath273_79'), date=datetime.datetime(2025, 2, 13, 16, 29, 14, tzinfo=datetime.timezone.utc), delete_chat_photo=False, entities=(MessageEntity(length=6, offset=0, type=<MessageEntityType.BOT_COMMAND>),), from_user=User(first_name='', id=378607439, is_bot=False, language_code='en', last_name='K', username='nath273_79'), group_chat_created=False, message_id=133, supergroup_chat_created=False, text='/start'), update_id=647682858)
2025-02-13 17:29:14,964 - __main__ - INFO - Processing command: /start
2025-02-13 17:29:14,964 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 378607439, 'text': " Hello! I'm your AI assistant bot. I can help you with various tasks and maintain our conversation history.\n\nUse /help to see available commands."}`
2025-02-13 17:29:14,964 - httpcore.connection - DEBUG - close.started
2025-02-13 17:29:14,965 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:29:14,965 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:29:15,033 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107775e50>
2025-02-13 17:29:15,034 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107596c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:29:15,076 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107776d50>
2025-02-13 17:29:15,077 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:29:15,078 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:29:15,078 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:29:15,078 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:29:15,079 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:29:15,174 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:29:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'506'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:29:15,175 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:29:15,175 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:29:15,176 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:29:15,176 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:29:15,177 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:29:15,177 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 134, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 378607439, 'first_name': '', 'last_name': 'K', 'username': 'nath273_79', 'type': 'private'}, 'date': 1739464155, 'text': " Hello! I'm your AI assistant bot. I can help you with various tasks and maintain our conversation history.\n\nUse /help to see available commands.", 'entities': [{'offset': 115, 'length': 5, 'type': 'bot_command'}]}`
2025-02-13 17:29:54,184 - __main__ - INFO - Received webhook with body: {'update_id': 647682859, 'message': {'message_id': 135, 'from': {'id': 308526396, 'is_bot': False, 'first_name': 'Naz', 'username': 'nm_2719', 'language_code': 'en', 'is_premium': True}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739464194, 'text': ''}}
2025-02-13 17:29:54,186 - __main__ - INFO - Created update object: Update(message=Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 29, 54, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Naz', id=308526396, is_bot=False, is_premium=True, language_code='en', username='nm_2719'), group_chat_created=False, message_id=135, supergroup_chat_created=False, text=''), update_id=647682859)
2025-02-13 17:29:54,186 - __main__ - INFO - Processing message: 
2025-02-13 17:29:54,230 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a helpful AI assistant with memory capabilities.\n                Important context about our conversation history:\n                1. Key recurring topics: \n- The user repeatedly wants the assistant to recall his name and information about him.\n- The assistant is repeatedly offering help to the user.\n\n2. Who are the group of people you are talking to: \n- Based on the conversation, the assistant is talking to a single person named Nazar.\n\n3. People names, life facts, relations between each other, etc.: \n- The user's name is Nazar. \n- Nazar likes triathlon, design, bright saturated colors, and travel.\n- He has a camera named Pentax MX, indicating he might enjoy photography.\n- Nazar has a friend named Innokenty whom he traveled to Andorra.\n\n4. Important facts or preferences mentioned:\n- Nazar enjoys triathlon, design, and his favorite colors are bright saturated ones. \n- He enjoys photography with his Pentax MX camera and has an interest in traveling. \n- He also mentioned a trip to Andorra with his friend Innokenty.\n\n5. Significant decisions or conclusions: \n- Through this conversation, the assistant is successful in identifying and remembering the user's name and his interests.\n\n6. User's behavioral patterns or preferences:\n- The user consistently tests to see if the assistant remembers his name and facts about him.\n- The user tends to ask for help from the assistant frequently.\n- He enjoys sharing personal details and seeing if the assistant will remember these details.\n                \n                Guidelines:\n                - Remember and use people's names and preferences\n                - Always respond in the same language as the user's message\n                - Keep track of important information shared in conversation\n                - If you learn someone's name, use it in future responses\n                - Be friendly and personable while maintaining professionalism"}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ', !      ?'}, {'role': 'user', 'content': '   ?'}, {'role': 'assistant', 'content': ',      ,       .      ?'}, {'role': 'user', 'content': '  '}, {'role': 'assistant', 'content': ' , !   ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': ',      .  ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '  , !     ?'}, {'role': 'user', 'content': '!'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '  ?'}, {'role': 'assistant', 'content': '  .      , ?'}, {'role': 'user', 'content': 'hey!'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !   ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': ', !    ?'}, {'role': 'user', 'content': '/start'}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': 'dsds'}, {'role': 'assistant', 'content': '-   ?   , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '  .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '      , ?'}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': ', !     ?'}, {'role': 'user', 'content': ' ,   ,   ,   .'}, {'role': 'assistant', 'content': ' , !    ? ,        ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,  ,      .     , ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '     ,    .    , ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ' , .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '         Pentax MX'}, {'role': 'assistant', 'content': ', !    -  !    ?           Pentax MX?'}, {'role': 'user', 'content': '     ! '}, {'role': 'assistant', 'content': ' !           ?     ?'}, {'role': 'user', 'content': '/context'}, {'role': 'assistant', 'content': '      .      ?     ?        - ,  !'}, {'role': 'user', 'content': '    ?'}, {'role': 'assistant', 'content': ' ,    - ,    ,     Pentax MX,       .   ,       .  - ,        ?'}, {'role': 'user', 'content': '/session'}, {'role': 'assistant', 'content': ', .   .    ?'}, {'role': 'user', 'content': '/help'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': '!     ?'}, {'role': 'assistant', 'content': ', !  ,    ,       .   ,              Pentax MX.     - ,        ,  !'}, {'role': 'user', 'content': ']'}, {'role': 'assistant', 'content': '     , ?'}, {'role': 'user', 'content': ''}], 'model': 'gpt-3.5-turbo'}}
2025-02-13 17:29:54,231 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-13 17:29:54,231 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:29:54,275 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1076ef4d0>
2025-02-13 17:29:54,275 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107594ef0> server_hostname='api.openai.com' timeout=5.0
2025-02-13 17:29:54,300 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1076ba520>
2025-02-13 17:29:54,300 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:29:54,300 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:29:54,300 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:29:54,300 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:29:54,300 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:29:55,014 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 16:29:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jrobrdv8bldfakdoyxdsiky9'), (b'openai-processing-ms', b'533'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198145'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'556ms'), (b'x-request-id', b'req_6fe5e295c29145219efa1802a88e6887'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SXuCUeTLBPlXlguZ.TFATPOi5Wev8FZ1_Q0Mba0V5QA-1739464195-1.0.1.1-wheBOIFXSfPpWjQ8TQ2IjL3B9SCFm.uGf0XAFVrnvWPqm.G9PnJ7uP2E9xvhBAa_sWUHShC8I4Sd7sKahkP1rA; path=/; expires=Thu, 13-Feb-25 16:59:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=DTVLQKLeYWCO7rVzLkKZCwh4L3I6fhuNqcH2yH3Li0I-1739464195008-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9116332e7cc02f95-MAD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-13 17:29:55,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-13 17:29:55,014 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:29:55,014 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:29:55,015 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:29:55,015 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:29:55,015 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 13 Feb 2025 16:29:55 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jrobrdv8bldfakdoyxdsiky9'), ('openai-processing-ms', '533'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '198145'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '556ms'), ('x-request-id', 'req_6fe5e295c29145219efa1802a88e6887'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=SXuCUeTLBPlXlguZ.TFATPOi5Wev8FZ1_Q0Mba0V5QA-1739464195-1.0.1.1-wheBOIFXSfPpWjQ8TQ2IjL3B9SCFm.uGf0XAFVrnvWPqm.G9PnJ7uP2E9xvhBAa_sWUHShC8I4Sd7sKahkP1rA; path=/; expires=Thu, 13-Feb-25 16:59:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=DTVLQKLeYWCO7rVzLkKZCwh4L3I6fhuNqcH2yH3Li0I-1739464195008-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9116332e7cc02f95-MAD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-13 17:29:55,015 - openai._base_client - DEBUG - request_id: req_6fe5e295c29145219efa1802a88e6887
2025-02-13 17:29:55,018 - __main__ - INFO - Got response: , !    ?
2025-02-13 17:29:55,018 - telegram.ext.ExtBot - DEBUG - Calling Bot API endpoint `sendMessage` with parameters `{'chat_id': 308526396, 'text': ', !    ?'}`
2025-02-13 17:29:55,019 - httpcore.connection - DEBUG - close.started
2025-02-13 17:29:55,019 - httpcore.connection - DEBUG - close.complete
2025-02-13 17:29:55,019 - httpcore.connection - DEBUG - connect_tcp.started host='api.telegram.org' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 17:29:55,059 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1077d4210>
2025-02-13 17:29:55,059 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107596c30> server_hostname='api.telegram.org' timeout=5.0
2025-02-13 17:29:55,098 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107733e70>
2025-02-13 17:29:55,098 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 17:29:55,098 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 17:29:55,098 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 17:29:55,098 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 17:29:55,098 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 17:29:55,167 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'nginx/1.18.0'), (b'Date', b'Thu, 13 Feb 2025 16:29:55 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'429'), (b'Connection', b'keep-alive'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'Access-Control-Allow-Origin', b'*'), (b'Access-Control-Allow-Methods', b'GET, POST, OPTIONS'), (b'Access-Control-Expose-Headers', b'Content-Length,Content-Type,Date,Server,Connection')])
2025-02-13 17:29:55,168 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8050570051:AAG4byICXKPopJ4pkngSfXLBEa7ZnJ4eTrs/sendMessage "HTTP/1.1 200 OK"
2025-02-13 17:29:55,168 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 17:29:55,168 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 17:29:55,168 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 17:29:55,168 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 17:29:55,168 - telegram.ext.ExtBot - DEBUG - Call to Bot API endpoint `sendMessage` finished with return value `{'message_id': 136, 'from': {'id': 8050570051, 'is_bot': True, 'first_name': 'Dildong', 'username': 'Dildong_bot'}, 'chat': {'id': 308526396, 'first_name': 'Naz', 'username': 'nm_2719', 'type': 'private'}, 'date': 1739464195, 'text': ', !    ?'}`
2025-02-13 17:29:55,169 - __main__ - INFO - Sent message: Message(channel_chat_created=False, chat=Chat(first_name='Naz', id=308526396, type=<ChatType.PRIVATE>, username='nm_2719'), date=datetime.datetime(2025, 2, 13, 16, 29, 55, tzinfo=datetime.timezone.utc), delete_chat_photo=False, from_user=User(first_name='Dildong', id=8050570051, is_bot=True, username='Dildong_bot'), group_chat_created=False, message_id=136, supergroup_chat_created=False, text=', !    ?')
